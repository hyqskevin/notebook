## <center>人工智能发展简史报告</center>
<br/>
从1956年达特茅斯会议开始，到2016年Alpha Go，AI的发展走过整整60年.期间对AI研究的高潮和低谷交替出现，研究人员也取得了举世瞩目的进展。但目及所见处，只是眼前的一小段距离，AI的发展依旧任重道远。

### 1.1950 图灵测试
  - 由计算机科学之父图灵在1950年发表论文《计算机器与智能》。其中中提出一种测试方法——图灵测试：如果电脑能在5分钟内回答由人类测试者提出的一系列问题，且其超过30%的回答让测试者误认为是人类所答，则电脑就通过测试并可下结论为机器具有智能。
  - 论文中图灵定义并解释了人工智能及其研究目的和发展方向,并驳斥了此前科学界及社会上普遍存在的反对观点,被称为 **人工智能科学的开山之作** 。
### 2.1956 历史性的会议
  - 一般认为，**AI的诞生** 在1956年夏季，在美国东北部风景如画的大学达特茅斯学院。
  - 与会十来人，其中就包括后来获得图灵奖的马文·明斯基(Marvin Minsky)、约翰·麦卡锡(JohnMccarthy)、艾伦·纽厄尔(Allen Newell)、赫伯特·西蒙(Herbert ASimon)四人，会议召集者麦卡锡当时还只是达特茅斯学院的数学系年轻助教，但正是他们，开启了波澜壮阔、跌宕困顿的AI史诗序幕。
  - 达特茅斯会议之后的十多年，AI专门研究机构开始创建，AI研究不断取得进展，鼓励前沿探索研究的经费源源不断，这段时间称为 **AI的黄金十年** 。
### 3.1956-1974 黄金年代
  - 达特茅斯会议之后的数年是大发现的时代。人们发现计算机可以去解决代数应用题，证明几何定理，学习和使用英语。当时大多数人几乎无法相信机器能够如此“智能”。
    - 1957年，弗兰克·罗森布拉特（Frank Rosenblatt）打造出 **感知机** (Perceptron)，能够基于两层计算机网络进行模式识别。
    - 1958年，约翰·麦卡锡（John McCarthy）开发编程语言 **Lisp** 。之后Lisp成为人工智能研究中最流行的编程语言。
    - 1959年，阿瑟·萨缪尔（Arthur Samuel）创造了“机器学习”一词。
    - 1961年，第一台工业机器人Unimate开始在新泽西州通用汽车工厂的生产线上工作。
    - 1972年，斯坦福大学开发出名为“MYCIN”的专家系统。能够利用人工智能识别感染细菌，并推荐抗生素。
  - 当时的AI研究人员对AI的发展及其乐观：
    - 1958年西蒙预言“十年之内，计算机将成为国际象棋世界冠军”。
    - 纽厄尔说“十年之内，计算机将发现并证明一个重要数学定理”。
    - 1965年，西蒙认为“二十年内，机器将能完成人能做到的一切工作”。
    - 1967年，明斯基更大胆判断：“在我们这一代人的努力下，创造人工智能难题将会从根本上被解决。

  - 要知道当时的经费几乎是无条件地提供给实验室的，然凌冬降至，好景不长。
### 4.1974-1980 计算之殇
  - 上世纪70年代初，AI遭遇瓶颈，AI研究者们遭遇了无法克服的基础性障碍，问题和批评也接踵而来。人们发现逻辑证明器、感知器、增强学习等等只能做很简单、非常专门且很窄的任务，稍微超出范围却发现高墙林立，无法应对。这其中计算机存在几方面的局限。
    - 计算机的运算能力：当时的计算机有限的内存和处理速度不足以解决任何实际的AI问题。
    - 计算复杂性和指数爆炸：除了那些最简单的情况，这些问题的解决需要近乎无限长的时间，成为了不可能完成的计算任务。
    - 常识与推理：许多重要的AI应用，都需要计算机处理对世界的认识信息，然而研究者们很快发现达到这个认知水平要求太高了。
    - 莫拉维克悖论：证明定理和解决几何问题对计算机而言相对容易，而一些看似简单的任务，如人脸识别或穿过屋子，实现起来却极端困难。

  - 资金上的困难接踵而至，由于缺乏进展，对AI提供资助的机构对无方向的AI研究逐渐停止了资助，如同釜底抽薪，曾经火热的AI从云端跌落，winter is comming…
### 5.1980-1993 跌宕困顿
  - 进入20世纪80年代，卡耐基·梅隆大学为DEC公司制造出了名为XCON的 **专家系统** 。
    - 专家系统实际上是一套程序软件，能够从专门的知识库系统中，通过推理找到一定规律，像人类专家那样解决某一特定领域的问题。

    这个专家系统可帮助DEC公司每年节约4000万美元左右的费用，特别是在决策方面能提供有价值的内容。
  - 受此鼓励，很多国家包括日本、美国都再次投入巨资开发所谓第5代计算机。日本经济产业省拨款八亿五千万美元支持第五代计算机项目，英国开始了耗资三亿五千万英镑的Alvey工程，DARPA也行动起来，组织了战略计算促进会。
  - 在80年代出现了人工智能数学模型方面的重大发明，其中包括著名的 **多层神经网络** 和 **BP反向传播算法**（1986）等，也出现了无人驾驶汽车的研究范例(1986),聊天机器人（1988），能与人类下象棋的高度智能机器（1989）。
  - ------
  - 1987年到1993年现代PC的出现，让人工智能的寒冬降临，持续近20年之久。Apple和IBM生产的台式机性能不断提升，计算机开始走入个人家庭，其费用远远低于专家系统所使用的Symbolics和Lisp等机器，一夜之间价值五亿美元的产业土崩瓦解。
### 6.1993-2006 曙光初照
  - 在1984年，马文·明斯基（Marvin Minsky）就警告“AI之冬”即将到来(三年后确实发生了）。但个人计算机产业蓬勃发展、互联网广泛使用，成为了一柄双刃剑，一方面把AI逼入寒冬，另一方面，却使人类社会获得前所未有的强大计算能力，通过互联网积累的信息、数据也岀现爆炸性增长，这些都在为AI日后复兴打下坚实的基础。
  - 新工具：在新的数学工具方面，原来已经存在于数学或者其他学科的文献中的数学模型，被重新发掘或者发明出来。当时比较显著几个成果包括最近获得图灵奖的 **图模型以及图优化** 、**深度学习网络** 等，都是大约在15年前重新被提出来，重新开始研究。
  - 新理念:在新的理论方面，由于数学模型对自然世界的简化，有着非常明确的数理逻辑，使得理论分析和证明成为可能.
  - **摩尔定律**:让计算越来越强大，当更强大的计算能力被转移到人工智能研究后，显著提高了人工智能的研究效果,一个新的繁荣期即将到来

  - 在这沉寂的近20年，AI也并非毫无发展：
    - 1997年，IBM研发的“深蓝”（Deep Blue）成为第一个击败人类象棋冠军的电脑程序。
    - 1998年，Yann LeCun和Yoshua Bengio发表关于神经网络应用于手写识别和优化反向传播的论文。
    - 2005年，Stanford开发的一台机器人在一条沙漠小径上成功地自动行驶了131英里，赢得了DARPA挑战大赛头奖。
### 7.2006-2012 破冰之路
  - AI高速发展的浪潮还有些时日，但深度学习的征途已在寒冬中开始前行。
  - #### “加拿大黑手党三人帮”
    - Geoffrey Hinton博士毕业后，AI刚好迎来第二次高潮，一直在神经网络领域耕耘的他并没有感到好时光到来；在AI第二次进入低谷时，Hinton仍然在这里坚守;在神经网络相关学术论文很难得到发表的那段时间，他坚持写了两百多篇研究论文，为后来的突破打下了坚实的基础。
    - 2004年，欣顿从加拿大高等研究所(CIFAR)获得了每年50万美元的经费支持,与Yann Lecun和Yoshua Bengio两位志同道合者的良好合作一下，他们将一批一流的计算机、生物学、电子工程、神经科学、物理学和心理学专家团结在一起，共同探索神经网络模拟人脑智能的新方法。三位深度学习的先驱和引领者，都与加拿大有渊源，之后都被高科技巨头公司网罗，被称为深度学习的"加拿大黑手党三人帮”。
    - 2006年，Geoffrey Hinton 发表《Learning Multiple Layers of Representation》一些新思想和新方法被应用到深度学习领域。
    - 2012年ImageNet图像识别竞赛，Hinton和学生们采用深度学习的进行识别，将图像识别的准确率进步提高一个数量级，超过第二名10%以上。**深度学习** 的热潮从此掀起，势如破竹，锐不可挡，大踏步向前迈进。
  - #### “疯狂的冒险家”
      - 神经网络系统如果训练数据太少，会出现“ **过拟合** (overfitting)”。而学习结果能广泛适用，称为“**泛化能力**”，则需要大量数据，深度学习必须在计算能力大大增强和海量数据出现的情况下，才能充分发挥作用。
      - 深度学习的兴起，还需要依靠一双翅膀，而借助GPU强大并行计算处理能力，深度学习迅速展示了自己的工程可行性和广泛应用前景，GPU又因深度学习打开AI一个个应用新市场，得到快速发展。

        GPU，正是黄仁勋创办的英伟达(NVIDIA)公司首创。
      - 2007年Nvidia推出了基于CUDA的通用GPUbeta版，用高性能通用GPU让个人拥有几百美元的廉价超级计算机、能支持大规模 **并行计算** ，吸引使用各种编程语言的工程师纷纷用英伟达的GPU进行开发，增强了GPU的开放性和通用性。
      - 度学习涉及到的计算，主要进行高速度、大规模的矩阵运算。这样的应用场景下，计算能力强大而价格低廉的GPU，成为最好选择。随着深度学习取得巨大成功，几乎作为标配的GPU同步得到极大发展。
  - #### “缔造传奇的ImageNet”
    - 2007年，李飞飞（Fei Fei Li）和普林斯顿大学的同事开始建立ImageNet。这是一个近10亿张图片的大型注释图像数据库，旨在帮助视觉对象识别软件进行研究。2009年ImageNet诞生时，已有1500万张经过标注图片、含22000类物品的数据库，无论在质量上还是数量上，这都是一个规模空前的数据库。
    - 大数据威力很快显示出来了，ImageNet大数据集开源，成为检验各种AI算法的最权威平台，也成为评价AI科研机构和科技公司AI实力的最好竞技场。


  - 深度学习最终借助GPU这双强有力的翅膀和大数据广阔的研究平台，直上云霄。
### 8.2012-至今 浪潮之巅
  - #### “重建巴别塔”
    - 《圣经》记载，远古人类希望建造一座通往天堂的高塔，这就是巴别塔（Tower of Babel）。为了阻止人类的计划，上帝让人类说不同的语言，分成了不同的民族。 现在，**机器翻译**（Mchine Translation）让人类的梦想一步步走向实现。
    - 2011年夏天，Hinton的博士生Navdeep Jaitly来谷歌语音识别组实习，用深度神经网络来替代高斯混合模型做声学模型，获得了显著超出谷歌原系统的识别结果。2012年初谷歌发布Voice Search，是业界首次将深度学习用于大词汇量语音识别产品中。
    - 2016年10月18日，由微软首席语音科学家黄学东博士带领的语音团队在权威的产业标准 Switchboard 语音识别基准测试中，实现了对话语音识别词错率5.9%，首次达到与专业速记员持平，被认为是AI领域历史性的突破。
  - #### “开眼看世界”
    - 2012年6月，吴恩达（Andrew Ng）和杰夫·迪恩（Jeff Dean）在给一个大型神经网络展示1000万张未标记的网络图像时，发现神经网络能够识别出一只猫的形象。如今在ImageNet图片集里，人眼辨识错误率大概为5.1%，而已有算法能够达到低于5%的结果。 **计算机视觉** 已经开始应用于智能安防、婴儿和老人看护、无人汽车和无人机等各种需要视觉的领域。接下来科学家们正在探索通用型视觉识别算法和工程化实现。一旦工程化实现了通用型视觉识别技术，智能机器开眼看世界的那一天就不远了。
  - #### “MOOC之道”
    - 2012年，是MOOC元年。1月，Sebastian Thrun 辞去斯坦福大学终身教职，在硅谷创立了第一家MOOC教育公司 Udacity。4月，Daphne Koller 和她的同事吴恩达(Andrew Ng)共同创办了 Coursera。5月，MIT和哈佛大学联手创办了非盈利性机构 edX。
    - MOOC的巨大影响，正是由于AI在其中扮演重要角色，分布于世界各地的授课者和大规模学习者的多空间交互、学生作业的讨论完成与评判、检查课程完成情况的各种小测验与期中期末考试等等，这些教学工作如果没有数据挖掘、教育专家系统、人机交互等多种AI手段的帮助，不可能完成。
  - #### “承上启下的AlphaGo”
    - 当AlphaGo战胜李世石，人工智能两个时代也完成了交接。人工智能前60年，主要通过有监督的深度学习算法，解决语音识别、图像识别、自然语言理解等总样本量有上限的相对“有穷大”问题。AlphaGo对 **强化学习** 的探索，更接近生物学习的行为特征，具有探索未知世界的能力,打开了“无穷大”的大门。

  在60年这个节点上，经过了1980年和2000年两次寒冬，全球人工智能界又迎来了第三次浪潮。这一次，随着前60年有监督深度学习算法的理论研究和工程化的成熟，以及硬件计算能力的大幅提升和成本的飞速降低，在云计算、大数据和移动互联网的融合推动下，AI在很多方面都有了突破性进展。

  目前我们能在书中学习的，都是AI发展伊始荜路蓝缕多年的研究成果，能从论文中获悉的，是5年来各领域不断研究的新进展，对于未来，目及所见，任重道远。

  We can only see a short distance ahead,but we can see plenty there that needs to be done。  ——A.M.Turing


#### 参考文献：

  - Turing, Alan, Computing Machinery and Intelligence, Mind, October 1950, LIX (236): 433–460 [2008-08-18], ISSN 0026-4423, doi:10.1093/mind/LIX.236.433 .

  - Lecun Y, Bengio Y, Hinton G. Deep learning[J]. Nature, 2015, 521(7553):436-444.

  - Krizhevsky A, Sutskever I, Hinton G E. ImageNet classification with deep convolutional neural networks[C]// International Conference on Neural Information Processing Systems. Curran Associates Inc. 2012:1097-1105.

  - Russell S J, Norvig P. Artificial Intelligence: A Modern Approach[M]. 人民邮电出版社, 2002.

  - wikipedia 人工智能史
