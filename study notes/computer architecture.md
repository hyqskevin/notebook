## <center>第一章 概念</center>
#### 1.1发展
  <center>
    <table>
      <tr>
        <th>时间</th>
        <th>发展</th>
        <th>速度</th>
      </tr>
      <tr>
        <th>1946之后的25年</th>
        <th>计算机制造技术发展，计算机系统结构创新</th>
        <th>提高25%</th>
      </tr>
      <tr>
        <th>20世纪70年代末和80年代初</th>
        <th>大规模集成电路，微处理器</th>
        <th>35%</th>
      </tr>
      <tr>
        <th>80年代中期后16年</th>
        <th>RISC</th>
        <th>50%</th>
      </tr>
      <tr>
        <th>2002年后</th>
        <th>功耗问题，可开发并行指令减少，存储器访问缓慢，</th>
        <th>降到20%</th>
      </tr>
      <tr>
        <th>2014年后</th>
        <th>多核处理，指令级并行转向线程级数据级并行</th>
        <th>/</th>
      </tr>
    </table>
  </center>

#### 1.2层次结构
  <center>翻译方法实现</center>

    ->L6：应用语言虚拟机
    ->L5：高级语言虚拟机
    ->L4:汇编语言虚拟机

  <center>解释方法实现</center>

    ->L3:操作系统虚拟机：传统机器级指令+操作系统级指令
    ->L2:机器语言(传统机器级)：RISC无L1，L2直接采用硬件逻辑，速度快
    ->L1:微程序机器级：微指令集
    低层计算机属性对高层计算机的程序员是透明的<p>
    计算机结构/组成/实现<p>
    计算机系统结构Flynn分类：SISD,SIMD,MISD,MIMD
#### 1.3定量分析技术
  - ##### 计算机系统设计定量原理
    - 以经常性事件为重点
    - Amdahl定律*
      <center>

        $系统加速比=\frac{系统性能_{改进后}}{系统性能_{改进前}}=\frac{总时间_{改进前}}{总时间_{改进后}}=\frac1{(1-改进比例)+\frac{改进比例}{部件加速比}}$
      </center>
    - cpu性能公式*
      <center>
      CPU时间 = IC × CPI × 时钟周期时间
      </center>
  - ##### 计算机系统性能评测
    - $n=\frac{执行时间_Y}{执行时间_X}=\frac{性能_X}{性能_Y}$ 执行时间和性能成反比
    - 基准测试程序(benchmark)
1.4计算机结构的发展
  - 冯诺依曼结构
1.5 并行 指令内部并行—>指令集并行—>线程级并行—>任务级或过程级并行—>作业或程序并行
  - 措施：时间重叠，资源重复，资源共享
---
## <center>第二章 指令集结构</center>
#### 2.1分类
  <center>
    <table>
      <tr>
        <th>堆栈结构</th>
        <th>累加器结构</th>
        <th>寄存器-存储器结构(RM)</th>
        <th>寄存器-寄存器结构(RR)</th>
      </tr>
      <tr>
        <th>操作数都为隐式，位于栈顶/次栈顶</th>
        <th>操作数累加器为隐式，存储器单元显式</th>
        <th>显式，位于寄存器/存储器</th>
        <th>显式，都位于寄存器</th>
      </tr>
      <tr>
        <th>结果写入栈顶</th>
        <th>结果送回累加器</th>
        <th>结果写入通用寄存器组</th>
        <th>结果写入通用寄存器组</th>
      </tr>
      <tr>
        <th>程序占用空间小|堆栈无法随机访问</th>
        <th>占用空间小|会频繁访问存储器</th>
        <th>访问速度快，容易编译，代码紧凑|操作数不对称，时钟周期不同</th>
        <th>访问速度快，容易编译，代码简洁，时钟周期相近|指令条数多，耗内存</th>
      </tr>
      <tr>
        <th>push A</th>
        <th>load A</th>
        <th>load R1,A</th>
        <th>load R1,A</th>
      </tr>
      <tr>
        <th>push B</th>
        <th>add B</th>
        <th>add R1,B</th>
        <th>add R2,B</th>
      </tr>
      <tr>
        <th>add</th>
        <th>store C</th>
        <th>store R1,C</th>
        <th>add R3,R1,R2</th>
      </tr>
      <tr>
        <th>pop C</th>
        <th></th>
        <th></th>
        <th>store R3,C</th>
      </tr>
    </table>
  </center>

#### 2.2寻址方式(部分)
  - 立即数寻址：Regs[R]<——Regs[R]+num
  - 直接寻址：Regs[R]<——Regs[R]+Mem[num]
  - 寄存器寻址：Regs[R1]<——Regs[R1]+Regs[R2]
  - 寄存器间接寻址：Regs[R2]<——Regs[R2]+Mem[Regs[R1]]
  - 偏移寻址：Regs[R2]<——Regs[R2]+Mem[Regs[R1]+num]
  - 存储器间接寻址：Regs[R2]<——Regs[R2]+Mem[Mem[Regs[R1]]]
  - 索引寻址：Regs[R3]<——Regs[R3]+Mem[Regs[R1]+Regs[R2]]
#### 2.3功能设计
  - 指令级基本要求：完整性(指令足够用)，规整性(对称性，均匀性)，高效率(指令执行速度快，使用频度高)，兼容性
  - CISC
    - 面向目标程序的增强指令：增强运算型指令，数据传送指令，程序控制指令|三方面会增加硬件成本和复杂度
    - 面向高级语言的优化：增强对高级语言和编译器的支持，使高级语言成为计算机的机器语言
    - 面向操作系统的优化：指令级支持操作系统进程的管理和切换，存储管理，信息保护，进程同步与互斥
    - 存在问题：许多指令很少用|指令级庞大，条数多，指令功能复杂，占用大量芯片面积容易造成错误|CPI值较大，执行速度慢|不易采用流水线技术提升性能
  - RISC原则：指令条数少且简单|采用简单而统一的指令格式，并减少寻址方式|指令执行在单个周期内完成|采用load-host结构，除load和host可访问存储器，其他指令都在寄存器间进行|指令采用硬件逻辑实现|优化编辑器|利用流水线技术提升性能
---
## <center>第三章 流水线技术</center>
#### 3.1 概念
  - 将每个子过程和部件称为流水线的级或段，把段连接起来形成了流水线；流水线的段数称为深度。
  - 流水线的执行过程：取指令，译码，执行，存结果
  - 流水线的执行过程采用时空图描述
  - 流水线特点
    - 流水线把一个处理过程分解为若干子过程，每个子过程由专门的部件实现，过程间并行工作以缩短时间
    - 流水线各段的时间应该尽可能相等，否则会形成瓶颈
    - 流水线每个功能部件后面需要一个缓冲寄存器(锁存器)传送相邻间的数据，并隔离各段的处理工作
    - 流水线技术适合于大量重复的时序过程
    - 流水线技术需要通过时间和排空时间
  - 流水线的分类
    - 单功能|多功能，静态流|动态，部件级|处理机级|处理机间，线性|非线性，顺序|乱序
#### 3.2 性能指标*
  - 吞吐率：$TP = \frac{n}{T_k}$
    - 各段时间相等流水线：$TP = \frac{n}{(k+n-1)\Delta t}$<p>
      $TP_{max} = lim \frac{n}{(k+n-1)\Delta t} = \frac1{\Delta t}$ | $TP = \frac{n}{k+n-1}TP_{max}$ (当 n>>k 时 $TP \approx TP_{max}$)
    - 各段时间不相等流水线：$TP = \frac{n}{\sum_{i=1}^k \Delta t_i+(n-1)max(\Delta t_1,\Delta t_2...,\Delta t_k)}$<p>
      $TP_{max} = \frac1{max(\Delta t_1,\Delta t_2...,\Delta t_k)}$
    - 解决瓶颈问题：细分瓶颈段，使各段时间相等|重复设置瓶颈段并行工作(控制逻辑复杂，硬件成本高)
  - 加速比：$S = \frac{T_s}{T_k}$
    - 各段相等：$S = \frac{nk}{k+n-1}$
    - 各段不相等：$S = \frac{n\sum_{i=1}^k \Delta t_i}{\sum_{i=1}^k \Delta t_i+(n-1)max(\Delta t_1,\Delta t_2...,\Delta t_k)}$
  - 效率:$E = TP·\Delta t$ | $E = \frac{S}{k}$
    - 各段相等：$E = \frac{n}{k+n-1}$
    - 各段不相等：$E = \frac{n\sum_{i=1}^k \Delta t_i}{k[\sum_{i=1}^k \Delta t_i+(n-1)max(\Delta t_1,\Delta t_2...,\Delta t_k)]}$
#### 3.3 流水线的相关和冲突
  - 五段流水线
    |取指令|指令译码/读取寄存器|执行/有效地址计算|存储器访问|写回|
    |---|---|---|---|---|
    |IF|ID|EX|MEM|WB|
    |IM|Reg|ALU|DM|Reg|
  - 流水线相关：两条流水线之间存在某种依赖关系
    - 1.数据相关：两条指令都直接或间接地共享某个数据
    - 2.名相关：两条指令使用相同的寄存器或存储器单元的名称，指令间有反相关和输出相关
      - 反相关：指令j写的名和i读的名相同
      - 输出相关：指令j写的名和i写的名相同
      - 换名技术：过改变名字来消除相关，可用译码器或硬件实现
    - 3.控制相关：由分支指令引起的相关，根据分支指令的结果判断是否继续执行
  - 流水线冲突：由于流水线相关的存在，使得指令中的下一条指令不能在指定时钟周期内进行
    - 会影响流水线性能，执行结果错误；会出现停顿，降低效率和加速比
    1.结构冲突：硬件资源数量满足不了指令的重叠执行要求而发生的冲突
      - 1.1 增加停顿周期(气泡)：将流水线停顿一个周期，推迟后面的指令的执行
      - 1.2 设置相互独立的指令存储器和数据寄存器
      - 1.3 将Cache分成指令Cache和数据Cache
    2.数据冲突：指令重叠执行或重新排序时发生的冲突
      - 写后读冲突：j使用i的计算结果,在i之前读寄存器
      - 写后写冲突：j和i使用相同的存储寄存单元，在i之前执行写入操作
      - 读后写冲突：j和i使用想同的源操作数单元，在i之前执行写入操作
      - 2.1 定向(旁路)技术：将计算结果从其产生的地方直接送达到其它指令需要的地方，可以避免停顿
      - 2.2 互锁机制：检测发现数据冲突，使流水线停顿，直至冲突消失
      - 2.3 指令调度/流水线调度：依靠编译器重新组织指令的执行顺序
    3.控制冲突：流水线遇到分支指令和其它改变PC指令引起的冲突
      - 冻结/排空流水线处理分支指令：在译码段ID检测到分支指令时暂停之后的所有指令，直到分支指令到达MEM确定是否成功并计算出新的PC值
      - 减少分支延迟
        - 确定分支预测失败时，流水线正常流动
        - 确定分支预测成功时，之后的所有指令转化为空操作，并按分支目标重新取指令执行
        - 延迟：在分支指令后加几条指令并看成是一个整体，不管分支是否成功都按顺序执行指令
---
## 第四章 指令集并行
---
## 第五章 存储系统
#### 5.1 存储结构
#### 5.2 Cache
  - 基本结构
  - 映像规则
  - 查找
  - Cache替换算法
  - 写策略
  - Cache性能分析
#### 5.3 降低Cache不命中率
  - 不命中类型
    - 强制性不命中(Compulsory miss)：第一次访问块时不在Cache中，需从下一级调入Cache。| 强制性不命中率很小，不受Cache容量和关联度影响
    - 容量不命中(Capacity miss)：程序执行所需的块不能全部调入Cache中，某些块替换后再重新访问会出现不命中。| 容量不命中随容量增加而减少，不受关联度影响
    - 冲突不命中(Conflict miss)：碰撞不命中/干扰不命中  在直接映像或组相联Cache中，太多块被分到同一组中，当某个块被替换后再重新访问会出现不命中。| 相联度越高，冲突不命中率就越少
  - 方法
    - 1.增加Cache块大小：不命中率先减后增，减少强制性不命中的同时会增加冲突不命中
    - 2.增加Cache容量：会增加成本和命中时间，在片外Cacheh中用的比较多
    - 3.提高相联度：>8的相联度实际意义不大，会增加命中时间
    - 4.伪相联：将Cache分成两部分，以直接映像方式访问第一个部分，若不命中，检查另一个相对应的位置，若匹配，则发生了伪命中，是正常命中时间的2、3倍。| 但多种命中时间会增加流水线的复杂程度，会用在离处理机较远的Cache中
    - 5.硬件预取：指令和数据在处理器访问之前就进行预取，预取内容放入Cache或外部缓冲器中。| 会影响正常不命中的处理
    - 6.编译器控制预取：编译器在程序中加入预取指令实现提前存取，使执行指令和读取数据能重叠进行
    - 7.编译优化：对软件进行优化来降低不命中率
    - 8.牺牲Cache
#### 5.4 减少Cache不命中开销
  - 1.采用两级Cache*：Cache1小而块，Cache2容量大
    - $平均访存时间 = 命中时间_{l1}+不命中率_{l1} * (命中时间_{l2}+不命中率_{l2} * 不命中开销_{l2})$
    - $平均访存停顿时间 = 平均访存时间 - 命中时间_{l1}$
    - $局部不命中率 =\frac{Cache不命中次数}{Cache访存次数}$
    - $全局不命中率 = \frac{Cache不命中次数}{CPU总访存次数}$
    - $全局不命中率_{l2} = 不命中率_{l1} * 不命中率_{l2}$

  - 2.读不命中优先于写
  - 3.写缓冲合并
  - 4.请求字处理技术
  - 5.非阻塞Cache技术
#### 5.5 减少命中时间

#### 5.6 并行主存系统
  - 主存的性能主要由延迟(Cache)和带宽(I/O)来衡量
  - 单体单字存储器：$B_m(带宽) = \frac{W(字长)}{T_m(存储器周期)}$
  - 1.单体多字存储器：$B_m =m* \frac{W}{T_m}$
    - 实现简单，但访存效率不高
  - 2.多体交叉存储器：多个单字存储器构成n(单体存储单元数)xm(存储体个数)个单元
    - 高位交叉编址：对存储单元矩阵按**列**优先的方式进行编址，同一个存储体中高位相同
      - 线性地址：$A = j*n+i$  (i为体内地址，j为存储体号)
    - 低位交叉编址：对存储单元矩阵按**行**优先的方式进行编址，同一个存储体中高位相同
      - 线性地址：$A = i*m+j$
    - 只有低位交叉编址可以有效解决访问冲突问题，可大幅度提升主存的带宽
  - 3.
#### 5.7 虚拟存储器

---
## 第六章  输入输出系统
#### 6.3 RAID
  - RAID分级及其特性(设数据盘为8)
    |rank|容忍故障/检测个数|优点|缺点|应用|
    |:---|:---|:---|:---|:---|
    |0 条带存放|0/0|无空间开销|无纠错能力|广泛应用|
    |1 镜像|1/8|无需CRC校验，读取快，数据恢复快|昂贵，检测空间开销最大|EMC，HP，IBM|
    |2 ECC|1/4|不依靠故障盘进行自诊断|||
    |3 位交叉CRC|1/1|检测空间开销小，大规模读写带宽高|||
    |4 块交叉CRC|1/1||||
    |5 块交叉分布CRC|1/1||||
    |6 P+Q双CRC|2/2||||
  - RAID0：
  - RAID1：对所有磁盘数据提供冗余备份，数据写入时同时写入镜像
  - RAID2：
  - RAID3：
  - RAID4：
  - RAID5：
  - RAID6：
