## Computer Vision for Autonomous Vehicles:Problems, Datasets and State-of-the-Art
è‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„è®¡ç®—æœºè§†è§‰ï¼šé—®é¢˜ï¼Œæ•°æ®å’Œå‰æ²¿æŠ€æœ¯

### 7. Reconstruction å†æ„å»º
- 7.1. Stereo ç«‹ä½“
- Stereo estimation is the process of extracting 3D information from 2D images captured by stereo cameras, without need for special range measurement devices. In particular, stereo algorithms estimate depth information by finding correspondences in two images taken at the same point in time, typically by two cameras mounted next to each other on a fixed rig. These correspondences are projections of the same physical surface in the 3D world. Depth information is crucial for applications in autonomous driving or driver assistance systems. Accurate estimation of dense depth maps is a necessary step for 3D reconstruction, and many other problems such as obstacle detection, free space analysis, and tracking benefit from the availability of depth estimates.
- ç«‹ä½“å£°ä¼°è®¡æ˜¯ä»ç«‹ä½“ç›¸æœºæ‹æ‘„çš„2Då›¾åƒä¸­æå–3Dä¿¡æ¯çš„è¿‡ç¨‹ï¼Œè€Œä¸éœ€è¦ç‰¹æ®Šçš„è·ç¦»æµ‹é‡è£…ç½®ã€‚ ç‰¹åˆ«åœ°ï¼Œç«‹ä½“å£°ç®—æ³•é€šè¿‡åœ¨åŒä¸€æ—¶é—´ç‚¹ä¸Šæ‹æ‘„çš„ä¸¤ä¸ªå›¾åƒä¸­çš„å¯¹åº”å…³ç³»æ¥ä¼°è®¡æ·±åº¦ä¿¡æ¯ï¼Œé€šå¸¸é€šè¿‡åœ¨å›ºå®šçš„é’»æœºä¸Šå½¼æ­¤ç›¸é‚»åœ°å®‰è£…ä¸¤ä¸ªç›¸æœºã€‚ è¿™äº›å¯¹åº”æ˜¯3Dä¸–ç•Œä¸­ç›¸åŒç‰©ç†è¡¨é¢çš„æŠ•å½±ã€‚ æ·±åº¦ä¿¡æ¯å¯¹äºè‡ªä¸»é©¾é©¶æˆ–é©¾é©¶å‘˜è¾…åŠ©ç³»ç»Ÿä¸­çš„åº”ç”¨è‡³å…³é‡è¦ã€‚ ç²¾ç¡®ä¼°è®¡å¯†é›†æ·±åº¦å›¾æ˜¯3Dé‡å»ºçš„å¿…è¦æ­¥éª¤ï¼Œè¯¸å¦‚éšœç¢ç‰©æ£€æµ‹ï¼Œè‡ªç”±ç©ºé—´åˆ†æå’Œè·Ÿè¸ªç­‰è®¸å¤šå…¶ä»–é—®é¢˜å¯ä»æ·±åº¦ä¼°è®¡çš„å¯ç”¨æ€§ä¸­è·ç›Šã€‚

- **Taxonomies**: Multiple taxonomies for stereo matching have been proposed in the literature. Guided by the computational restrictions, the earliest one is based on the density of the output (Franke & Joos (2000)). Feature-based methods provide only sparse depth maps based on edges while area-based methods, such as block matching, generate dense outputs at the expense of computation time. A more recent and commonly referred taxonomy of stereo algorithms is based on the optimization as local and global. Local methods compute the disparity by simply selecting the lowest matching cost which is known as the winner takes all (WTA) solution. Global methods formulate disparity computation as an energy-minimization framework based on the smoothness assumption between neighboring pixels or regions. There are various ways of finding the minimum of a global energy function, including variational approaches in continuous domain and discrete approaches using dynamic programming, Graph Cuts, and Belief Propagation.
- åˆ†ç±»ï¼šæ–‡çŒ®ä¸­å·²ç»æå‡ºäº†ç«‹ä½“åŒ¹é…çš„å¤šé‡åˆ†ç±»æ³•ã€‚åœ¨è®¡ç®—é™åˆ¶çš„åŸºç¡€ä¸Šï¼Œæœ€æ—©çš„æ˜¯åŸºäºè¾“å‡ºå¯†åº¦ï¼ˆFrankeï¼†Joosï¼ˆ2000ï¼‰ï¼‰ã€‚åŸºäºç‰¹å¾çš„æ–¹æ³•ä»…æä¾›åŸºäºè¾¹ç¼˜çš„ç¨€ç–æ·±åº¦å›¾ï¼Œè€ŒåŸºäºåŒºåŸŸçš„æ–¹æ³•ï¼ˆä¾‹å¦‚å—åŒ¹é…ï¼‰ä»¥ç‰ºç‰²è®¡ç®—æ—¶é—´ä¸ºä»£ä»·äº§ç”Ÿå¯†é›†è¾“å‡ºã€‚ç«‹ä½“å£°ç®—æ³•çš„æ›´æ–°å’Œæ™®éå¼•ç”¨çš„åˆ†ç±»æ³•æ˜¯åŸºäºæœ¬åœ°å’Œå…¨å±€çš„ä¼˜åŒ–ã€‚æœ¬åœ°æ–¹æ³•é€šè¿‡ç®€å•åœ°é€‰æ‹©è¢«ç§°ä¸ºè·èƒœè€…è·å¾—æ‰€æœ‰ï¼ˆWTAï¼‰è§£çš„æœ€ä½åŒ¹é…æˆæœ¬æ¥è®¡ç®—å·®å¼‚ã€‚å…¨å±€æ–¹æ³•åŸºäºç›¸é‚»åƒç´ æˆ–åŒºåŸŸä¹‹é—´çš„å¹³æ»‘åº¦å‡è®¾ï¼Œå°†è§†å·®è®¡ç®—ä½œä¸ºèƒ½é‡æœ€å°åŒ–æ¡†æ¶ã€‚æœ‰å„ç§å„æ ·çš„æ–¹æ³•å¯ä»¥æ‰¾åˆ°å…¨å±€èƒ½é‡å‡½æ•°çš„æœ€å°å€¼ï¼ŒåŒ…æ‹¬ä½¿ç”¨åŠ¨æ€è§„åˆ’ï¼Œå›¾è¡¨åˆ‡æ¢å’Œä¿¡å¿µä¼ æ’­çš„è¿ç»­åŸŸå’Œç¦»æ•£æ–¹æ³•çš„å˜åˆ†æ–¹æ³•ã€‚

- Matching Cost Function: Stereo matching is a correspondence problem where the goal is to identify the matching points between left and right image based on a cost function. The algorithms usually assume images are rectified, and the search space is reduced to a horizontal line where the correspondence between a left and right point is encoded by the distance on this line, which is defined as disparity. The matching cost computation is the process of computing a cost function at each pixel for all possible disparities which takes its minimal value at the true disparity. However, it is hard to design such a cost function in practice, therefore stereo algorithms make the assumption of constant appearance between matching points. This assumption is often violated in real-world situations, such as cameras with slightly dierent settings causing exposure changes, vignetting, image noise, non-Lambertian surfaces, illumination changes, etc. HirschmÂ¨uller & Scharstein (2007) call these changes radiometric differences and systematically investigate their effect on commonly used matching cost functions, namely absolute differences, filter-based costs (LoG, Rank and Mean), hierarchical mutual information (HMI), and normalized crosscorrelation. They found that the performance of a cost function depends on the stereo method that uses it. On images with simulated and real radiometric differences, rank filter performed best for correlation-based methods. For global methods, in tests with global radiometric changes or noise, HMI performed best, while in the presence of local radiometric variations, Rank and LoG filters performed better than HMI. Qualitative results show that filter-based cost cause blurred object boundaries when used with global methods. None of the matching costs evaluated could succeed at handling strong lighting changes.
- åŒ¹é…æˆæœ¬å‡½æ•°ï¼šç«‹ä½“åŒ¹é…æ˜¯ä¸€ä¸ªå¯¹åº”é—®é¢˜ï¼Œå…¶ç›®çš„æ˜¯åŸºäºæˆæœ¬å‡½æ•°æ¥è¯†åˆ«å·¦å³å›¾åƒä¹‹é—´çš„åŒ¹é…ç‚¹ã€‚ç®—æ³•é€šå¸¸å‡è®¾å›¾åƒè¢«æ•´æµï¼Œå¹¶ä¸”æœç´¢ç©ºé—´å‡å°‘åˆ°æ°´å¹³çº¿ï¼Œå…¶ä¸­å·¦å’Œå³ç‚¹ä¹‹é—´çš„å¯¹åº”è¢«è¯¥è¡Œä¸Šçš„è·ç¦»ç¼–ç ï¼Œå…¶è¢«å®šä¹‰ä¸ºè§†å·®ã€‚åŒ¹é…æˆæœ¬è®¡ç®—æ˜¯å¯¹äºæ‰€æœ‰å¯èƒ½çš„å·®å¼‚ï¼Œåœ¨æ¯ä¸ªåƒç´ å¤„è®¡ç®—æˆæœ¬å‡½æ•°çš„è¿‡ç¨‹ï¼Œå…¶åœ¨çœŸå®å·®å¼‚ä¸‹é‡‡ç”¨å…¶æœ€å°å€¼ã€‚ç„¶è€Œï¼Œåœ¨å®è·µä¸­å¾ˆéš¾è®¾è®¡è¿™æ ·çš„æˆæœ¬å‡½æ•°ï¼Œå› æ­¤ç«‹ä½“å£°ç®—æ³•ä½¿åŒ¹é…ç‚¹ä¹‹é—´çš„å¤–è§‚ä¸å˜ã€‚è¿™ç§å‡è®¾åœ¨ç°å®ä¸–ç•Œçš„æƒ…å†µä¸‹ç»å¸¸é­åˆ°ä¾µçŠ¯ï¼Œä¾‹å¦‚å…·æœ‰è½»å¾®ä¸åŒè®¾ç½®çš„æ‘„å½±æœºï¼Œä¼šå¼•èµ·æ›å…‰å˜åŒ–ï¼Œæ¸æ™•ï¼Œå›¾åƒå™ªå£°ï¼Œéæœ—ä¼¯è¡¨é¢ï¼Œç…§æ˜å˜åŒ–ç­‰ã€‚HirschmÃ¼llerï¼†Scharsteinï¼ˆ2007ï¼‰ç§°è¿™äº›å˜åŒ–è¾å°„åº¦å·®å¼‚ï¼Œå¹¶ç³»ç»Ÿåœ°ç ”ç©¶å…¶å¯¹å¸¸ç”¨åŒ¹é…æˆæœ¬å‡½æ•°çš„å½±å“ï¼Œå³ç»å¯¹å·®å¼‚ï¼ŒåŸºäºè¿‡æ»¤å™¨çš„æˆæœ¬ï¼ˆLoGï¼ŒRankå’ŒMeanï¼‰ï¼Œåˆ†å±‚äº’ä¿¡æ¯ï¼ˆHMIï¼‰å’Œå½’ä¸€åŒ–äº’ç›¸å…³ã€‚ä»–ä»¬å‘ç°æˆæœ¬å‡½æ•°çš„æ€§èƒ½å–å†³äºä½¿ç”¨å®ƒçš„ç«‹ä½“å£°æ–¹æ³•ã€‚åœ¨å…·æœ‰æ¨¡æ‹Ÿå’Œå®é™…è¾å°„åº¦å·®å¼‚çš„å›¾åƒä¸Šï¼Œç­‰çº§æ»¤æ³¢å™¨å¯¹äºåŸºäºç›¸å…³çš„æ–¹æ³•è¡¨ç°æœ€ä½³ã€‚å¯¹äºå…¨å±€æ–¹æ³•ï¼Œåœ¨å…·æœ‰å…¨å±€è¾å°„åº¦å˜åŒ–æˆ–å™ªå£°çš„æµ‹è¯•ä¸­ï¼ŒHMIæ€§èƒ½æœ€å¥½ï¼Œè€Œåœ¨å­˜åœ¨å±€éƒ¨è¾å°„åº¦å˜åŒ–çš„æƒ…å†µä¸‹ï¼ŒRankå’ŒLoGæ»¤æ³¢å™¨çš„æ€§èƒ½ä¼˜äºHMIã€‚å®šæ€§ç»“æœè¡¨æ˜ï¼Œå½“ä¸å…¨å±€æ–¹æ³•ä¸€èµ·ä½¿ç”¨æ—¶ï¼ŒåŸºäºè¿‡æ»¤å™¨çš„æˆæœ¬å¯¼è‡´å¯¹è±¡è¾¹ç•Œæ¨¡ç³Šã€‚è¯„ä¼°çš„åŒ¹é…æˆæœ¬ä¸­æ²¡æœ‰ä¸€ä¸ªå¯ä»¥æˆåŠŸå¤„ç†å¼ºçƒˆçš„ç…§æ˜å˜åŒ–ã€‚

- **SGM**: Semi-Global Matching (SGM) (HirschmÂ¨uller (2008)) has become very influential due to its speed and high accuracy as evidenced in various benchmarks such as Middlebury (Scharstein & Szeliski (2002)) or KITTI (Geiger et al. (2012b)). SGM is also recently used on top of CNN features, since simply outputting the most likely configuration for every pixel is not competitive with modern stereo algorithms (Zbontar & LeCun (2016); Luo et al. (2016)). The energy function has two levels of penalization for small and large disparity differences with a weighting based on the local intensity gradient for the latter one. The energy is calculated by summing costs along 1D paths from multiple directions towards each pixel using dynamic programming and the result is determined by WTA. There are a couple of follow-up works investigating the practical and theoretical sides of SGM. Gehrig et al. (2009) propose a real-time, low-power implementation of the SGM with algorithmic extensions for automotive applications on a reconfigurable hardware platform. Drory et al. (2014) offer a principled explanation for the success of SGM by clarifying its relation to belief propagation and tree-reweighted message passing with an uncertainty measure as an outcome.
- The performance of SGMs can be further improved by incorporating confidences of the stereo estimation. Seki & Pollefeys (2016) leverage CNNs to predict the confidences for stereo estimations. Taking into account ideas from conventional confidences features, that neighboring pixel which are consistent are more likely to be correct and the disparity estimated from the other image should correspond, they design a two-channel disparity patch which is used as input for the CNN. In order to acquire dense disparity, the confidences are incorporated into SGM by weighting each pixel according to the estimated confidence.
- SGMï¼šåŠå…¨çƒé…å¯¹ï¼ˆHirschmullerï¼ˆ2008ï¼‰ï¼‰ç”±äºå…¶é€Ÿåº¦å’Œå‡†ç¡®æ€§è€Œå˜å¾—éå¸¸æœ‰å½±å“åŠ›ï¼Œå¦‚ç±³å¾·ä¼¯å‹’ï¼ˆScharsteinï¼†Szeliskiï¼ˆ2002ï¼‰ï¼‰æˆ–KITTIï¼ˆGeiger ï¼ˆ2012bï¼‰ï¼‰ã€‚ SGMä¹Ÿæœ€è¿‘è¢«ç”¨äºCNNåŠŸèƒ½ä¹‹ä¸Šï¼Œå› ä¸ºç®€å•åœ°è¾“å‡ºæ¯ä¸ªåƒç´ çš„æœ€å¯èƒ½çš„é…ç½®ä¸ç°ä»£ç«‹ä½“å£°ç®—æ³•ï¼ˆZbontarï¼†LeCunï¼ˆ2016ï¼‰; Luoç­‰ï¼ˆ2016ï¼‰ï¼‰ä¸å…·æœ‰ç«äº‰åŠ›ã€‚èƒ½é‡å‡½æ•°å¯¹äºå°å’Œå¤§çš„å·®å¼‚å·®å¼‚å…·æœ‰ä¸¤ä¸ªçº§åˆ«çš„æƒ©ç½šï¼ŒåŸºäºå¯¹åè€…çš„å±€éƒ¨å¼ºåº¦æ¢¯åº¦çš„åŠ æƒã€‚é€šè¿‡ä½¿ç”¨åŠ¨æ€è§„åˆ’å°†æ¥è‡ªå¤šä¸ªæ–¹å‘çš„1Dè·¯å¾„çš„æˆæœ¬ä¸æ¯ä¸ªåƒç´ ç›¸åŠ æ¥è®¡ç®—èƒ½é‡ï¼Œå¹¶ä¸”ç»“æœç”±WTAç¡®å®šã€‚æœ‰å‡ é¡¹åç»­å·¥ä½œè°ƒæŸ¥äº†ä¸Šæµ·è¯åˆ¸äº¤æ˜“æ‰€çš„å®é™…å’Œç†è®ºæ–¹é¢ã€‚ Gehrigç­‰äººï¼ˆ2009ï¼‰æå‡ºäº†åœ¨å¯é‡é…ç½®ç¡¬ä»¶å¹³å°ä¸Šå®ç°æ±½è½¦åº”ç”¨çš„ç®—æ³•æ‰©å±•çš„SGMçš„å®æ—¶ä½åŠŸè€—å®ç°ã€‚ Droryç­‰ï¼ˆ2014å¹´ï¼‰é€šè¿‡æ¾„æ¸…å…¶ä¸ä¿¡ä»°ä¼ æ’­çš„å…³ç³»å’Œæ ‘é‡åŠ æƒçš„æ¶ˆæ¯ä¼ é€’ä»¥ä¸ç¡®å®šæ€§åº¦é‡ä½œä¸ºç»“æœï¼Œä¸ºSGMçš„æˆåŠŸæä¾›äº†åŸåˆ™æ€§çš„è§£é‡Šã€‚
- é€šè¿‡å¼•å…¥ç«‹ä½“å£°ä¼°è®¡çš„ä¿¡å¿ƒï¼Œå¯ä»¥è¿›ä¸€æ­¥æé«˜SGMçš„æ€§èƒ½ã€‚ Sekiï¼†Pollefeysï¼ˆ2016ï¼‰åˆ©ç”¨CNNæ¥é¢„æµ‹ç«‹ä½“å£°ä¼°è®¡çš„ä¿¡å¿ƒã€‚è€ƒè™‘åˆ°å¸¸è§„ä¿¡å·ç‰¹å¾çš„æƒ³æ³•ï¼Œä¸€è‡´çš„ç›¸é‚»åƒç´ æ›´å¯èƒ½æ˜¯æ­£ç¡®çš„ï¼Œå¹¶ä¸”ä»å¦ä¸€ä¸ªå›¾åƒä¼°è®¡çš„è§†å·®åº”è¯¥å¯¹åº”ï¼Œå®ƒä»¬è®¾è®¡ä¸€ä¸ªåŒé€šé“è§†å·®è¡¥ä¸ï¼Œç”¨ä½œCNNçš„è¾“å…¥ã€‚ä¸ºäº†è·å¾—å¯†é›†çš„å·®å¼‚ï¼Œé€šè¿‡æ ¹æ®ä¼°è®¡çš„ç½®ä¿¡åº¦å¯¹æ¯ä¸ªåƒç´ è¿›è¡ŒåŠ æƒï¼Œå°†ä¿¡æ¯å¹¶å…¥SGMã€‚

- **Variable Baseline/Resolution**: Stereo estimates can be fused to yield a more complete reconstruction of the static parts of the three-dimensional scene. However, assuming fixed baseline, focal length, field of view might not always be the best strategy. Gallup et al. (2008) point out two problems with traditional stereo methods: dropping accuracy in the far range and unnecessary computation time spent in the near range. Given that choice of views for stereo is quite flexible in many applications such as structure from motion, Gallup et al. (2008) propose to dynamically select the best cameras with the appropriate baseline for accurate estimation in the far range from a set of possible cameras recording images at the same time. Further, they reduce the resolution to speed up the computation in the near range. In contrast to traditional fixed-baseline stereo, the proposed variable baseline/resolution stereo algorithm achieves constant accuracy over the reconstructed volume by evenly spreading the computation throughout the volume.
- **Planarity**: The inherent ambiguity in appearance based matching costs can be overcome by regularization, i.e., by introducing prior knowledge about the expected disparity map into the stereo estimation process. The simplest prior favors neighboring pixels to take on the same disparity value. However, such generic smoothness priors fail to reconstruct poorly-textured and slanted surfaces, as they favor fronto-parallel planes. A more generic approach to handle arbitrary smoothness priors is using higher-order connections beyond pairwise. Higherorder priors are able to express more realistic assumptions about depth images, but usually at additional computational cost. One very common way to deal with slanted surfaces in the literature is to assume piecewise planarity. Geiger et al. (2010) build a prior over the disparity space by forming a triangulation on a set of robustly matched correspondences, called support points. This reduces matching ambiguities and results in an efficient algorithm by restricting the search to plausible regions. Gallup et al. (2010) first train a classifier to segment an image into piecewise planar and non-planar regions and then enforce a piecewise planarity prior only for planar regions. Non-planar regions are modeled by the output of a standard multi-view stereo algorithm.
- å¯å˜åŸºå‡†/åˆ†è¾¨ç‡ï¼šå¯ä»¥èåˆç«‹ä½“å£°ä¼°è®¡ï¼Œä»¥äº§ç”Ÿä¸‰ç»´åœºæ™¯çš„é™æ€éƒ¨åˆ†çš„æ›´å®Œæ•´çš„é‡å»ºã€‚ç„¶è€Œï¼Œå‡è®¾å›ºå®šåŸºçº¿ï¼Œç„¦è·ï¼Œè§†é‡å¯èƒ½ä¸æ€»æ˜¯æœ€å¥½çš„ç­–ç•¥ã€‚ç›–æ´›æ™®ç­‰äººï¼ˆ2008ï¼‰æŒ‡å‡ºäº†ä¼ ç»Ÿç«‹ä½“å£°æ–¹æ³•çš„ä¸¤ä¸ªé—®é¢˜ï¼šåœ¨è¿œç¨‹èŒƒå›´å†…é™ä½ç²¾åº¦ï¼Œåœ¨è¿‘è·ç¦»å†…æ¶ˆè€—ä¸å¿…è¦çš„è®¡ç®—æ—¶é—´ã€‚é‰´äºç«‹ä½“å£°çš„é€‰æ‹©åœ¨è®¸å¤šåº”ç”¨ä¸­æ˜¯éå¸¸çµæ´»çš„ï¼Œä¾‹å¦‚æ¥è‡ªè¿åŠ¨çš„ç»“æ„ï¼ŒGallupç­‰äººï¼ˆ2008ï¼‰æå‡ºåŠ¨æ€é€‰æ‹©å…·æœ‰é€‚å½“åŸºå‡†çš„æœ€ä½³ç›¸æœºï¼Œä»¥ä¾¿åœ¨è¿œè·ç¦»èŒƒå›´å†…è¿›è¡Œç²¾ç¡®ä¼°è®¡ï¼Œä»ä¸€ç»„å¯èƒ½çš„æ‘„åƒæœºåŒæ—¶è®°å½•å›¾åƒã€‚æ­¤å¤–ï¼Œå®ƒä»¬é™ä½äº†åˆ†è¾¨ç‡ï¼Œä»¥åŠ é€Ÿè¿‘ä¼¼èŒƒå›´å†…çš„è®¡ç®—ã€‚ä¸ä¼ ç»Ÿçš„å›ºå®šåŸºçº¿ç«‹ä½“å£°ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„å¯å˜åŸºçº¿/åˆ†è¾¨ç‡ç«‹ä½“å£°ç®—æ³•é€šè¿‡åœ¨æ•´ä¸ªéŸ³é‡ä¸Šå‡åŒ€åœ°å±•å¼€è®¡ç®—ï¼Œåœ¨é‡å»ºä½“ç§¯ä¸Šå®ç°äº†æ’å®šçš„ç²¾åº¦ã€‚
- å¹³é¢ï¼šåŸºäºå¤–è§‚çš„åŒ¹é…æˆæœ¬çš„å›ºæœ‰æ­§ä¹‰å¯ä»¥é€šè¿‡æ­£åˆ™åŒ–æ¥å…‹æœï¼Œå³é€šè¿‡å°†å…³äºé¢„æœŸè§†å·®å›¾çš„å…ˆå‰çŸ¥è¯†å¼•å…¥åˆ°ç«‹ä½“å£°ä¼°è®¡è¿‡ç¨‹ä¸­ã€‚æœ€ç®€å•çš„å…ˆå‰æœ‰åˆ©äºç›¸é‚»åƒç´ å…·æœ‰ç›¸åŒçš„å·®å¼‚å€¼ã€‚ç„¶è€Œï¼Œè¿™ç§é€šç”¨å¹³æ»‘åº¦å…ˆéªŒä¸èƒ½é‡æ„ä¸è‰¯çº¹ç†å’Œå€¾æ–œçš„è¡¨é¢ï¼Œå› ä¸ºå®ƒä»¬æœ‰åˆ©äºå‰å¹³è¡Œå¹³é¢ã€‚å¤„ç†ä»»æ„å¹³æ»‘å…ˆéªŒçš„æ›´é€šç”¨çš„æ–¹æ³•æ˜¯ä½¿ç”¨æˆå¯¹ä»¥å¤–çš„é«˜é˜¶è¿æ¥ã€‚é«˜é˜¶å…ˆéªŒèƒ½å¤Ÿå¯¹æ·±åº¦å›¾åƒè¡¨è¾¾æ›´çœŸå®çš„å‡è®¾ï¼Œä½†é€šå¸¸ä»¥é¢å¤–çš„è®¡ç®—æˆæœ¬ã€‚åœ¨æ–‡çŒ®ä¸­å¤„ç†å€¾æ–œè¡¨é¢çš„ä¸€ä¸ªå¾ˆå¸¸è§çš„æ–¹æ³•æ˜¯å‡è®¾åˆ†æ®µå¹³é¢ã€‚ç›–é©ç­‰äººï¼ˆ2010ï¼‰é€šè¿‡åœ¨ç§°ä¸ºæ”¯æŒç‚¹çš„ä¸€ç»„é²æ£’åŒ¹é…çš„å¯¹åº”ä¸Šå½¢æˆä¸‰è§’æµ‹é‡æ¥æ„å»ºå·®å¼‚ç©ºé—´çš„å‰ä¸€ä¸ªã€‚è¿™å‡å°‘äº†åŒ¹é…æ¨¡ç³Šåº¦ï¼Œå¹¶é€šè¿‡å°†æœç´¢é™åˆ¶åˆ°åˆç†çš„åŒºåŸŸæ¥äº§ç”Ÿæœ‰æ•ˆçš„ç®—æ³•ã€‚ç›–æ´›æ™®ç­‰äººï¼ˆ2010ï¼‰é¦–å…ˆè®­ç»ƒåˆ†ç±»å™¨å°†å›¾åƒåˆ†å‰²æˆåˆ†æ®µå¹³é¢å’Œéå¹³é¢åŒºåŸŸï¼Œç„¶åä»…åœ¨å¹³é¢åŒºåŸŸä¹‹å‰å®æ–½åˆ†æ®µå¹³é¢åº¦ã€‚éå¹³é¢åŒºåŸŸç”±æ ‡å‡†å¤šè§†ç‚¹ç«‹ä½“å£°ç®—æ³•çš„è¾“å‡ºå»ºæ¨¡ã€‚

- **Variational Approaches**: Similarly, in variational approaches, commonly used smoothness prior, Total Variation (TV) does not produce convincing results in the presence of weak and ambiguous observations, since it encourages piecewise constant regions leading to stair-casing artifacts. Haene et al. (2012) introduce patch-based priors into a TV framework in the form of small, piecewise planar dictionaries. Total Generalized Variation (TGV) (Bredies et al. (2010)) is argued to be a better prior than TV, since it does not penalize piecewise affine solutions. However, it is restricted to convex data terms in contrast to TV, where global solutions can be computed even in the presence of non-convex data terms. Coarse-to-fine approaches as an approximation to non-convex problem of stereo matching often end up with loss of details. To preserve fine details, Kuschk & Cremers (2013) integrate an adaptive regularization weight into the TGV framework by using edge detection and report improved results compared to a coarse-to-fine approach. Ranftl et al. (2013) obtain even better results by proposing a decomposition of the non-convex functional into two subproblems which can be solved globally where one is convex, and the other can be made convex by lifting the functional to a higher dimensional space.
- **State-of-the-art**: In Table 6 we show the ranking of stereo methods on the KITTI stereo 2015 benchmark. The KITTI benchmark reports the percentage of erroneous (bad) pixels over background regions (D1-bg), foreground regions (D1-fg) and over all regions (D1-all). The best performing method GÂ¨uney & Geiger (2015) use object knowledge to compensate for the weak data term on the reflecting and textureless surfaces. Seki &Pollefeys (2016) achieve the best performance on background regions with the prediction of stereo correspondence confidences and integration into SGM. Recently, deep learning approaches (Zbontar&LeCun (2016); Luo et al. (2016); Mayer et al. (2016)) were proposed achieving state-of-the-art performance. The deep learning approach presented by Mayer et al. (2016) is one of the fastest approaches.
- å˜å¼‚æ–¹æ³•ï¼šç±»ä¼¼åœ°ï¼Œåœ¨å˜åˆ†æ–¹æ³•ä¸­ï¼Œæ™®éä½¿ç”¨çš„å¹³æ»‘åº¦ä¹‹å‰ï¼Œæ€»å˜å¼‚ï¼ˆTVï¼‰ä¸ä¼šäº§ç”Ÿä»¤äººä¿¡æœçš„ç»“æœå­˜åœ¨å¼±å’Œæ¨¡ç³Šçš„è§‚å¯Ÿï¼Œå› ä¸ºå®ƒé¼“åŠ±åˆ†æ®µæ’å®šåŒºåŸŸå¯¼è‡´æ¥¼æ¢¯å¥—ç®¡ä¼ªå½±ã€‚ Haeneç­‰äººï¼ˆ2012ï¼‰å°†è¡¥ä¸ä¸ºåŸºç¡€çš„å…ˆéªŒå¼•å…¥ç”µè§†æ¡†æ¶ï¼Œå½¢å¼ä¸ºå°å‹ï¼Œåˆ†æ®µå¹³é¢å­—å…¸ã€‚æ€»å¹¿ä¹‰å˜å¼‚ï¼ˆTGVï¼‰ï¼ˆBrediesç­‰äººï¼ˆ2010ï¼‰ï¼‰è¢«è®¤ä¸ºæ¯”ç”µè§†æ›´å¥½ï¼Œå› ä¸ºå®ƒä¸æƒ©ç½šåˆ†æ®µä»¿å°„è§£å†³æ–¹æ¡ˆã€‚ç„¶è€Œï¼Œä¸TVç›¸åï¼Œå®ƒä»…é™äºå‡¸æ•°æ®é¡¹ï¼Œå³ä½¿åœ¨å­˜åœ¨éå‡¸æ•°æ®é¡¹çš„æƒ…å†µä¸‹ï¼Œä¹Ÿå¯ä»¥è®¡ç®—å…¨å±€è§£ã€‚ç²—ç•¥åˆ°ç²¾ç»†çš„æ–¹æ³•ä½œä¸ºç«‹ä½“åŒ¹é…çš„éå‡¸é—®é¢˜çš„è¿‘ä¼¼é€šå¸¸æœ€ç»ˆå¯¼è‡´ç»†èŠ‚çš„æŸå¤±ã€‚ä¸ºäº†ä¿æŒç»†èŠ‚ï¼ŒKuschkï¼†Cremersï¼ˆ2013ï¼‰é€šè¿‡ä½¿ç”¨è¾¹ç¼˜æ£€æµ‹å°†è‡ªé€‚åº”æ­£åˆ™åŒ–æƒé‡æ•´åˆåˆ°TGVæ¡†æ¶ä¸­ï¼Œå¹¶æŠ¥å‘Šä¸ç²—ç•¥åˆ°ç²—ç•¥æ–¹æ³•ç›¸æ¯”çš„æ”¹è¿›ç»“æœã€‚ Ranftlç­‰äººï¼ˆ2013ï¼‰é€šè¿‡æå‡ºå°†éå‡¸å‡½æ•°åˆ†è§£æˆä¸¤ä¸ªå­é—®é¢˜æ¥è·å¾—æ›´å¥½çš„ç»“æœï¼Œè¿™ä¸¤ä¸ªå­é—®é¢˜å¯ä»¥åœ¨ä¸€ä¸ªå‡¸èµ·çš„æƒ…å†µä¸‹è¢«å…¨å±€æ±‚è§£ï¼Œå¦ä¸€ä¸ªå¯ä»¥é€šè¿‡å°†åŠŸèƒ½æå‡åˆ°æ›´é«˜ç»´åº¦çš„ç©ºé—´æ¥åˆ¶ä½œå‡¸èµ·ã€‚
- æœ€å…ˆè¿›çš„ï¼šåœ¨è¡¨6ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†KITTIç«‹ä½“å£°2015åŸºå‡†çš„ç«‹ä½“å£°æ–¹æ³•çš„æ’åã€‚ KITTIåŸºå‡†æµ‹è¯•æŠ¥å‘Šäº†èƒŒæ™¯åŒºåŸŸï¼ˆD1-bgï¼‰ï¼Œå‰æ™¯åŒºåŸŸï¼ˆD1-fgï¼‰å’Œæ‰€æœ‰åŒºåŸŸï¼ˆD1-allï¼‰ä¹‹é—´çš„é”™è¯¯ï¼ˆå·®ï¼‰åƒç´ çš„ç™¾åˆ†æ¯”ã€‚æœ€å¥½çš„è¡¨ç°æ–¹æ³•GÂ¨uneyï¼†Geigerï¼ˆ2015ï¼‰ä½¿ç”¨å¯¹è±¡çŸ¥è¯†æ¥è¡¥å¿åå°„å’Œæ— çº¹ç†è¡¨é¢ä¸Šçš„å¼±æ•°æ®é¡¹ã€‚ Sekiï¼†Pollefeysï¼ˆ2016ï¼‰åœ¨èƒŒæ™¯åŒºåŸŸå®ç°äº†æœ€ä½³æ€§èƒ½ï¼Œé¢„æµ‹äº†ç«‹ä½“å£°é€šä¿¡çš„ä¿¡å¿ƒå¹¶èå…¥äº†SGMã€‚æœ€è¿‘ï¼Œæå‡ºäº†æ·±å…¥å­¦ä¹ çš„æ–¹æ³•ï¼ˆZbontarï¼†LeCunï¼ˆ2016ï¼‰; Luoç­‰ï¼ˆ2016ï¼‰; Mayerç­‰ï¼ˆ2016ï¼‰ï¼‰æå‡ºäº†æœ€å…ˆè¿›çš„è¡¨ç°ã€‚ Mayerç­‰äººæå‡ºçš„æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ˆ2016ï¼‰æ˜¯æœ€å¿«æ·çš„æ–¹æ³•ä¹‹ä¸€ã€‚

- **Superpixels**: An alternative way of modeling piecewise planarity is to explicitly partition the image into superpixels and modeling the surface at each superpixel as a slanted plane (Yamaguchi et al. (2012); GÂ¨uney & Geiger (2015)). However, care must be taken that the super-pixelization is indeed an over-segmentation of the image with respect to planarity, i.e., that no superpixel contains two surfaces which are not co-planar. Yamaguchi et al. (2012) jointly reason about occlusion boundaries and depth in a hybrid MRF composed of both continuous and discrete random variables. Guney & Geiger (2015) use a similar framework to incorporate object-category specific 3D shape proposals which regularize over larger distances. By leveraging semantic segmentation and 3D CAD models, they resolve ambiguities in reflective and textureless regions originating from highly specular surface of cars in the scene as shown in Figure 19.
- **Deep Learning**: In the last years, deep learning approaches (Mayer et al. (2016); Zbontar&LeCun (2016); Luo et al. (2016)) gained popularity in stereo estimation. Mayer et al. (2016) adapt the encoder-decoder architecture proposed by Dosovitskiy et al. (2015) that was used for optical flow estimation (see Section 8.1). The encoder computes abstract features while the decoder reestablishes the original resolution with additional crosslinks between the contracting and expanding network parts. In contrast to the encoder-decoder architecture, Ë‡ Zbontar & LeCun (2016); Luo et al. (2016) use Siamese network which consists of two sub-networks with shared weights and a final score computation layer. The idea is to train the network for computing the matching cost by learning a similarity measure on small image patches. Zbontar & LeCun (2016) define positive/negative examples as matching and non-matching patches and use a margin loss to train either a fast architecture with a simple dot-product layer in the end or a slow but more accurate architecture which learns score computation with a set of fully connected layers. Luo et al. (2016) use a similar architecture, but formulate the problem as multi-class classification over all possible disparities to capture correlations between different disparities implicitly as visualized in Figure 20.
- è¶…åƒç´ ï¼šåˆ†æ®µå¹³é¢å»ºæ¨¡çš„å¦ä¸€ç§æ–¹æ³•æ˜¯å°†å›¾åƒæ˜ç¡®åœ°åˆ’åˆ†ä¸ºè¶…åƒç´ ï¼Œå¹¶å°†æ¯ä¸ªè¶…åƒç´ çš„è¡¨é¢ä½œä¸ºå€¾æ–œå¹³é¢è¿›è¡Œå»ºæ¨¡ï¼ˆYamaguchi et alã€‚ï¼ˆ2012ï¼‰;GÂ¨uneyï¼†Geigerï¼ˆ2015ï¼‰ï¼‰ ã€‚ç„¶è€Œï¼Œå¿…é¡»æ³¨æ„ï¼Œè¶…åƒç´ åŒ–ç¡®å®æ˜¯ç›¸å¯¹äºå¹³é¢åº¦çš„å›¾åƒçš„è¿‡åº¦åˆ†å‰²ï¼Œå³ï¼Œæ²¡æœ‰è¶…åƒç´ åŒ…å«ä¸å…±é¢çš„ä¸¤ä¸ªè¡¨é¢ã€‚å±±å£ç­‰ï¼ˆ2012ï¼‰å…±åŒç†è§£äº†ç”±è¿ç»­å’Œç¦»æ•£éšæœºå˜é‡ç»„æˆçš„æ··åˆMRFä¸­çš„é—­å¡è¾¹ç•Œå’Œæ·±åº¦ã€‚ Guneyï¼†Geigerï¼ˆ2015ï¼‰ä½¿ç”¨ç±»ä¼¼çš„æ¡†æ¶æ¥æ•´åˆåœ¨æ›´å¤§è·ç¦»ä¸Šè§„åˆ™åŒ–çš„å¯¹è±¡â€‹â€‹ç±»ç‰¹å®š3Då½¢çŠ¶ææ¡ˆã€‚é€šè¿‡åˆ©ç”¨è¯­ä¹‰åˆ†å‰²å’Œ3D CADæ¨¡å‹ï¼Œå®ƒä»¬è§£å†³äº†æºè‡ªç°åœºæ±½è½¦é«˜åº¦é•œé¢çš„åå°„å’Œæ— çº¹ç†åŒºåŸŸçš„æ¨¡ç³Šæ€§ï¼Œå¦‚å›¾19æ‰€ç¤ºã€‚
- æ·±åº¦å­¦ä¹ ï¼šåœ¨è¿‡å»å‡ å¹´ä¸­ï¼Œæ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ˆMayerç­‰ï¼ˆ2016ï¼‰; Zbontarï¼†LeCunï¼ˆ2016ï¼‰; Luoç­‰ï¼ˆ2016ï¼‰ï¼‰åœ¨ç«‹ä½“å£°ä¼°è®¡ä¸­å¾—åˆ°æ™®åŠã€‚ Mayerç­‰äººï¼ˆ2016ï¼‰é€‚åº”Dosovitskiyç­‰äººæå‡ºçš„ç¼–ç å™¨ - è§£ç å™¨æ¶æ„ã€‚ ï¼ˆ2015å¹´ï¼‰ï¼Œç”¨äºå…‰æµä¼°è®¡ï¼ˆè§ç¬¬8.1èŠ‚ï¼‰ã€‚ç¼–ç å™¨è®¡ç®—æŠ½è±¡ç‰¹å¾ï¼Œè€Œè§£ç å™¨é‡æ–°å»ºç«‹åŸå§‹åˆ†è¾¨ç‡ï¼Œå¹¶åœ¨åˆåŒå’Œæ‰©å±•ç½‘ç»œéƒ¨åˆ†ä¹‹é—´é™„åŠ äº¤å‰é“¾æ¥ã€‚ä¸ç¼–ç å™¨ - è§£ç å™¨æ¶æ„ç›¸æ¯”ï¼ŒZbontarï¼†LeCunï¼ˆ2016ï¼‰;ç½—ç­‰äººï¼ˆ2016ï¼‰ä½¿ç”¨ç”±å…·æœ‰å…±äº«æƒé‡çš„ä¸¤ä¸ªå­ç½‘ç»œå’Œæœ€ç»ˆåˆ†æ•°è®¡ç®—å±‚ç»„æˆçš„æš¹ç½—ç½‘ç»œã€‚è¿™ä¸ªæƒ³æ³•æ˜¯é€šè¿‡å­¦ä¹ å°å›¾åƒè¡¥ä¸çš„ç›¸ä¼¼æ€§åº¦é‡æ¥è®­ç»ƒç½‘ç»œæ¥è®¡ç®—åŒ¹é…æˆæœ¬ã€‚ Zbontarï¼†LeCunï¼ˆ2016ï¼‰å°†æ­£/è´Ÿçš„ä¾‹å­å®šä¹‰ä¸ºåŒ¹é…å’ŒéåŒ¹é…è¡¥ä¸ï¼Œå¹¶ä½¿ç”¨è¾¹é™…æŸå¤±æ¥è®­ç»ƒæœ€ç»ˆçš„ç®€å•ç‚¹é˜µäº§å“å±‚çš„å¿«é€Ÿæ¶æ„ï¼Œæˆ–è€…å­¦ä¹ åˆ†æ•°è®¡ç®—çš„æ…¢ä½†æ›´å‡†ç¡®çš„æ¶æ„ä¸ä¸€å¥—å®Œå…¨è¿æ¥çš„å±‚ã€‚ç½—ç­‰äººï¼ˆ2016ï¼‰ä½¿ç”¨äº†ç±»ä¼¼çš„æ¶æ„ï¼Œä½†æ˜¯å°†æ‰€æœ‰å¯èƒ½çš„å·®å¼‚ä½œä¸ºå¤šç±»åˆ«åˆ†ç±»æ¥å½¢æˆé—®é¢˜ï¼Œä»¥ä¾¿åœ¨å›¾20ä¸­éšå«åœ°éšè—ä¸åŒå·®å¼‚ä¹‹é—´çš„ç›¸å…³æ€§ã€‚


- Discussion: Stereo estimation has shown great progress in the last years both in terms of accuracy and efficiency. However, some inherent problems refrain it from being marked as solved. Stereo matching is ultimately searching for correspondences in two images based on the assumption of constant appearance. However, appearance frequently changes by cues different than geometry, furthermore occluded regions or pixels leaving the frame cannot be matched. Therefore, failure in those cases is inevitable for methods that solely rely on appearance matching without any other prior assumptions about the geometry. We show accumulated errors of top 15 methods on KITTI stereo benchmark Geiger et al. (2012b) in Figure 21. The most common example of failure case in the autonomous driving context are car surfaces due to shiny and reflective regions. GÂ¨uney & Geiger (2015) specifically address this problem by integrating prior knowledge on possible car shapes. Similarly, windows that are reflective and transparent cannot be matched reliably. As concluded by HirschmÂ¨uller & Scharstein (2007), strong illumination changes constitute another common source of error such as inside a tunnel or over-exposure on road surfaces. Pixels leaving the frame and occlusions often cause errors for many methods and both require reasoning beyond matching and local interactions. Other specific examples of problematic regions include thin structures like traffic signs, or repetitive ones like fences.
- è®¨è®ºï¼šç«‹ä½“å£°ä¼°è®¡åœ¨è¿‡å»å‡ å¹´ä¸­åœ¨ç²¾åº¦å’Œæ•ˆç‡æ–¹é¢éƒ½å–å¾—äº†å¾ˆå¤§è¿›å±•ã€‚ç„¶è€Œï¼Œä¸€äº›å›ºæœ‰çš„é—®é¢˜é¿å…è¢«æ ‡è®°ä¸ºè§£å†³ã€‚åŸºäºæ’å®šå¤–è§‚çš„å‡è®¾ï¼Œç«‹ä½“åŒ¹é…æœ€ç»ˆæœç´¢ä¸¤ä¸ªå›¾åƒä¸­çš„å¯¹åº”å…³ç³»ã€‚ç„¶è€Œï¼Œå¤–è§‚é€šå¸¸ç”±ä¸å‡ ä½•ä¸åŒçš„çº¿ç´¢æ”¹å˜ï¼Œè€Œç¦»å¼€æ¡†æ¶çš„é®æŒ¡åŒºåŸŸæˆ–åƒç´ ä¹Ÿä¸èƒ½åŒ¹é…ã€‚å› æ­¤ï¼Œåœ¨è¿™äº›æƒ…å†µä¸‹çš„å¤±è´¥å¯¹äºä»…ä¾èµ–äºå¤–è§‚åŒ¹é…çš„æ–¹æ³•æ¥è¯´æ˜¯ä¸å¯é¿å…çš„ï¼Œè€Œå¯¹äºå‡ ä½•å½¢çŠ¶æ²¡æœ‰ä»»ä½•å…¶ä»–å…ˆå‰çš„å‡è®¾ã€‚æˆ‘ä»¬åœ¨KITTIç«‹ä½“å£°åŸºå‡†Geigerç­‰äººæ˜¾ç¤ºäº†å‰15ç§æ–¹æ³•çš„ç´¯ç§¯è¯¯å·®ã€‚ ï¼ˆ2012bï¼‰ã€‚è‡ªä¸»é©¾é©¶ç¯å¢ƒä¸­æ•…éšœæ¡ˆä¾‹çš„æœ€å¸¸è§ä¾‹å­æ˜¯æ±½è½¦è¡¨é¢ï¼Œç”±äºå…‰çº¿å’Œåå°„åŒºåŸŸã€‚ GÂ¨uneyï¼†Geigerï¼ˆ2015ï¼‰ä¸“é—¨é’ˆå¯¹è¿™ä¸ªé—®é¢˜ï¼Œæ•´åˆäº†å¯èƒ½çš„æ±½è½¦å½¢çŠ¶çš„å…ˆå‰çš„çŸ¥è¯†ã€‚ç±»ä¼¼åœ°ï¼Œåå°„å’Œé€æ˜çš„çª—å£ä¸èƒ½å¯é åœ°åŒ¹é…ã€‚å¦‚Hirschmullerï¼†Scharsteinï¼ˆ2007ï¼‰æ‰€åšçš„é‚£æ ·ï¼Œå¼ºçƒˆçš„ç…§æ˜å˜åŒ–æ„æˆäº†éš§é“å†…çš„å¦ä¸€ä¸ªå¸¸è§çš„é”™è¯¯æ¥æºï¼Œæˆ–è€…åœ¨è·¯é¢ä¸Šè¿‡åº¦æ›å…‰ã€‚ç¦»å¼€å¸§å’Œé®æŒ¡çš„åƒç´ é€šå¸¸ä¼šå¯¼è‡´è®¸å¤šæ–¹æ³•çš„é”™è¯¯ï¼Œå¹¶ä¸”éƒ½éœ€è¦è¶…å‡ºåŒ¹é…å’Œæœ¬åœ°äº¤äº’çš„æ¨ç†ã€‚æœ‰é—®é¢˜çš„åœ°åŒºçš„å…¶ä»–å…·ä½“ä¾‹å­åŒ…æ‹¬åƒäº¤é€šæ ‡å¿—è¿™æ ·çš„è–„ç»“æ„ï¼Œæˆ–åƒæ …æ è¿™æ ·çš„é‡å¤çš„ç»“æ„ã€‚

- 7.2. Multi-view 3D Reconstruction å¤šè§†è§’3Dé‡æ„
- The goal of multi-view 3D reconstruction is to model the underlying 3D geometry by inverting the image formation process often under certain prior or smoothness assumptions. In contrast to two-view stereo, multi-view reconstruction algorithms in particular address the problems of varying viewpoints and the complete reconstruction of 3D scenes from more than two and potentially a very large number of images. If the camera parameters are known, solving for the 3D geometry of the scene is equivalent to solving the correspondence problem, based on a photo-consistency function which measures the agreement between different viewpoints.
- Taxonomies: Several categorizations of multi-view reconstruction algorithms have been proposed in the literature, typically considering the form of the photo-consistency function, the scene representation, visibility computation, priors, and initialization requirements as in Seitz et al. (2006). From an application perspective, the scene representation is a common way of classifying multi-view reconstruction approaches into depth map, point cloud, mesh, and volumetric.
- å¤šè§†å›¾3Dé‡å»ºçš„ç›®æ ‡æ˜¯é€šè¿‡åœ¨æŸäº›å…ˆå‰æˆ–å¹³æ»‘å‡è®¾ä¸‹ç»å¸¸åè½¬å›¾åƒå½¢æˆè¿‡ç¨‹æ¥å¯¹åº•å±‚3Då‡ ä½•è¿›è¡Œå»ºæ¨¡ã€‚ä¸åŒè§†å›¾ç«‹ä½“å£°ç›¸æ¯”ï¼Œå¤šè§†å›¾é‡å»ºç®—æ³•ç‰¹åˆ«è§£å†³äº†æ¥è‡ªä¸¤ä¸ªä»¥ä¸Šä¸”æ½œåœ¨çš„å¤§é‡å›¾åƒçš„å˜åŒ–è§†ç‚¹å’Œ3Dåœºæ™¯çš„å®Œæ•´é‡å»ºçš„é—®é¢˜ã€‚å¦‚æœç›¸æœºå‚æ•°æ˜¯å·²çŸ¥çš„ï¼Œåˆ™è§£å†³åœºæ™¯çš„3Då‡ ä½•ç›¸å½“äºåŸºäºæµ‹é‡ä¸åŒè§†ç‚¹ä¹‹é—´çš„ä¸€è‡´æ€§çš„ç…§ç‰‡ä¸€è‡´æ€§å‡½æ•°æ¥è§£å†³å¯¹åº”é—®é¢˜ã€‚
- åˆ†ç±»ï¼šæ–‡çŒ®ä¸­å·²ç»æå‡ºäº†å¤šè§†å›¾é‡å»ºç®—æ³•çš„å‡ ä¸ªåˆ†ç±»ï¼Œé€šå¸¸è€ƒè™‘åˆ°ç…§ç‰‡ä¸€è‡´æ€§å‡½æ•°çš„å½¢å¼ï¼Œåœºæ™¯è¡¨ç¤ºï¼Œå¯è§†æ€§è®¡ç®—ï¼Œå…ˆéªŒå’Œåˆå§‹åŒ–è¦æ±‚ï¼Œå¦‚Seitzç­‰äººã€‚ ï¼ˆ2006å¹´ï¼‰ã€‚ä»åº”ç”¨çš„è§’åº¦æ¥çœ‹ï¼Œåœºæ™¯è¡¨ç¤ºæ˜¯å°†å¤šè§†å›¾é‡å»ºæ–¹æ³•åˆ†ä¸ºæ·±åº¦å›¾ï¼Œç‚¹äº‘ï¼Œç½‘æ ¼å’Œä½“ç§¯çš„å¸¸è§æ–¹å¼ã€‚

- **Representations: Depth Map**: The depth map representation typically consists of a depth map for each input view estimated with a 3D modeling pipeline which starts with image matching followed by pose estimation and dense stereo. This representation is usually preferred in scene analysis due to its flexibility and scalability to large scenes. One strategy which is particularly effiective for urban scenes is Plane Sweeping Stereo algorithm (Collins (1996)). It sweeps a family of parallel planes in a scene, projects images onto a plane via planar homographies, then evaluates photo-consistency values on each plane. In large scenes, one of the challenges is to handle massive amount of data in real-time. Pollefeys (2008) propose a large scale, realtime 3D reconstruction system based on depth map representation. The real-time performance is achieved by incorporating a set of components which are particularly efficient on typical urban scenes such as a 2D feature tracker with automatic gain adaptation for handling large dynamic range in natural scenes, and parallel implementations of plane sweeping stereo and depth map fusion on GPU.
- **Representations: Point-cloud**: In contrast to a partial depth map for each view, point-cloud or patch based surface representations reconstruct a single 3D point-cloud model using all the input images. Under spatial consistency assumptions, the pointcloud on the surface of the scene can grow or expand which provides easy model manipulation such as merging and splitting. The representative work for these kind of approaches is Patch-based Multi-View Stereo (PMVS) by Furukawa & Ponce (2010). PMVS starts with a feature matching step to generate a sparse set of patches and then iterate between a greedy expansion step and a filtering step to make patches dense and remove erroneous matches.
- è¡¨ç¤ºï¼šæ·±åº¦å›¾ï¼šæ·±åº¦å›¾è¡¨ç¤ºé€šå¸¸ç”±ç”¨3Då»ºæ¨¡æµæ°´çº¿ä¼°ç®—çš„æ¯ä¸ªè¾“å…¥è§†å›¾çš„æ·±åº¦å›¾ç»„æˆï¼Œ3Då»ºæ¨¡æµæ°´çº¿ä»¥å›¾åƒåŒ¹é…å¼€å§‹ï¼Œéšåæ˜¯å§¿æ€ä¼°è®¡å’Œå¯†é›†ç«‹ä½“ã€‚ç”±äºåœºæ™¯åˆ†æçš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ï¼Œå› æ­¤è¿™ç§è¡¨ç¤ºåœ¨åœºæ™¯åˆ†æä¸­é€šå¸¸æ˜¯é¦–é€‰çš„ã€‚ä¸€ç§å¯¹åŸå¸‚åœºæ™¯ç‰¹åˆ«æœ‰æ•ˆçš„ç­–ç•¥æ˜¯å¹³é¢æ‰«æç«‹ä½“å£°ç®—æ³•ï¼ˆCollinsï¼ˆ1996ï¼‰ï¼‰ã€‚å®ƒåœ¨åœºæ™¯ä¸­æ‰«æä¸€ç³»åˆ—å¹³è¡Œå¹³é¢ï¼Œé€šè¿‡å¹³é¢åŒå›¾å°†å›¾åƒæŠ•å½±åˆ°å¹³é¢ä¸Šï¼Œç„¶åè¯„ä¼°æ¯ä¸ªå¹³é¢ä¸Šçš„ç…§ç‰‡ä¸€è‡´æ€§å€¼ã€‚åœ¨å¤§å‹åœºæ™¯ä¸­ï¼ŒæŒ‘æˆ˜ä¹‹ä¸€æ˜¯å®æ—¶å¤„ç†å¤§é‡æ•°æ®ã€‚ Pollefeysï¼ˆ2008ï¼‰æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å›¾è¡¨ç¤ºçš„å¤§è§„æ¨¡å®æ—¶ä¸‰ç»´é‡å»ºç³»ç»Ÿã€‚å®æ—¶æ€§èƒ½æ˜¯é€šè¿‡ç»“åˆä¸€å¥—åœ¨å…¸å‹åŸå¸‚åœºæ™¯ä¸Šç‰¹åˆ«æœ‰æ•ˆçš„ç»„ä»¶æ¥å®ç°çš„ï¼Œä¾‹å¦‚å…·æœ‰è‡ªåŠ¨å¢ç›Šé€‚åº”çš„2Dç‰¹å¾è·Ÿè¸ªå™¨ï¼Œç”¨äºå¤„ç†è‡ªç„¶åœºæ™¯ä¸­çš„å¤§åŠ¨æ€èŒƒå›´ï¼Œä»¥åŠå¹³é¢æ‰«æç«‹ä½“å£°å’Œæ·±åº¦å›¾çš„å¹¶è¡Œå®ç°èåˆåœ¨GPUä¸Š
- è¡¨ç¤ºï¼šç‚¹äº‘ï¼šä¸æ¯ä¸ªè§†å›¾çš„éƒ¨åˆ†æ·±åº¦å›¾ç›¸åï¼Œç‚¹äº‘æˆ–åŸºäºè´´ç‰‡çš„è¡¨é¢è¡¨ç¤ºä½¿ç”¨æ‰€æœ‰è¾“å…¥å›¾åƒé‡å»ºå•ä¸ª3Dç‚¹äº‘æ¨¡å‹ã€‚åœ¨ç©ºé—´ä¸€è‡´æ€§å‡è®¾ä¸‹ï¼Œåœºæ™¯è¡¨é¢ä¸Šçš„ç‚¹äº‘å¯ä»¥å¢é•¿æˆ–æ‰©å±•ï¼Œè¿™æä¾›äº†å®¹æ˜“çš„æ¨¡å‹æ“ä½œï¼Œå¦‚åˆå¹¶å’Œåˆ†å‰²ã€‚è¿™äº›æ–¹æ³•çš„ä»£è¡¨æ€§å·¥ä½œæ˜¯Furukawaï¼†Ponceï¼ˆ2010ï¼‰çš„åŸºäºPatchçš„å¤šè§†ç‚¹ç«‹ä½“å£°ï¼ˆPMVSï¼‰ã€‚ PMVSä»ç‰¹å¾åŒ¹é…æ­¥éª¤å¼€å§‹ï¼Œä»¥ç”Ÿæˆä¸€ç»„ç¨€ç–çš„è¡¥ä¸ï¼Œç„¶ååœ¨è´ªå¿ƒæ‰©å¼ æ­¥éª¤å’Œè¿‡æ»¤æ­¥éª¤ä¹‹é—´è¿›è¡Œè¿­ä»£ï¼Œä»¥ä½¿è¡¥ä¸å¯†é›†å¹¶åˆ é™¤é”™è¯¯çš„åŒ¹é…é¡¹ã€‚

- **Representations: Volumetric**: Volumetric approaches represent geometry on a regularly sampled 3D grid, i.e. volume, either as a discrete occupancy function (Kutulakos&Seitz (2000)) or a function encoding distance to the closest surface (level-set) (Faugeras & Keriven (1998)). More recent approaches use a probability map defined at regular voxel locations to encode the probability of occupancy (Bhotika et al. (2002); Pollard & Mundy (2007); Ulusoy et al. (2015)). The amount of memory required is the main limitation for volumetric approaches. There is a variety of methods for dealing with this problem such as voxel hashing (NieÃŸner et al. (2013)) or a data adaptive discretization of the space in the form of a Delaunay triangulation (Labatut et al. (2007)). One effective solution is an octree data structure which is essentially an adaptive voxel grid to allocate high resolution cells only near the surfaces.
- **Representations: Mesh or Surface**: The final representation in reconstruction is typically triangular mesh-based surfaces. Volumetric surface extraction fuses 3D information from an intermediate representation such as depth maps, point clouds, volumes or scans into a single, clean mesh model. Seminal work by Curless & Levoy (1996) proposes an algorithm to accumulate surface evidence into a voxel grid using signed distance functions. The surface is implicitly represented as the zero crossing of the aggregated signed distance functions. It can be extracted using the Marching Cube algorithm Lorensen & Cline (1987) or using volumetric graph cuts to label each voxel as interior or exterior. There are approaches which directly start from images and refine a mesh model using an energy function composed of a data term based on photo-consistency function and a regularization term for smoothness. In these approaches, the energy is usually optimized using gradient descent, where the movement of each vertex is determined by the gradient of the objective function.
- è¡¨ç¤ºï¼šä½“ç§¯ï¼šä½“ç§¯æ–¹æ³•è¡¨ç¤ºå®šæœŸé‡‡æ ·çš„3Dç½‘æ ¼ä¸Šçš„å‡ ä½•ï¼Œå³ä½“ç§¯ï¼Œä½œä¸ºç¦»æ•£å ç”¨å‡½æ•°ï¼ˆKutulakosï¼†Seitzï¼ˆ2000ï¼‰ï¼‰æˆ–å‡½æ•°ç¼–ç è·ç¦»æœ€æ¥è¿‘çš„è¡¨é¢ï¼ˆæ°´å¹³é›†ï¼‰çš„è·ç¦»ï¼ˆFaugeras ï¼†Kerivenï¼ˆ1998ï¼‰ï¼‰ã€‚æœ€è¿‘çš„æ–¹æ³•ä½¿ç”¨åœ¨å¸¸è§„ä½“ç´ ä½ç½®å®šä¹‰çš„æ¦‚ç‡å›¾æ¥ç¼–ç å ç”¨æ¦‚ç‡ï¼ˆBhotikaç­‰ï¼ˆ2002ï¼‰; Pollardï¼†Mundyï¼ˆ2007ï¼‰; Ulusoyç­‰ï¼ˆ2015ï¼‰ï¼‰ã€‚æ‰€éœ€çš„å†…å­˜é‡æ˜¯ä½“ç§¯æ–¹æ³•çš„ä¸»è¦é™åˆ¶ã€‚å¤„ç†è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼Œå¦‚ä½“ç´ æ•£åˆ—ï¼ˆNieÃŸneret alã€‚ï¼ˆ2013ï¼‰ï¼‰æˆ–ä»¥Delaunayä¸‰è§’å‰–åˆ†å½¢å¼å¯¹ç©ºé—´è¿›è¡Œæ•°æ®è‡ªé€‚åº”ç¦»æ•£åŒ–ï¼ˆLabatut et alã€‚ï¼ˆ2007ï¼‰ï¼‰ã€‚ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆæ˜¯å…«å‰æ ‘æ•°æ®ç»“æ„ï¼Œå®ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªé€‚åº”æ€§ä½“ç´ ç½‘æ ¼ï¼Œä»…åœ¨è¡¨é¢é™„è¿‘åˆ†é…é«˜åˆ†è¾¨ç‡å•å…ƒã€‚
- è¡¨ç¤ºï¼šç½‘æ ¼æˆ–æ›²é¢ï¼šé‡å»ºä¸­çš„æœ€ç»ˆè¡¨ç¤ºé€šå¸¸æ˜¯ä¸‰è§’å½¢ç½‘æ ¼çš„æ›²é¢ã€‚ä½“ç§¯è¡¨é¢æå–å°†3Dä¿¡æ¯ä»è¯¸å¦‚æ·±åº¦å›¾ï¼Œç‚¹äº‘ï¼Œä½“ç§¯æˆ–æ‰«æçš„ä¸­é—´è¡¨ç¤ºèåˆåˆ°å•ä¸ªï¼Œå¹²å‡€çš„ç½‘æ ¼æ¨¡å‹ä¸­ã€‚ Curlessï¼†Levoyï¼ˆ1996ï¼‰çš„ç²¾ç¥å·¥ä½œæå‡ºäº†ä¸€ç§ä½¿ç”¨å¸¦ç¬¦å·è·ç¦»å‡½æ•°å°†è¡¨é¢è¯æ®ç§¯ç´¯åˆ°ä½“ç´ ç½‘æ ¼ä¸­çš„ç®—æ³•ã€‚è¡¨é¢éšå«åœ°è¡¨ç¤ºä¸ºèšåˆæœ‰ç¬¦å·è·ç¦»å‡½æ•°çš„è¿‡é›¶ç‚¹ã€‚å®ƒå¯ä»¥ä½¿ç”¨Marching Cubeç®—æ³•Lorensenï¼†Clineï¼ˆ1987ï¼‰æå–ï¼Œæˆ–ä½¿ç”¨ä½“ç§¯å›¾åˆ‡å‰²å°†æ¯ä¸ªä½“ç´ æ ‡è®°ä¸ºå†…éƒ¨æˆ–å¤–éƒ¨ã€‚å­˜åœ¨ç›´æ¥ä»å›¾åƒå¼€å§‹çš„æ–¹æ³•ï¼Œå¹¶ä¸”ä½¿ç”¨ç”±åŸºäºå…‰ä¸€è‡´æ€§å‡½æ•°çš„æ•°æ®é¡¹ç»„æˆçš„èƒ½é‡å‡½æ•°å’Œç”¨äºå¹³æ»‘åº¦çš„æ­£åˆ™åŒ–é¡¹æ¥ç»†åŒ–ç½‘æ ¼æ¨¡å‹ã€‚åœ¨è¿™äº›æ–¹æ³•ä¸­ï¼Œé€šå¸¸ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¼˜åŒ–èƒ½é‡ï¼Œå…¶ä¸­æ¯ä¸ªé¡¶ç‚¹çš„ç§»åŠ¨ç”±ç›®æ ‡å‡½æ•°çš„æ¢¯åº¦ç¡®å®šã€‚

- **Urban Reconstruction**: In this survey, we focus on multiview reconstruction from an autonomous driving perspective which mainly concerns the reconstruction of large urban areas, up to whole cities. The goal of urban reconstruction algorithms is to produce fully automatic, high-quality, dense reconstructions of urban areas by addressing inherent challenges such as lighting conditions, occlusions, appearance changes, high-resolution inputs, and large scale outputs. Musialski et al. (2013) provide a survey of urban reconstruction approaches by following an output-based ordering, namely buildings and semantics, facades and images, and finally blocks and cities.
- **Input Data**: Musialski et al. (2013) point out that ground, aerial and satellite imagery, as well as Light Detection and Ranging (LiDAR) scans are the most commonly used sensors for urban reconstruction. Ground-level imagery is the most prevalent one due to easy acquisition, storage and exchange. Aerial and satellite imagery have become more easily available due to the advances of Web-mapping projects. In contrast to aerial or multi-view imagery, satellite imagery provides a worldwide coverage at a high frequency with lower costs, but also with lower resolution. LiDAR delivers semi-dense 3D point-clouds which are fairly precise, both ground-level and aerial. Some approaches also incorporate several of these data types together in order to combine their complementary strengths. To deal with the challenging conditions of outdoor scenes, other methods leverage additional data sources, like Digital Surface Models (DSMs) which capture the Earthâ€™s surface. DSMs are 2:5D representations of an urban scene that provide a height for each point on a regular grid. In the following, we provide recent examples of dierent input modalities.
- åŸå¸‚é‡å»ºï¼šåœ¨è¿™æ¬¡è°ƒæŸ¥ä¸­ï¼Œæˆ‘ä»¬ä»è‡ªä¸»é©¾é©¶çš„è§’åº¦é‡ç‚¹å…³æ³¨å¤šè§†è§’é‡å»ºï¼Œä¸»è¦æ¶‰åŠåˆ°å¤§åŸå¸‚ï¼Œç›´åˆ°æ•´ä¸ªåŸå¸‚çš„é‡å»ºã€‚åŸå¸‚é‡å»ºç®—æ³•çš„ç›®æ ‡æ˜¯é€šè¿‡è§£å†³è¯¸å¦‚ç…§æ˜æ¡ä»¶ï¼Œé®æŒ¡ï¼Œå¤–è§‚å˜åŒ–ï¼Œé«˜åˆ†è¾¨ç‡è¾“å…¥å’Œå¤§è§„æ¨¡è¾“å‡ºç­‰å†…åœ¨æŒ‘æˆ˜ï¼Œæ¥å®ç°åŸå¸‚å…¨è‡ªåŠ¨ï¼Œé«˜è´¨é‡ï¼Œå¯†é›†çš„é‡å»ºã€‚ Musialskiç­‰ï¼ˆ2013å¹´ï¼‰é€šè¿‡éµå¾ªåŸºäºè¾“å‡ºçš„æ’åºï¼Œå³å»ºç­‘ç‰©å’Œè¯­ä¹‰ï¼Œå¤–å¢™å’Œå›¾åƒï¼Œä»¥åŠæœ€ç»ˆçš„è¡—åŒºå’ŒåŸå¸‚ï¼Œæä¾›åŸå¸‚é‡å»ºæ–¹æ³•çš„è°ƒæŸ¥ã€‚
- è¾“å…¥æ•°æ®ï¼šMusialski et alã€‚ ï¼ˆ2013ï¼‰æŒ‡å‡ºï¼Œåœ°é¢ï¼Œç©ºä¸­å’Œå«æ˜Ÿå›¾åƒä»¥åŠå…‰æ£€æµ‹å’Œæµ‹è·ï¼ˆLiDARï¼‰æ‰«ææ˜¯åŸå¸‚é‡å»ºä¸­æœ€å¸¸ç”¨çš„ä¼ æ„Ÿå™¨ã€‚åœ°å¹³é¢å›¾åƒæ˜¯æœ€æµè¡Œçš„ï¼Œå› ä¸ºæ˜“äºé‡‡é›†ï¼Œå­˜å‚¨å’Œäº¤æ¢ã€‚ç”±äºWeb-mappingé¡¹ç›®çš„è¿›æ­¥ï¼Œç©ºä¸­å’Œå«æ˜Ÿå›¾åƒå˜å¾—æ›´å®¹æ˜“è·å¾—ã€‚ä¸ç©ºä¸­æˆ–å¤šè§†ç‚¹å›¾åƒç›¸æ¯”ï¼Œå«æ˜Ÿå›¾åƒåœ¨é«˜é¢‘ç‡ä¸‹æä¾›äº†å…¨çƒè¦†ç›–ï¼Œæˆæœ¬æ›´ä½ï¼Œè€Œä¸”åˆ†è¾¨ç‡æ›´ä½ã€‚ LiDARæä¾›åŠå¯†åº¦3Dç‚¹äº‘ï¼Œè¿™äº›äº‘ç‚¹ç›¸å½“ç²¾ç¡®ï¼ŒåŒ…æ‹¬åœ°é¢å’Œå¤©çº¿ã€‚ä¸€äº›æ–¹æ³•ä¹Ÿå°†è¿™äº›æ•°æ®ç±»å‹ä¸­çš„å‡ ç§ç»“åˆåœ¨ä¸€èµ·ï¼Œä»¥ä¾¿ç»“åˆå®ƒä»¬çš„äº’è¡¥ä¼˜åŠ¿ã€‚ä¸ºäº†åº”å¯¹æˆ·å¤–åœºæ™¯çš„æŒ‘æˆ˜æ€§æ¡ä»¶ï¼Œå…¶ä»–æ–¹æ³•åˆ©ç”¨äº†æ•è·åœ°çƒè¡¨é¢çš„æ•°å­—è¡¨é¢æ¨¡å‹ï¼ˆDSMï¼‰ç­‰é™„åŠ æ•°æ®æºã€‚å¸æ–¯æ›¼æ˜¯åŸå¸‚åœºæ™¯çš„2ï¼š5Dè¡¨ç¤ºï¼Œä¸ºå¸¸è§„ç½‘æ ¼ä¸Šçš„æ¯ä¸ªç‚¹æä¾›é«˜åº¦ã€‚åœ¨ä¸‹æ–‡ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸åŒè¾“å…¥æ¨¡å¼çš„æœ€è¿‘ä¾‹å­ã€‚

- **Stereo Sequences**: Cornelis et al. (2008) point out that the extraction of detailed 3D information from video streams incur high computational cost for reconstruction algorithms. By keeping the necessary level of detail low, they focus on creating compact, memory ecient 3D city models from a stereo pair, at high speed based on simplified geometry assumptions, namely ruled surfaces for facade and road surfaces. Since objects such as cars which are prevalent in urban scenes violate these assumptions, they integrate the detection and localization of cars into the reconstruction. By leveraging efficient stereo matching, Geiger et al. (2011) propose a system to generate accurate 3D reconstructions of static scenes from stereo sequences in realtime. For online reconstruction, they employ two threads: the first thread performs feature matching and ego-motion estimation, while the second thread performs dense stereo matching and 3D reconstruction.
- **Digital Surface Models (DSM)**: Digital Surface Models are either generated from aerial LiDAR point clouds or Multi-View Stereo (MVS) and adapted to geometric descriptions of urban scenes. MVS-based DSMs can be very noisy and therefore Lafarge et al. (2010) propose to generate DSMs from MVS imagery by reconstructing buildings with an assemble of simple urban structures extracted from a library of 3D parametric blocks. In contrast to MVS-based DSMs, laser scans have been also very popular to acquire 3D city models. Lafarge & Mallet (2012) provide a more complete description of urban scenes by simultaneously reconstructing trees and topologically complex ground surfaces in addition to the buildings from point clouds generated by aerial data. They model the original hybrid representation of buildings by combining two dierent types of 3D representations: primitives for regular parts of buildings as in Lafarge et al. (2010) and mesh patches for modeling atypical surfaces such as irregular roofs.
- ç«‹ä½“å£°åºåˆ—ï¼šCornelis et alã€‚ ï¼ˆ2008ï¼‰æŒ‡å‡ºï¼Œä»è§†é¢‘æµä¸­æå–è¯¦ç»†çš„3Dä¿¡æ¯ä¼šå¯¼è‡´é‡å»ºç®—æ³•çš„é«˜è®¡ç®—æˆæœ¬ã€‚é€šè¿‡ä¿æŒå¿…è¦çš„ç»†èŠ‚æ°´å¹³ï¼Œä»–ä»¬ä¸“æ³¨äºä»ç«‹ä½“å£°å¯¹ï¼ŒåŸºäºç®€åŒ–çš„å‡ ä½•å‡è®¾ï¼Œå³ç«‹é¢å’Œè·¯é¢çš„è§„åˆ™è¡¨é¢é«˜é€Ÿåˆ›å»ºç´§å‡‘ï¼Œè®°å¿†æ•ˆç‡çš„3DåŸå¸‚æ¨¡å‹ã€‚ç”±äºè¯¸å¦‚åŸå¸‚åœºé¢æ™®éå­˜åœ¨çš„æ±½è½¦ç­‰ç‰©å“è¿åäº†è¿™äº›å‡è®¾ï¼Œå°†æ±½è½¦çš„æ£€æµ‹å’Œæœ¬åœ°åŒ–æ•´åˆåˆ°é‡å»ºä¸­ã€‚é€šè¿‡åˆ©ç”¨é«˜æ•ˆçš„ç«‹ä½“åŒ¹é…ï¼ŒGeigerç­‰ï¼ˆ2011ï¼‰æå‡ºäº†ä¸€ç§ä»ç«‹ä½“å£°åºåˆ—å®æ—¶ç”Ÿæˆé™æ€åœºæ™¯çš„ç²¾ç¡®3Dé‡å»ºçš„ç³»ç»Ÿã€‚å¯¹äºåœ¨çº¿é‡å»ºï¼Œå®ƒä»¬é‡‡ç”¨ä¸¤ä¸ªçº¿ç¨‹ï¼šç¬¬ä¸€ä¸ªçº¿ç¨‹æ‰§è¡Œç‰¹å¾åŒ¹é…å’Œè‡ªä¸»è¿åŠ¨ä¼°è®¡ï¼Œè€Œç¬¬äºŒä¸ªçº¿ç¨‹æ‰§è¡Œå¯†é›†çš„ç«‹ä½“åŒ¹é…å’Œ3Dé‡å»ºã€‚
- æ•°å­—è¡¨é¢æ¨¡å‹ï¼ˆDSMï¼‰ï¼šæ•°å­—è¡¨é¢æ¨¡å‹å¯ä»¥ä»ç©ºä¸­LiDARç‚¹äº‘æˆ–å¤šè§†ç‚¹ç«‹ä½“å£°ï¼ˆMVSï¼‰ç”Ÿæˆï¼Œå¹¶é€‚ç”¨äºåŸå¸‚åœºæ™¯çš„å‡ ä½•æè¿°ã€‚åŸºäºMVSçš„DSMå¯èƒ½éå¸¸å˜ˆæ‚ï¼Œå› æ­¤Lafargeç­‰äººï¼ˆ2010ï¼‰æå‡ºä»MVSå›¾åƒç”ŸæˆDSMï¼Œé€šè¿‡ä»3Då‚æ•°å—åº“æå–çš„ç®€å•åŸå¸‚ç»“æ„çš„ç»„åˆé‡å»ºå»ºç­‘ç‰©ã€‚ä¸åŸºäºMVSçš„DSMç›¸åï¼Œæ¿€å…‰æ‰«æä¹Ÿéå¸¸å—æ¬¢è¿ï¼Œä»¥è·å¾—3DåŸå¸‚æ¨¡å‹ã€‚æ‹‰æ³•åŸºå’Œé©¬å‹’ï¼ˆ2012ï¼‰é€šè¿‡åŒæ—¶é‡å»ºæ ‘æœ¨å’Œæ‹“æ‰‘å¤æ‚çš„åœ°é¢ä»¥åŠç”±èˆªç©ºæ•°æ®äº§ç”Ÿçš„ç‚¹äº‘çš„å»ºç­‘ç‰©ï¼Œæä¾›äº†æ›´å®Œæ•´çš„åŸå¸‚åœºæ™¯æè¿°ã€‚ä»–ä»¬é€šè¿‡ç»„åˆä¸¤ç§ä¸åŒç±»å‹çš„3Dè¡¨ç¤ºæ¥æ¨¡æ‹Ÿå»ºç­‘ç‰©çš„åŸå§‹æ··åˆè¡¨ç¤ºï¼šå¦‚Lafargeç­‰äººçš„å¸¸è§„å»ºç­‘éƒ¨åˆ†çš„åŸå§‹å›¾å½¢ã€‚ ï¼ˆ2010ï¼‰å’Œç”¨äºå»ºæ¨¡éå…¸å‹è¡¨é¢ï¼ˆå¦‚ä¸è§„åˆ™å±‹é¡¶ï¼‰çš„ç½‘æ ¼è¡¥ä¸ã€‚

- **Air and Street level**: Fruh et al. (2005) register a series of vertical 2D surface scans and camera images to airborne data (DSMs) to generate textured facade meshes of cities. They propose a class of data processing techniques to create visually appealing facade meshes by removing noisy foreground objects and filling holes in the geometry and texture of building facades. BÂ´odis-SzomorÂ´u et al. (2016) point out that airborne and mobile mapping data provide complementary information and need to be exploited together in order to produce complete and detailed large-scale city models. Airborne sensors can acquire roof structures, ground, and vegetation at large scale while on-road mobile mapping by multi-view stereo approaches or LiDAR provide the facade and street-side details. They propose
a solution to fuse a detailed on-road mobile mapping and a coarser but more complete point cloud from airborne acquisition in a joint surface mesh. Their evaluation shows that the quality of the model improves substantially by fusing streetside details into the airborne model.
- **Stereo Satellite**: Duan & Lafarge (2016) propose a method to produce compact 3D city models composed of ground and building objects from stereo pairs of satellite images. They represent the scene using convex polygons and perform joint classification and reconstruction of the semantic class (ground, roof, and facade) and the elevation of each polygon. Although their evaluation shows that the obtained results are not as accurate as LiDAR scans, the proposed method can produce fast, compact, and semantic-aware models robust to low resolution and occlusion problems.
- ç©ºæ°”å’Œè¡—é“ç­‰çº§ï¼šFruh et alã€‚ ï¼ˆ2005ï¼‰å°†ä¸€ç³»åˆ—å‚ç›´äºŒç»´è¡¨é¢æ‰«æå’Œæ‘„åƒæœºå›¾åƒæ³¨å†Œåˆ°æœºè½½æ•°æ®ï¼ˆDSMï¼‰ï¼Œä»¥ç”ŸæˆåŸå¸‚çš„çº¹ç†å¤–è§‚ç½‘æ ¼ã€‚ä»–ä»¬æå‡ºäº†ä¸€ç±»æ•°æ®å¤„ç†æŠ€æœ¯ï¼Œé€šè¿‡å»é™¤å˜ˆæ‚çš„å‰æ™¯ç‰©ä½“å¹¶å¡«å……å»ºç­‘ç«‹é¢çš„å‡ ä½•å’Œçº¹ç†ä¸­çš„å­”ï¼Œæ¥åˆ›å»ºè§†è§‰ä¸Šå¸å¼•äººçš„ç«‹é¢ç½‘æ ¼ã€‚ B'odis-Szomor'uç­‰ï¼ˆ2016ï¼‰æŒ‡å‡ºï¼Œæœºè½½å’Œç§»åŠ¨åœ°å›¾æ•°æ®æä¾›äº†è¡¥å……ä¿¡æ¯ï¼Œéœ€è¦ä¸€èµ·åˆ©ç”¨ï¼Œä»¥ä¾¿åˆ¶ä½œå®Œæ•´å’Œè¯¦ç»†çš„å¤§å‹åŸå¸‚æ¨¡å‹ã€‚æœºè½½ä¼ æ„Ÿå™¨å¯ä»¥å¤§è§„æ¨¡è·å¾—å±‹é¡¶ç»“æ„ï¼Œåœ°é¢å’Œæ¤è¢«ï¼Œè€Œé€šè¿‡å¤šè§†è§’ç«‹ä½“å£°æ–¹å¼æˆ–LiDARçš„é“è·¯ç§»åŠ¨åœ°å›¾å¯æä¾›ç«‹é¢å’Œè¡—é“ç»†èŠ‚ã€‚ä»–ä»¬æå‡º
ä¸€ç§è§£å†³æ–¹æ¡ˆï¼Œç”¨äºèåˆè¯¦ç»†çš„é“è·¯ä¸Šç§»åŠ¨åœ°å›¾ä»¥åŠä»è”åˆè¡¨é¢ç½‘æ ¼ä¸­çš„ç©ºä¸­é‡‡é›†è·å–æ›´ç²—ç³™ä½†æ›´å®Œæ•´çš„ç‚¹äº‘ã€‚ä»–ä»¬çš„è¯„ä»·è¡¨æ˜ï¼Œé€šè¿‡å°†è¡—å¤´ç»†èŠ‚èå…¥æœºè½½æ¨¡å‹ï¼Œæ¨¡å‹çš„è´¨é‡å¤§å¤§æé«˜ã€‚
- ç«‹ä½“å£°å«æ˜Ÿï¼šDuanï¼†Lafargeï¼ˆ2016ï¼‰æå‡ºäº†ä¸€ç§åˆ¶ä½œç´§å‡‘å‹3DåŸå¸‚æ¨¡å‹çš„æ–¹æ³•ï¼Œç”±åœ°é¢å’Œå»ºç­‘ç‰©ä½“ç»„æˆçš„ç«‹ä½“å£°å¯¹å«æ˜Ÿå›¾åƒã€‚å®ƒä»¬ä½¿ç”¨å‡¸å¤šè¾¹å½¢ä»£è¡¨åœºæ™¯ï¼Œå¹¶è¿›è¡Œè¯­ä¹‰ç±»ï¼ˆåœ°é¢ï¼Œå±‹é¡¶å’Œç«‹é¢ï¼‰çš„è”åˆåˆ†ç±»å’Œé‡å»ºä»¥åŠæ¯ä¸ªå¤šè¾¹å½¢çš„é«˜ç¨‹ã€‚è™½ç„¶ä»–ä»¬çš„è¯„ä¼°è¡¨æ˜æ‰€è·å¾—çš„ç»“æœä¸å¦‚LiDARæ‰«æçš„å‡†ç¡®æ€§ï¼Œä½†æ˜¯æ‰€æå‡ºçš„æ–¹æ³•å¯ä»¥äº§ç”Ÿå¯¹ä½åˆ†è¾¨ç‡å’Œé—­å¡é—®é¢˜åšå›ºçš„å¿«é€Ÿï¼Œç´§å‡‘å’Œè¯­ä¹‰æ„ŸçŸ¥æ¨¡å‹ã€‚

- 7.3. Reconstruction and Recognition
- In autonomous driving, it is important to understand both the structural and semantic information of the surroundings. Traditionally, image segmentation methods employ priors entirely in the 2D image domain, i.e., spatial smoothness terms, and reconstruction methods usually encourage piecewise smooth surfaces. It has been long argued that semantics and 3D reconstruction carry valuable information to each other. Similarly to stereo, the motivation to incorporate semantics in reconstruction is photo-consistency failing in case of imperfect and ambiguous image information due to specularities, lack of texture, repetitive structures, or strong lighting changes. Semantic labels provide geometric cues about likely surface orientations at a certain location and help resolving inherent ambiguities. 3D reconstruction lifts the reasoning from 2D to 3D and acts as a strong regularizer by enforcing geometric consistency over multiple images for segmentation.
- Planarity and Primitives: Micusik & Kosecka (2009) present a method to overcome these difficulties by exploiting image segmentation cues as well as presence of dominant scene orientations and piecewise planar structures. In particular, they adopt a super-pixel based dense stereo reconstruction method by using the Manhattan world assumption with three orthogonal plane normals in the MRF formulation. Another way of exploiting piecewise planar structures and the shape repetition is to use primitives such as planes, spheres, cylinders, cones and tori (Lafarge et al. (2010); Lafarge & Mallet (2012); Lafarge et al. (2013)). Primitive arrangement-based approaches provide compactness and reduce complexity. However, they remain simplistic representations and fail to model fine details and irregular shapes. Therefore, Lafarge et al. (2013) propose a hybrid approach which is both compact and detailed. Starting from an initial mesh-based reconstruction, they use primitives for regular structures such as columns and walls, while irregular elements are still described by meshes for preserving details.
- åœ¨è‡ªä¸»é©¾é©¶ä¸­ï¼Œäº†è§£å‘¨è¾¹ç¯å¢ƒçš„ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯å¾ˆé‡è¦ã€‚ä¼ ç»Ÿä¸Šï¼Œå›¾åƒåˆ†å‰²æ–¹æ³•åœ¨2Då›¾åƒåŸŸä¸­å®Œå…¨ä½¿ç”¨å…ˆéªŒï¼Œå³ç©ºé—´å¹³æ»‘åº¦é¡¹ï¼Œé‡å»ºæ–¹æ³•é€šå¸¸ä¼šä¿ƒä½¿åˆ†æ®µå¹³æ»‘è¡¨é¢ã€‚é•¿æœŸä»¥æ¥ï¼Œè¯­ä¹‰å’Œ3Dé‡å»ºç›¸äº’ä¼ é€’æœ‰ä»·å€¼çš„ä¿¡æ¯ã€‚ä¸ç«‹ä½“å£°ç±»ä¼¼ï¼Œåœ¨é‡å»ºä¸­çº³å…¥è¯­ä¹‰çš„åŠ¨æœºæ˜¯ç”±äºé•œé¢åå°„ï¼Œç¼ºä¹çº¹ç†ï¼Œé‡å¤ç»“æ„æˆ–å¼ºçƒˆçš„ç…§æ˜å˜åŒ–è€Œå¯¼è‡´çš„å›¾åƒä¿¡æ¯ä¸å®Œæ•´å’Œæ¨¡ç³Šçš„æƒ…å†µä¸‹çš„ç…§ç‰‡ä¸€è‡´æ€§å¤±è´¥ã€‚è¯­ä¹‰æ ‡ç­¾æä¾›å…³äºæŸä¸ªä½ç½®å¤„å¯èƒ½çš„è¡¨é¢å–å‘çš„å‡ ä½•çº¿ç´¢ï¼Œå¹¶å¸®åŠ©è§£å†³å›ºæœ‰çš„æ¨¡ç³Šæ€§ã€‚ 3Dé‡å»ºå°†æ¨ç†ä»2Dæå‡åˆ°3Dï¼Œå¹¶é€šè¿‡å¯¹å¤šä¸ªå›¾åƒæ‰§è¡Œå‡ ä½•ä¸€è‡´æ€§è¿›è¡Œåˆ†å‰²ï¼Œå¹¶ä½œä¸ºå¼ºæ­£åˆ™åŒ–å™¨ã€‚
å¹³é¢æ€§å’ŒåŸå§‹æ€§ï¼šMicusikï¼†Koseckaï¼ˆ2009ï¼‰æå‡ºäº†ä¸€ç§é€šè¿‡åˆ©ç”¨å›¾åƒåˆ†å‰²çº¿ç´¢ä»¥åŠä¸»è¦åœºæ™¯å–å‘å’Œåˆ†æ®µå¹³é¢ç»“æ„çš„å­˜åœ¨æ¥å…‹æœè¿™äº›å›°éš¾çš„æ–¹æ³•ã€‚ç‰¹åˆ«åœ°ï¼Œå®ƒä»¬é‡‡ç”¨åŸºäºè¶…åƒç´ çš„å¯†é›†ç«‹ä½“é‡å»ºæ–¹æ³•ï¼Œé€šè¿‡åœ¨MRFå…¬å¼ä¸­ä½¿ç”¨å…·æœ‰ä¸‰ä¸ªæ­£äº¤å¹³é¢æ³•çº¿çš„æ›¼å“ˆé¡¿ä¸–ç•Œå‡è®¾ã€‚ä½¿ç”¨åˆ†æ®µå¹³é¢ç»“æ„å’Œå½¢çŠ¶é‡å¤çš„å¦ä¸€ç§æ–¹æ³•æ˜¯ä½¿ç”¨è¯¸å¦‚å¹³é¢ï¼Œçƒä½“ï¼Œåœ†æŸ±ä½“ï¼Œé”¥ä½“å’Œæ‰˜é‡Œï¼ˆLafargeç­‰äººï¼ˆ2010ï¼‰; Lafargeï¼†Malletï¼ˆ2012ï¼‰; Lafargeç­‰äººï¼ˆ2013ï¼‰ï¼‰çš„åŸè¯­ã€‚åŸºäºåŸå§‹å¸ƒç½®çš„æ–¹æ³•æä¾›äº†ç´§å‡‘æ€§å¹¶é™ä½äº†å¤æ‚æ€§ã€‚ç„¶è€Œï¼Œå®ƒä»¬ä»ç„¶æ˜¯ç®€å•çš„è¡¨ç¤ºï¼Œå¹¶ä¸”ä¸èƒ½å¯¹ç²¾ç»†ç»†èŠ‚å’Œä¸è§„åˆ™å½¢çŠ¶è¿›è¡Œå»ºæ¨¡ã€‚å› æ­¤ï¼Œæ‹‰æ³•åŸºç­‰ï¼ˆ2013ï¼‰æå‡ºä¸€ç§æ—¢ç´§å‡‘åˆè¯¦ç»†çš„æ··åˆæ–¹æ³•ã€‚ä»åˆå§‹çš„åŸºäºç½‘æ ¼çš„é‡å»ºå¼€å§‹ï¼Œå®ƒä»¬ä½¿ç”¨åŸºæœ¬åŸç†ç”¨äºå¸¸è§„ç»“æ„ï¼Œä¾‹å¦‚åˆ—å’Œå¢™å£ï¼Œè€Œä¸è§„åˆ™å…ƒç´ ä»ç”±ç½‘æ ¼æè¿°ä»¥ä¿ç•™ç»†èŠ‚ã€‚

- Volumetric: Volumetric scene reconstruction typically segments the volume into occupied and free-space regions. Haene et al. (2013) present the mathematical framework to extend it to a multi-label volumetric segmentation framework which assigns object classes or a free-space label to voxels as shown in Figure 22. They first learn appearance likelihoods and classspecific geometry priors for surface orientations from the training data. Then, these data-driven priors are used to define unary and pairwise potentials in a continuous formulation for volumetric segmentation. Joint reasoning benefits from typical class-specific geometry, such as the normals of the ground plane pointing upwards. In addition, it provides a class-specific smoothness prior in cases of weak cues for the scene geometry. Their evaluation shows the benefit of such a prior over standard smoothness assumptions such as Total Variation.
- Zhou et al. (2015) propose a method for 3D reconstruction of street scenes from a sequence of fisheye cameras by introducing semantic priors. Motivated by recurring objects of similar 3D shapes in outdoor scenes, they first localize buildings and vehicles using 3D object detectors and then jointly reconstruct them while learning a volumetric model of their shape. This allows to reduce noise while completing missing surfaces as objects of similar shape benefit from all observations of the respective category.
- ä½“ç§¯ï¼šä½“ç§¯åœºæ™¯é‡å»ºé€šå¸¸å°†ä½“ç§¯åˆ†æˆå ç”¨å’Œè‡ªç”±ç©ºé—´åŒºåŸŸã€‚ Haeneç­‰äººï¼ˆ2013ï¼‰æå‡ºäº†æ•°å­¦æ¡†æ¶ï¼Œå°†å…¶æ‰©å±•åˆ°å¤šæ ‡ç­¾ä½“ç§¯åˆ†å‰²æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†å¯¹è±¡ç±»æˆ–è‡ªç”±ç©ºé—´æ ‡ç­¾åˆ†é…ç»™ä½“ç´ ï¼Œå¦‚å›¾22æ‰€ç¤ºã€‚ä»–ä»¬é¦–å…ˆå­¦ä¹ è¡¨é¢å–å‘çš„å¤–è§‚ä¼¼ç„¶æ€§å’Œç±»ç‰¹å®šå‡ ä½•å…ˆéªŒä»è®­ç»ƒæ•°æ®ã€‚ç„¶åï¼Œè¿™äº›æ•°æ®é©±åŠ¨çš„å…ˆéªŒè¢«ç”¨æ¥å®šä¹‰è¿ç»­å…¬å¼ä¸­çš„ä¸€å…ƒå’Œæˆå¯¹çš„ç”µä½ï¼Œç”¨äºä½“ç§¯åˆ†å‰²ã€‚è”åˆæ¨ç†å—ç›Šäºå…¸å‹çš„ç±»åˆ«ç‰¹å®šå‡ ä½•ï¼Œå¦‚åœ°å¹³é¢å‘ä¸Šçš„æ³•çº¿ã€‚æ­¤å¤–ï¼Œåœ¨åœºæ™¯å‡ ä½•çš„å¼±æç¤ºçš„æƒ…å†µä¸‹ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªç±»åˆ«çš„å¹³æ»‘åº¦ã€‚ä»–ä»¬çš„è¯„ä¼°æ˜¾ç¤ºäº†è¿™æ ·ä¸€ä¸ªå…ˆå‰è¿‡åº¦çš„æ ‡å‡†å¹³æ»‘å‡è®¾ï¼ˆå¦‚æ€»å˜å¼‚ï¼‰çš„å¥½å¤„ã€‚
- Zhou et alã€‚ ï¼ˆ2015ï¼‰æå‡ºäº†ä¸€ç§é€šè¿‡å¼•å…¥è¯­ä¹‰å…ˆéªŒä»ä¸€ç³»åˆ—é±¼çœ¼æ‘„å½±æœºçš„è¡—é“åœºæ™¯3Dé‡å»ºçš„æ–¹æ³•ã€‚ç”±äºæˆ·å¤–åœºæ™¯ä¸­ç±»ä¼¼3Då½¢çŠ¶çš„åå¤å‡ºç°çš„å¯¹è±¡ï¼Œä»–ä»¬é¦–å…ˆä½¿ç”¨3Dç‰©ä½“æ£€æµ‹å™¨å¯¹å»ºç­‘ç‰©å’Œè½¦è¾†è¿›è¡Œæœ¬åœ°åŒ–ï¼Œç„¶ååœ¨å­¦ä¹ å…¶å½¢çŠ¶çš„ä½“ç§¯æ¨¡å‹çš„åŒæ—¶é‡å»ºå®ƒä»¬ã€‚è¿™å…è®¸åœ¨å®Œæˆç¼ºå¤±è¡¨é¢æ—¶å‡å°‘å™ªå£°ï¼Œå› ä¸ºå…·æœ‰ç±»ä¼¼å½¢çŠ¶çš„å¯¹è±¡å—ç›Šäºç›¸åº”ç±»åˆ«çš„æ‰€æœ‰è§‚å¯Ÿã€‚

- **Monocular Video**: Failures in multi-view stereo cause problems for approaches like Haene et al. (2013) which require dense depth measurements. Using a monocular image stream as input, Kundu et al. (2014) propose another joint reasoning approach over a sparse point cloud from SfM and dense semantic labeling of the frames. This way, 3D semantic representation is temporally coherent without additional cost. They model the problem with a higher order CRF in 3D which allows realistic scene constraints and priors such as 3D object support. In addition, they explicitly model the free space which provides cues to reduce ambiguities, especially along weakly supported surfaces. Their evaluation on monocular datasets Camvid and Leuven shows improved 3D structure compared to traditional SfM and state-of-the-art multi-view stereo as well as better segmentation quality over video segmentation methods in terms of both per pixel accuracy and temporal consistency.
- å•ç›®è§†é¢‘ï¼šå¤šè§†ç‚¹ç«‹ä½“å£°æ•…éšœå¯¼è‡´Haeneç­‰äººç­‰æ–¹æ³•å‡ºç°é—®é¢˜ã€‚ ï¼ˆ2013å¹´ï¼‰ï¼Œéœ€è¦æ·±åº¦æµ‹é‡ã€‚ ä½¿ç”¨å•ç›®å›¾åƒæµä½œä¸ºè¾“å…¥ï¼ŒKundu et alã€‚ ï¼ˆ2014ï¼‰æå‡ºäº†ä»SfMçš„ç¨€ç–ç‚¹äº‘å’Œæ¡†æ¶çš„å¯†é›†è¯­ä¹‰æ ‡æ³¨çš„å¦ä¸€ä¸ªè”åˆæ¨ç†æ–¹æ³•ã€‚ è¿™æ ·ï¼Œ3Dè¯­ä¹‰è¡¨ç¤ºåœ¨æ—¶é—´ä¸Šç›¸å¹²è€Œæ²¡æœ‰é¢å¤–çš„æˆæœ¬ã€‚ ä»–ä»¬ç”¨3Dä¸­çš„é«˜é˜¶CRFå¯¹é—®é¢˜è¿›è¡Œå»ºæ¨¡ï¼Œè¿™æ ·å¯ä»¥å®ç°åœºæ™¯çº¦æŸå’Œ3Då¯¹è±¡æ”¯æŒç­‰å…ˆä¿®ã€‚ æ­¤å¤–ï¼Œä»–ä»¬æ˜ç¡®åœ°æ¨¡æ‹Ÿäº†æä¾›çº¿ç´¢çš„è‡ªç”±ç©ºé—´ï¼Œä»¥å‡å°‘æ¨¡ç³Šï¼Œç‰¹åˆ«æ˜¯åœ¨å¼±æ”¯æ’‘çš„è¡¨é¢ä¸Šã€‚ ä»–ä»¬å¯¹å•ç›®æ•°æ®é›†çš„è¯„ä¼°Camvidå’ŒLeuvenæ˜¾ç¤ºå‡ºä¸ä¼ ç»ŸSfMå’Œæœ€å…ˆè¿›çš„å¤šè§†ç‚¹ç«‹ä½“å£°ç›¸æ¯”æ”¹è¿›çš„3Dç»“æ„ä»¥åŠåœ¨æ¯åƒç´ ç²¾åº¦å’Œæ—¶é—´ä¸€è‡´æ€§æ–¹é¢å¯¹è§†é¢‘åˆ†å‰²æ–¹æ³•çš„æ›´å¥½çš„åˆ†å‰²è´¨é‡ã€‚

- **Volumetric**: Large-scale: Previous works on semantic reconstruction (Haene et al. (2013); Kundu et al. (2014)) are limited to small scenes and low resolution, because of their large memory footprint and computational cost. To scale them up to large scenes, Blaha et al. (2016) point out that high resolution is not required for large regions such as free space, parts under the ground, or inside the building. They propose an extension of Haene et al. (2013) by employing an adaptive octree data structure with coarse-to-fine optimization, in an application to generate 3D city models from terrestrial and aerial images. Starting from a coarse voxel grid, they solve a sequence of problems in which the solution is gradually refined only near the predicted surfaces. The adaptive refinement saves memory and runs much faster while still being as accurate as the fixed voxel discretization at the highest target resolution, both in geometric reconstruction and semantic labeling.
- Besides the spatial extent, the number of different semantic labels is also a problem for scalability due to increasing memory requirements. The complexity is quadratic in the number of labels due to indicator variables for the transitions between the different labels. Cherabier et al. (2016) propose to divide the scene into blocks in which only a set of relevant labels is active, since absence of many semantic classes from a specific block can be determined early on. Accordingly, they can deactivate a label right from the beginning of the optimization which leads to a more efficient processing. The set of active labels in each block is updated during the iterative optimization to recover from wrong initializations. Their evaluation shows that they can increase the number of labels from six to nine with a significant gain in memory compared to Haene et al. (2013).
- ä½“ç§¯ï¼šå¤§è§„æ¨¡ï¼šä»¥å‰çš„è¯­ä¹‰é‡å»ºï¼ˆHaene et alã€‚ï¼ˆ2013ï¼‰; Kundu et alã€‚ï¼ˆ2014ï¼‰ï¼‰ä»…é™äºå°åœºæ™¯å’Œä½åˆ†è¾¨ç‡ï¼Œå› ä¸ºå®ƒä»¬å…·æœ‰è¾ƒå¤§çš„å†…å­˜å ç”¨å’Œè®¡ç®—æˆæœ¬ã€‚ä¸ºäº†å°†å®ƒä»¬æ‰©å¤§åˆ°å¤§å‹åœºæ™¯ï¼ŒBlahaç­‰ï¼ˆ2016å¹´ï¼‰æŒ‡å‡ºï¼Œå¤§å‹åœ°åŒºï¼Œå¦‚è‡ªç”±ç©ºé—´ï¼Œåœ°ä¸‹éƒ¨åˆ†ï¼Œå»ºç­‘ç‰©å†…éƒ¨éƒ½ä¸éœ€è¦é«˜åˆ†è¾¨ç‡ã€‚ä»–ä»¬æå‡ºå»¶é•¿Haeneç­‰ï¼ˆ2013ï¼‰é€šè¿‡åœ¨ä»åœ°é¢å’Œèˆªç©ºå›¾åƒç”Ÿæˆ3DåŸå¸‚æ¨¡å‹çš„åº”ç”¨ä¸­é‡‡ç”¨å…·æœ‰ç²—ç•¥åˆ°ä¼˜åŒ–çš„è‡ªé€‚åº”å…«å‰æ ‘æ•°æ®ç»“æ„ã€‚ä»ç²—ä½“ç´ ç½‘æ ¼å¼€å§‹ï¼Œå®ƒä»¬è§£å†³äº†ä¸€ç³»åˆ—é—®é¢˜ï¼Œå…¶ä¸­è§£å†³æ–¹æ¡ˆä»…åœ¨é¢„æµ‹è¡¨é¢é™„è¿‘é€æ¸å®Œå–„ã€‚è‡ªé€‚åº”ç»†åŒ–å¯ä»¥èŠ‚çœå†…å­˜å¹¶ä¸”è¿è¡Œå¾—æ›´å¿«ï¼ŒåŒæ—¶åœ¨å‡ ä½•é‡å»ºå’Œè¯­ä¹‰æ ‡æ³¨ä¸­ä»ç„¶ä¸æœ€é«˜ç›®æ ‡åˆ†è¾¨ç‡ä¸‹çš„å›ºå®šä½“ç´ ç¦»æ•£åº¦ä¸€æ ·å‡†ç¡®ã€‚
- é™¤ç©ºé—´èŒƒå›´å¤–ï¼Œç”±äºå†…å­˜éœ€æ±‚çš„å¢åŠ ï¼Œä¸åŒè¯­ä¹‰æ ‡ç­¾çš„æ•°é‡ä¹Ÿæ˜¯å¯æ‰©å±•æ€§çš„é—®é¢˜ã€‚ç”±äºä¸åŒæ ‡ç­¾ä¹‹é—´çš„è½¬æ¢çš„æŒ‡ç¤ºç¬¦å˜é‡ï¼Œæ ‡ç­¾æ•°é‡çš„å¤æ‚åº¦æ˜¯äºŒæ¬¡æ–¹ã€‚ Cherabierç­‰äººï¼ˆ2016ï¼‰æå‡ºå°†åœºæ™¯åˆ’åˆ†ä¸ºåªæœ‰ä¸€ç»„ç›¸å…³æ ‡ç­¾æ˜¯æ´»åŠ¨çš„å—ï¼Œå› ä¸ºå¯ä»¥åœ¨æ—©æœŸç¡®å®šä¸å­˜åœ¨æ¥è‡ªç‰¹å®šå—çš„è®¸å¤šè¯­ä¹‰ç±»åˆ«ã€‚å› æ­¤ï¼Œå®ƒä»¬å¯ä»¥ä»ä¼˜åŒ–å¼€å§‹å°±åœç”¨æ ‡ç­¾ï¼Œè¿™å¯¼è‡´æ›´æœ‰æ•ˆçš„å¤„ç†ã€‚æ¯ä¸ªå—ä¸­çš„æ´»åŠ¨æ ‡ç­¾é›†åœ¨è¿­ä»£ä¼˜åŒ–æœŸé—´è¢«æ›´æ–°ï¼Œä»¥ä»é”™è¯¯çš„åˆå§‹åŒ–ä¸­æ¢å¤ã€‚ä»–ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼Œä¸Haeneç­‰äººç›¸æ¯”ï¼Œä»–ä»¬å¯ä»¥å°†æ ‡ç­¾çš„æ•°é‡ä»6ä¸ªå¢åŠ åˆ°9ä¸ªï¼Œè®°å¿†æ˜¾ç€å¢åŠ ã€‚ ï¼ˆ2013å¹´ï¼‰ã€‚

- **Shape Priors**: Advances in sensors to acquire 3D shapes and the performance of object detection algorithms have encouraged the use of 3D shape priors in 3D reconstruction. Dimensionality reduction is an effective and popular way of representing shape knowledge. Early approaches use linear dimensionality reduction such as PCA to capture the shape variance in low dimensional latent shape spaces. More recent approaches use nonlinear dimensionality reduction such as Gaussian Process Latent Variable Models (GP-LVM) (Dame et al. (2013)). Dame et al. (2013) investigate the importance of shape priors in a monocular SLAM approach. In parallel with depth estimation, they refine an objectâ€™s pose, shape and scale to match an initial segmentation and depth cues. It is finally fused into the volumetric representation. Their experiments show improvement in transparent and specular surfaces, and even in unobserved parts of the scene. In addition to mean shape, Bao et al. (2013) propose to learn a set of anchor points as representative of object shape across several instances. They first perform an initial alignment using 2D object detectors. Next, they align the point cloud from SfM with the mean shape by matching anchor points, and then warp and refine it to approach the actual shape. Their evaluation demonstrates that the model is general enough to learn semantic priors for different object categories such as car, fruit, and keyboard by handling large shape variations across instances.
- While previous approaches (Dame et al. (2013); Bao et al. (2013)) try to fit a parametric shape model to input data, Haene et al. (2014) model the local distribution of normals for an object. They propose an object class specific shape prior in the form of spatially varying anisotropic smoothness terms. Similar to multi-label segmentation approach of Haene et al. (2013), they divide the reconstruction into object region and the supporting ground and apply the shape prior only on object to guide the optimization to the right shape.
- å…ˆå‰çš„å½¢çŠ¶ï¼šè·å–3Då½¢çŠ¶çš„ä¼ æ„Ÿå™¨çš„è¿›æ­¥å’Œå¯¹è±¡æ£€æµ‹ç®—æ³•çš„æ€§èƒ½å·²ç»é¼“åŠ±åœ¨3Dé‡å»ºä¸­ä½¿ç”¨3Då½¢çŠ¶å…ˆéªŒã€‚å°ºå¯¸å‡å°‘æ˜¯è¡¨ç¤ºå½¢çŠ¶çŸ¥è¯†çš„æœ‰æ•ˆå’Œå—æ¬¢è¿çš„æ–¹å¼ã€‚æ—©æœŸæ–¹æ³•ä½¿ç”¨çº¿æ€§ç»´æ•°é™ä½ï¼ˆå¦‚PCAï¼‰æ¥æ•è·ä½ç»´éšå½¢å½¢çŠ¶ç©ºé—´ä¸­çš„å½¢çŠ¶æ–¹å·®ã€‚æ›´è¿‘æœŸçš„æ–¹æ³•ä½¿ç”¨éçº¿æ€§ç»´æ•°é™ä½ï¼Œå¦‚é«˜æ–¯è¿‡ç¨‹æ½œåœ¨å˜é‡æ¨¡å‹ï¼ˆGP-LVMï¼‰ï¼ˆDameç­‰ï¼ˆ2013ï¼‰ï¼‰ã€‚ Dameç­‰äººï¼ˆ2013ï¼‰ç ”ç©¶å½¢çŠ¶å…ˆéªŒåœ¨å•çœ¼SLAMæ–¹æ³•ä¸­çš„é‡è¦æ€§ã€‚ä¸æ·±åº¦ä¼°è®¡å¹¶è¡Œï¼Œå®ƒä»¬ä¼˜åŒ–å¯¹è±¡çš„å§¿æ€ï¼Œå½¢çŠ¶å’Œå°ºåº¦ä»¥åŒ¹é…åˆå§‹åˆ†å‰²å’Œæ·±åº¦çº¿ç´¢ã€‚å®ƒæœ€ç»ˆèåˆåˆ°ä½“ç§¯è¡¨ç¤ºä¸­ã€‚ä»–ä»¬çš„å®éªŒæ˜¾ç¤ºé€æ˜å’Œé•œé¢è¡¨é¢çš„æ”¹è¿›ï¼Œç”šè‡³åœ¨åœºæ™¯çš„æœªè§‚å¯Ÿçš„éƒ¨åˆ†ã€‚é™¤äº†å¹³å‡å½¢çŠ¶å¤–ï¼ŒBao et alã€‚ ï¼ˆ2013ï¼‰æå‡ºåœ¨å‡ ä¸ªå®ä¾‹ä¸­å­¦ä¹ ä¸€ç»„é”šç‚¹ä½œä¸ºå¯¹è±¡å½¢çŠ¶çš„ä»£è¡¨ã€‚ä»–ä»¬é¦–å…ˆä½¿ç”¨2Dç‰©ä½“æ£€æµ‹å™¨è¿›è¡Œåˆå§‹å¯¹å‡†ã€‚æ¥ä¸‹æ¥ï¼Œä»–ä»¬é€šè¿‡åŒ¹é…é”šç‚¹å°†SfMçš„ç‚¹äº‘ä¸å¹³å‡å½¢çŠ¶å¯¹é½ï¼Œç„¶åæ‰­æ›²å’Œç»†åŒ–ä»¥æ¥è¿‘å®é™…å½¢çŠ¶ã€‚ä»–ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ¨¡å‹è¶³ä»¥é€šè¿‡å¤„ç†å®ä¾‹ä¹‹é—´çš„å¤§çš„å½¢çŠ¶å˜åŒ–æ¥å­¦ä¹ ä¸åŒå¯¹è±¡ç±»åˆ«ï¼ˆå¦‚æ±½è½¦ï¼Œæ°´æœå’Œé”®ç›˜ï¼‰çš„è¯­ä¹‰é¢„æµ‹ã€‚
- å°½ç®¡ä»¥å‰çš„æ–¹æ³•ï¼ˆDameç­‰äººï¼ˆ2013ï¼‰; Baoç­‰ï¼ˆ2013ï¼‰ï¼‰è¯•å›¾å°†å‚æ•°åŒ–å½¢çŠ¶æ¨¡å‹æ‹Ÿåˆä¸ºè¾“å…¥æ•°æ®ï¼ŒHaeneç­‰äººï¼ˆ2014ï¼‰æ¨¡æ‹Ÿäº†ä¸€ä¸ªå¯¹è±¡çš„æ³•çº¿çš„å±€éƒ¨åˆ†å¸ƒã€‚ä»–ä»¬ä»¥ç©ºé—´å˜åŒ–å„å‘å¼‚æ€§å¹³æ»‘åº¦é¡¹çš„å½¢å¼æå‡ºäº†å¯¹è±¡ç±»ç‰¹å®šå½¢çŠ¶ã€‚ç±»ä¼¼äºHaeneç­‰äººçš„å¤šæ ‡ç­¾åˆ†å‰²æ–¹æ³•ï¼ˆ2013ï¼‰ï¼Œä»–ä»¬å°†é‡å»ºåˆ’åˆ†ä¸ºç‰©ä½“åŒºåŸŸå’Œæ”¯æ’‘åœ°é¢ï¼Œç„¶åä»…åœ¨ç‰©ä½“ä¸Šåº”ç”¨å½¢çŠ¶ï¼Œå°†ä¼˜åŒ–å¼•å¯¼åˆ°æ­£ç¡®çš„å½¢çŠ¶ã€‚

- **Data-Driven**: Instead of modeling a semantic prior for each object explicitly, Wei et al. (2014) propose a data-driven regularization to transfer the shape information of the disparity or flow from semantically matched patches in the training database using the SIFT flow algorithm. They represent the shape information as the relative relationship of scene properties instead of absolute values. It is mainly for reusability of scene properties, such as modeling disparity of car independent of its position. They compare their data-driven prior against popular smoothness terms on Sintel and show improved performance while being comparable to state-of-the-art on KITTI.
- æ•°æ®é©±åŠ¨ï¼šè€Œä¸æ˜¯æ˜ç¡®åœ°ä¸ºæ¯ä¸ªå¯¹è±¡å»ºæ¨¡ä¸€ä¸ªè¯­ä¹‰å…ˆéªŒï¼ŒWei et alã€‚ ï¼ˆ2014ï¼‰æå‡ºäº†ä¸€ç§æ•°æ®é©±åŠ¨çš„æ­£åˆ™åŒ–æ–¹æ³•ï¼Œä½¿ç”¨SIFTæµç¨‹ç®—æ³•ä»è®­ç»ƒæ•°æ®åº“ä¸­çš„è¯­ä¹‰åŒ¹é…è¡¥ä¸ä¸­ä¼ è¾“è§†å·®æˆ–æµé‡çš„å½¢çŠ¶ä¿¡æ¯ã€‚ å®ƒä»¬å°†å½¢çŠ¶ä¿¡æ¯è¡¨ç¤ºä¸ºåœºæ™¯å±æ€§è€Œä¸æ˜¯ç»å¯¹å€¼çš„ç›¸å¯¹å…³ç³»ã€‚ å®ƒä¸»è¦ç”¨äºåœºæ™¯å±æ€§çš„å¯é‡ç”¨æ€§ï¼Œå¦‚ç‹¬ç«‹äºå…¶ä½ç½®çš„æ±½è½¦æ¨¡å‹å·®å¼‚ã€‚ ä»–ä»¬æ¯”è¾ƒäº†ä»–ä»¬çš„æ•°æ®é©±åŠ¨å…ˆå‰ä¸Sintelä¸Šçš„æµè¡Œå¹³æ»‘åº¦æ¡æ¬¾ï¼Œå¹¶æ˜¾ç¤ºå‡ºæ”¹è¿›çš„æ€§èƒ½ï¼ŒåŒæ—¶ä¸KITTIä¸Šçš„æœ€å…ˆè¿›æŠ€æœ¯ç›¸åª²ç¾ã€‚
