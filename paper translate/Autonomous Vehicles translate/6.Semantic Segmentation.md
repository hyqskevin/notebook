## Computer Vision for Autonomous Vehicles:Problems, Datasets and State-of-the-Art
自动驾驶技术的计算机视觉：问题，数据和前沿技术

### 6. Semantic Segmentation  语义分割
- Semantic segmentation, is a fundamental topic in computer vision. The goal of semantic segmentation is to assign each pixel in the image a label from a predefined set of categories. The task is illustrated in Figure 12 with all pixel of a certain category colorized in as specific color in a scene of the Cityscapes dataset by Cordts et al. (2016) recorded in Zurich. Segmentation of images into semantic regions usually found in street scenes, such as cars, pedestrians, or road affords a comprehensive understanding of the surrounding which is essential to autonomous navigation. Challenges of semantic segmentation arise from the complexity of the scene and the size of the label space.
- 语义分割是计算机视觉中的一个基本课题。 语义分割的目标是为图像中的每个像素分配来自预定义类别集合的标签。 该任务在图12中示出，Cordts等人在Cityscapes数据集的场景中以特定颜色的所有像素着色。 （2016年）记录在苏黎世。 将图像分割成通常在街道场景中发现的语义区域，例如汽车，行人或道路，可以全面了解对自主导航至关重要的周边环境。 语义分割的挑战源于场景的复杂性和标签空间的大小。

- **Formulation**: Traditionally, the semantic segmentation problem was posed as maximum a posteriori (MAP) inference in a conditional random field (CRF), defined over pixels or super pixels (He et al. (2004, 2006)). However, these early formulations were not efficient and could only handle only datasets of limited size and a small number of classes. Furthermore, only very simple features such as color, edge and texture information have been exploited. Shotton et al. (2009) observed that more powerful features can significantly boost performance and proposed an approach based on a novel type of features called texture-layout filter that exploits the textural appearance of objects, its layout and textural context. They combine texturelayout filters with lower-level image features in a CRF to obtain pixel-level segmentations. Randomized boosting and piecewise training techniques are exploited to efficiently train the model.
- Hierarchical and long-range connectivity, as well as higherorder potentials defined on image regions were considered to tackle the limited ability of CRFs to model long-range interactions within the image. However, methods based on image regions (He et al. (2004); Kumar & Hebert (2005); He et al. (2006); Kohli et al. (2009); Ladicky et al. (2009, 2014)) are restricted by the accuracy of the image segmentations used as input. In contrast, Krahenbuhl & Koltun (2011) propose a highly efficient inference algorithm for fully connected CRF models which models pairwise potentials between all pairs of pixels in the image.
- 制定：传统上，语义分割问题被构成为在像素或超像素上定义的条件随机场（CRF）中的最大后验（MAP）推理（He et al。（2004，2006））。 然而，这些早期方法并不有效，只能处理有限大小和少数类的数据集。 此外，只有非常简单的特征，如颜色，边缘和纹理信息已被利用。 Shotton等人 （2009）观察到，更强大的功能可以显着提高性能，并提出了一种基于一种新颖的功能类型的方法，称为纹理布局过滤器，利用了对象的纹理外观，其布局和纹理上下文。 它们将纹理布局过滤器与CRF中的较低级别图像特征相结合，以获得像素级分割。 利用随机提升和分段训练技术有效地训练模型。
- 被认为分层和远距离连接以及图像区域定义的更高阶电位可以解决CRF在图像中建立长距离相互作用的有限能力。 然而，基于图像区域的方法（He et al。（2004）; Kumar＆Hebert（2005）; He et al。（2006）; Kohli et al。（2009）; Ladicky et al。（2009，2014）） 受用作输入的图像分割的准确性的限制。 相比之下，Krahenbuhl＆Koltun（2011）为完全连接的CRF模型提出了一种高效的推理算法，它们在图像中的所有像素对之间建模成对的电位。

- The methods so far consider each object class independently while the co-occurrence of object classes can be an important clue for semantic segmentation, for example cars are more likely to occur in a street scene than in an office. Consequently, Ladicky et al. (2010) propose to incorporate object class cooccurrence as global potentials in a CRF. They show how these potentials can be efficiently optimized using a graph cut algorithm and demonstrate improvements over simpler pairwise models.
- The success of deep convolutional neural networks for image classification and object detection has sparked interest in leveraging their power for solving the pixel-wise semantic segmentation task. The fully convolutional neural network (Long et al. (2015)) is one of the earliest works which applies CNNs to the image segmentation problem. However, while modern convolutional neural networks for image classification combine multi-scale contextual information by consecutive pooling and subsampling layers that lower the resolution, semantic segmentation requires multi-scale contextual reasoning together with full-resolution dense prediction. In the following we will review recent approaches which address this problem.
- We focus the comparison of different semantic segmentation approaches on the Cityscapes dataset by Cordts et al. (2016) described in Section 2 because of the autonomous driving context. Table 4a shows the leaderboard of Cityscapes for the pixel-level semantic labeling task. The intersection-over union metric is provided for two semantic granularities, i.e., classes and categories, and additionally the instance-weighted IoU is reported for both granularities to penalize methods ignoring small instances.
- 迄今为止，这些方法独立地考虑每个对象类，而对象类的共现可能是语义分割的重要线索，例如，汽车在街景场景中比在办公室中更可能发生。 因此，Ladicky et al。 （2010）提出将对象类并发作为全球潜力纳入CRF。 他们展示了如何使用图形切割算法有效地优化这些潜力，并通过简单的成对模型来证明改进。
- 用于图像分类和物体检测的深卷积神经网络的成功引发了兴趣，利用他们的力量来解决像素方面的语义分割任务。 完全卷积神经网络（Long et al。（2015））是将CNN应用于图像分割问题的最早的作品之一。 然而，虽然用于图像分类的现代卷积神经网络通过连续的合并和降低分辨率的子采样层组合多尺度上下文信息，语义分割需要多尺度上下文推理以及全分辨率密集预测。 在下文中，我们将回顾最近解决这个问题的方法。
- Cordts等人对Cityscapes数据集的不同语义分割方法进行了比较。 （2016）由于自主驾驶环境而在第2节中描述。 表4a显示了Cityscapes针对像素级语义标注任务的排行榜。 提供了交叉联合度量用于两个语义粒度，即类和类别，另外为两个粒度报告了实例加权的IoU，以惩罚忽略小实例的方法。

- **Structured CNNs**: Recently, several methods have been proposed to tackle the opposing needs of multi-scale inference and full-resolution prediction output. Dilated convolutions have been proposed (Chen et al. (2015b); Yu & Koltun (2016)) to enlarge the receptive field of neural networks without loss of resolution. Their operation corresponds to regular convolution with dilated filters which allows for efficient multi-scale reasoning while limiting the increase in the number of model parameters.
- In the SegNet model, Badrinarayanan et al. (2015) have replaced the traditional decoder in a deep architecture with a network which consists of a hierarchy of decoders one corresponding to each encoder. Each decoder maps a low resolution feature map of an encoder (max-pooling layer) to a higher resolution feature map. In particular, the decoder in their model takes advantage of the pooling indices computed in the max-pooling step of the corresponding encoder to implement the upsampling process. This eliminates the need to learn the upsampling and thus results in a smaller number of parameters. Furthermore, sharper segmentation boundaries have been demonstrated using this approach.
- 结构化CNN：最近，已经提出了几种方法来解决多尺度推理和全分辨率预测输出的相反需求。 已经提出了扩张卷积（Chen et al。（2015b）; Yu＆Koltun（2016））来扩大神经网络的接受场而不损失分辨率。 它们的操作对应于具有扩张过滤器的常规卷积，其允许有效的多尺度推理，同时限制模型参数的数量的增加。
- 在SegNet模型中，Badrinarayanan等 （2015）已经用深层架构代替了传统的解码器，网络由一个对应于每个编码器的解码器层次组成。 每个解码器将编码器的低分辨率特征图（最大池）映射到更高分辨率的特征图。 特别地，其模型中的解码器利用在相应编码器的最大汇集步骤中计算的汇集指数来实现上采样过程。 这消除了学习上采样的需要，从而导致较少数量的参数。 此外，已经使用这种方法证明了更清晰的分割边界。

- While activation maps at lower-levels of the CNN hierarchy lack object category specificity, they do contain higher spatial resolution information. Ghiasi & Fowlkes (2016) leverage this assumption and propose to construct a Laplacian pyramid based on a fully convolutional network. Aggregating information at multiple scales allows them to successively refine the boundary reconstructed from lower-resolution layers. They achieve this by using skip connections from higher resolution feature maps and multiplicative confidence gating, penalizing noisy high-resolution outputs in regions where the low-resolution predictions have high confidence. With this approach Ghiasi&Fowlkes (2016) achieve competitive results on Cityscapes Table 4a.
- One of the best performing methods on Cityscapes was proposed by Zhao et al. (2016) using a pyramid scene parsing network, illustrated in Figure 13, to incorporate global context information into the pixel-level prediction task. Specifically, they apply a pyramid parsing module to the last convolutional layer of a CNN which fuses features of several pyramid scales to combine local and global context information. The resulting representation is fed into a convolution layer to obtain final per-pixel predictions.
- 虽然CNN层次较低层的激活映射缺少对象类别的特异性，但它们确实包含较高的空间分辨率信息。 Ghiasi＆Fowlkes（2016）利用这一假设，并提出构建基于完全卷积网络的拉普拉斯金字塔。 在多个尺度上聚合信息使得它们可以连续细化从较低分辨率层重建的边界。 他们通过使用来自较高分辨率特征图的跳跃连接和乘法置信门控来实现这一点，在低分辨率预测具有高置信度的地区惩罚嘈杂的高分辨率输出。 通过这种方式，Ghiasi＆Fowlkes（2016）在“城市风景”表4a中获得了竞争优势。
- Zhao等人提出了Cityscapes最佳表现方法之一。 （2016），使用如图13所示的金字塔场景解析网络，以将全局上下文信息并入到像素级预测任务中。 具体来说，它们将金字塔解析模块应用于CNN的最后卷积层，该融合层融合了几个金字塔尺度的特征以组合局部和全局上下文信息。 所得到的表示被馈送到卷积层以获得最终的每像素预测。

- Simonyan & Zisserman (2015) and Szegedy et al. (2015) have shown that the depth of a CNN is crucial to represent rich features. However, increasing the depth of a network lead to the saturation and degradation of the accuracy. He et al. (2016) propose deep residual learning framework (ResNet) to address this problem. They let each stacked layer learn a residual mapping instead of the original, unreferenced mapping. This allows them to train deeper networks with improving accuracy while plain networks (simply stacked networks) exhibited higher training errors. Pohlen et al. (2016) present a ResNet-like architecture that provides strong recognition performance while preserving high-resolution information throughout the entire network by combining two different processing streams. One stream passes through a sequence of pooling layers, whereas the other stream processes feature maps at full image resolution. The two processing streams are combined at the full image resolution using residuals. Wu et al. (2016b) have proposed a more efficient ResNet architecture by analyzing the effective depths of residual units. They point out that ResNets behave as linear ensembles of shallow networks. Based on this understanding they design a group of relatively shallow convolutional networks for the task of semantic image segmentation. While Pohlen et al. (2016) achieve competitive results on Cityscapes (Table 4a), Wu et al. (2016b) outperform all others in all measures besides the instance-weighted class-level IoU.
- Simonyan＆Zisserman（2015）和Szegedy等人（2015）表明，CNN的深度对于表现丰富的特征至关重要。然而，增加网络的深度导致饱和度和精度的降低。他等（2016）提出了深层次的残留学习框架（ResNet）来解决这个问题。它们使每个堆叠层学习残差映射，而不是原始的未引用映射。这允许他们在提高准确性的同时训练更深入的网络，而简单的网络（简单的堆叠网络）展示更高的训练误差。 Pohlen等人（2016）提出了一种类似ResNet的架构，通过组合两种不同的处理流，可以在整个网络中保持高分辨率信息，提供强大的识别性能。一个流通过一系列池池，而另一个流以完整图像分辨率处理特征图。两个处理流以全图像分辨率使用残差进行组合。吴等（2016b）通过分析剩余单位的有效深度，提出了一种更有效的ResNet架构。他们指出ResNets表现为浅网络的线性集合。基于这一理解，他们为语义图像分割任务设计了一组相对浅的卷积网络。而Pohlen等人（2016）在“城市景观”中获得了竞争优势（表4a），Wu et al。 （2016b）除了实例加权的类水平IoU之外的所有措施都胜过所有其他。

- **Conditional Random Fields**: A different way to address the needs of multi-scale inference and full resolution prediction is the combination of CNNs with CRF models. Chen et al.(2015b) propose to refine the label map obtained using a convolutional neural network using a fully connected CRF model (Krahenbuhl & Koltun (2011)). The CRF allows to capture fine details based on the raw RGB input which are missing in the CNN output due to the limited spatial accuracy of the CNN model. In similar spirit, Jampani et al. (2016) generalize bilateral filters and unroll the CRF program which allows for end-to-end training of the (generalized) filter parameters from data. This effiectively allows for reasoning over larger spatial regions within one convolutional layer by leveraging input features as a guiding signal.
- Inspired by higher order CRFs for semantic segmentation, Gadde et al. (2016a) propose a new Bilateral Inception module for CNN architectures as an alternative to structured CNNs and CRF techniques. They use the assumption that pixels which are spatially and photometrically similar are more likely to have the same label. This allows them to directly learn long-range interactions, thereby removing the need for post-processing using CRF models. Specifically, the proposed modules propagate edge-aware information between distant pixels based on their spatial and color similarity, incorporating the spatial layout of superpixels. Propagation of information is achieved by applying bilateral filters with Gaussian kernels at various scales.
- 条件随机场：解决多尺度推理和全分辨率预测需求的不同方法是将CNN与CRF模型相结合。 Chen等人（2015b）提出使用完全连接的CRF模型（Krahenbuhl＆Koltun（2011））来改进使用卷积神经网络获得的标签图。 由于CNN模型的空间精度有限，CRF可以根据CNN输出中缺少的原始RGB输入来捕获细节。 类似的精神，Jampani等人 （2016）推广双边筛选器并展开CRF程序，允许对来自数据的（广义）过滤器参数进行端对端培训。 这有效地允许通过利用输入特征作为引导信号来推理在一个卷积层内的较大空间区域。
- 灵感来自语义分割的高阶CRF，Gadde et al。 （2016a）提出了一种用于CNN架构的新的双边入局模块，作为结构化CNN和CRF技术的替代方案。 他们使用这样的假设：空间和光度相似的像素更可能具有相同的标签。 这允许他们直接学习远程交互，从而消除了使用CRF模型进行后处理的需要。 具体地说，所提出的模块基于它们的空间和颜色相似性，在远距离像素之间传播边缘感知信息，并结合超像素的空间布局。 通过在各种尺度上应用具有高斯核的双边滤波器来实现信息的传播。

- **Discussion**: The focus on multi-scale inference of recent methods led to impressive results in pixel-level semantic segmentation on Cityscapes. Today, the top methods in Cityscapes Table 4b reach an impressive IoU of almost 81% over classes and 91% over categories. In contrast, the instance-weighted IoU is always below 58% over classes and 80% over categories. This indicates that semantic segmentation works well with instances covering large image areas but is still problematic with instances covering small regions. Similarly to the detection in low resolutions discussed in Section 5.6, small regions provide only little information to assign the correct label. Furthermore segmenting out small, and possibly occluded objects is a challenging task which might require novel approaches to jointly perform depth estimation and depth-adaptive recognition.
- 讨论：对近期方法的多尺度推论的关注导致了Cityscapes中像素级语义分割的令人印象深刻的结果。 今天，“城市风景”表4b中的顶级方法达到令人印象深刻的几率，达到81％，超过类别91％。 相比之下，实例加权IoU总是低于58％，超过类别80％。 这表明语义分割对于覆盖大图像区域的实例很好，但是对于覆盖小区域的实例仍然是有问题的。 类似于5.6节中讨论的低分辨率检测，小区域只提供很少的信息来分配正确的标签。 此外，分割出小的可能闭塞的物体是一项具有挑战性的任务，可能需要新颖的方法来共同执行深度估计和深度自适应识别。

- 6.1. Semantic Instance Segmentation  语义实例分割
- The goal of semantic instance segmentation is simultaneous detection, segmentation and classification of every individual object in an image. Unlike semantic segmentation, it provides information about the position, semantics, shape and count of individual objects, and therefore has many applications in autonomous driving. For the task of semantic instance segmentation, there exist two major lines of research: Proposal-based and proposal-free instance segmentation.
- In Table 4b we show the leaderboard of semantic instance segmentation methods on the Cityscapes dataset. The performance is assessed with the average precision on the region level averaged across a range of overlap thresholds (AP), for an overlap value of 50 % (AP 50%) and for objects within 100 m and 50 m (AP 100m, AP 50m).
- 语义实例分割的目标是对图像中每个单独对象进行同时检测，分割和分类。 与语义分割不同，它提供了关于单个对象的位置，语义，形状和数量的信息，因此在自主驾驶中具有许多应用。 对于语义实例分割的任务，存在两个主要研究领域：基于提案和无提议的实例分割。
- 在表4b中，我们在Cityscapes数据集上显示语义实例分割方法的排行榜。 对于重叠值为50％（AP 50％）和100米和50米范围内的物体（AP 100米，AP 50米），区域水平平均精度在平均重叠阈值（AP）范围内进行评估）。

- **Proposal-based Instance Segmentation**: Proposal-based instance segmentation methods extract class-agnostic proposals which are classified as an instance of a certain semantic class in order to obtain pixel-level instance masks. Region proposals like Multiscale Combinatorial Grouping (Arbel´aez et al. (2014)) can be directly used as instance segments. Coarser representations such as bounding boxes need further refinement to obtain the instance mask. Unfortunately, proposal-based algorithms are slow at inference time due to the computationally expensive proposal generation step. To avoid this bottleneck, Dai et al. (2016) propose a fully convolutional network with three stages. They extract box proposals, use shared features to refine these to segments, and finally classify them into semantic categories. The causal relations between the outputs of the stages complicate training of the multi-task cascade. However, the authors show how these difficulties can be overcome using a differentiable layer which allows for training the whole model in an end-to-end fashion.
- Proposal-based instance segmentation methods that use proposals in the form of bounding boxes to predict a binary segmentation mask are sensitive to errors in the proposal generation process including wrongly scaled or shifted bounding boxes. To tackle this problem, Hayder et al. (2016) present a new object representation. More specifically, they propose a shape aware object mask network that predicts a binary mask for each bounding box proposal, potentially extending beyond the box itself. They integrate the object mask network into the Multitask Network Cascade framework of Dai et al. (2016) by replacing the original mask prediction stage. The shape aware approach is the second best performing method on Cityscapes(Table 4b).
- 基于提案的实例分段：基于提案的实例分段方法提取类别不可知的提案，被分类为某个语义类的实例，以获得像素级实例掩码。区域建议如多尺度组合分组（Arbel'aez et al。（2014））可直接用作实例。较粗糙的表示，例如边界框需要进一步细化以获得实例掩码。不幸的是，由于计算昂贵的建议生成步骤，基于提议的算法在推理时间较慢。为了避免这个瓶颈，Dai等（2016）提出了一个具有三个阶段的完全卷积网络。他们提取框提案，使用共享功能将这些细分为细分，最后将它们分类为语义类别。这些阶段的产出之间的因果关系使多任务级联的训练复杂化。然而，作者展示了如何使用可微分层来克服这些难题，从而可以以端对端的方式对整个模型进行训练。
- 使用基于边界框形式的提案以预测二进制分割掩码的基于投标的实例分割方法对提案生成过程中的错误（包括错误缩放或移位的边界框）敏感。 为了解决这个问题，Hayder等 （2016）提出了一个新的对象表示。 更具体地说，它们提出了一种形状感知对象掩模网络，其预测每个边界框提案的二进制掩码，潜在地延伸超出框本身。 他们将对象掩码网络集成到Dai等人的多任务网络级联框架中。 （2016）通过替换原始的掩模预测阶段。 形状感知方法是Cityscapes第二好的表现方法（表4b）。

- Proposal-free Instance Segmentation: Recently, a number of alternative methods to proposal-based instance segmentation have been proposed in the literature. These methods jointly infer the segmentation and the semantic category of individual instances by casting instance segmentation directly as a pixel labeling task.
- Zhang et al. (2015, 2016c) train a fully convolutional neural networks (FCN) to directly predict pixel-level instance segmentation while the instance ID encodes a depth ordering. They improve the predictions and enforce consistency with a subsequent Markov Random Field. Uhrig et al. (2016) propose a method based on FCN to jointly predict semantic segmentation as well as depth and an instance-based direction relative to the centroid of each instance. The instance segmentation pipeline is illustrated in Figure 14. However, they require ground-truth depth data for training their model. Kirillov et al. (2016) present a proposal-free method which combines semantic segmentation and object boundary detection via global reasoning in a multi-cut formulation to infer semantic instance segmentation. Bai & Urtasun (2016) combine intuitions from classical watershed transform and deep learning to create an energy map where the basins corresponds to object instances. This allows them to cut at a single energy level to obtain an pixel-level instance segmentation. Kirillov et al. (2016) and Bai & Urtasun (2016) both achieve competitive results on Cityscapes (Table 4b). However, Arnab & Torr (2017) outperform all others by feeding an initial semantic segmentation into an instance subnetwork. Specifically, the initial category-level segmentation is used along cues from the output of an object detector within an end-to-end CRF to predict pixel-level instances.
- 无提议实例分割：最近，文献中提出了一些基于提案的实例分割的替代方法。 这些方法通过直接将实例分割作为像素标注任务来共同推断单个实例的分割和语义类别。
- Zhang et al（2015，2016c）训练完全卷积神经网络（FCN）直接预测像素级实例分割，而实例ID编码深度排序。他们改进了预测，并强制与随后的马尔可夫随机场一致。 Uhrig等人（2016）提出了一种基于FCN的方法来共同预测语义分割以及相对于每个实例的重心的深度和基于实例的方向。实例分割管线如图14所示。但是，它们需要用于训练其模型的地面真相深度数据。基里洛夫等人（2016）提出了一种无提议方法，通过全局推理将语义分割和对象边界检测结合在一个多切分公式中，以推断语义实例分割。 Bai＆Urtasun（2016）结合了经典流域变换和深度学习的直觉，创建了一个能量图，其中盆地对应于对象实例。这允许他们在单个能级切割以获得像素级的实例分割。基里洛夫等人（2016年）和Bai＆Urtasun（2016年）都在Cityscapes上取得了竞争力的结果（表4b）。然而，Arnab＆Torr（2017）通过将初始语义分割提供给实例子网络来胜过所有其他方式。具体来说，初始类别级别的分段被用于端到端CRF内的对象检测器输出的提示，以预测像素级实例。

- **Discussion**: The instance segmentation task is much more difficult than the semantic segmentation task. Each instance need to be carefully annotated separately whereas in semantic segmentation groups of one semantic class can be annotated together when they occur next to each other. In addition, the number of instance varies greatly between different images. In the autonomous driving context often a wide view is present. Therefore, a large number of instances that appear are rather small in the image making them challenging to detect. In contrast to bounding boxes discussed in Section 5.6, the exact shape of each object instance needs to be inferred in this task. For these reasons, the state-of-the-art is still struggling with the Cityscape dataset (Table 4b) reaching an average precision of 20% or less.
- 讨论：实例分割任务比语义分割任务困难得多。 每个实例需要分别仔细注释，而在语义分割中，一个语义类的组可以在彼此相邻发生时一起注释。 另外，实例的数量在不同的图像之间变化很大。 在自主驾驶环境中，通常有广泛的观点。 因此，出现的大量实例在图像中相当小，使得它们具有挑战性。 与第5.6节讨论的边界框相反，每个对象实例的确切形状需要在此任务中推断出来。 由于这些原因，最先进的技术仍然在与Cityscape数据集（表4b）挣扎，达到20％以下的平均精度。...

- 6.2. Label Propagation 标签传播
- Creating large-scale image datasets with highly accurate pixel-level annotations is labor intensive, and thus very expensive to obtain the desired degree of quality. Semi-supervised methods for annotation of video sequences can help to reduce this cost. Compared to annotating individual images, video sequences offer the advantage of temporal consistency between consecutive frames. Label propagation techniques take advantage of this fact by propagating annotations from a small set of annotated keyframes to all unlabeled frames based on color
information and motion estimates.
- 创建具有高精度像素级注解的大规模图像数据集是劳动密集型的，因此获得所需的质量程度非常昂贵。 用于注释视频序列的半监督方法可以帮助降低成本。 与注释单个图像相比，视频序列提供连续帧之间的时间一致性的优点。 标签传播技术通过将注释从一小部分注释关键帧传播到基于颜色的所有未标记的帧来利用这一事实
信息和运动估计。

- Towards this goal, Badrinarayanan et al. (2010) propose a coupled Bayesian network for joint modeling of the image sequence and pixel-wise labels. Specifically, they employ a propagation scheme based on correspondences obtained from image patch based similarities and semantically consistent regions to transfer label information to unlabeled frames between annotated keyframes. Budvytis et al. (2010) extend this approach by proposing a hybrid model of the generative propagation introduced in Badrinarayanan et al. (2010) as well as a discriminative classification stage which tackles occlusions and dis-occlusions, and allows to propagate over larger time frames. To correct erroneous label propagation, Badrinarayanan et al. (2014) propose a superpixel based mixture-of-tree model for temporal correlation. Vijayanarasimhan & Grauman (2012) tackle the
problem of selecting the most promising keyframes for manual labeling such that the expected propagation error is minimized.
- 为实现这一目标，Badrinarayanan等 （2010）提出了一种耦合贝叶斯网络，用于图像序列和像素方向标签的联合建模。 具体地说，它们采用基于从基于图像块的相似性和语义上一致的区域获得的对应的传播方案来将标签信息转移到带标注的关键帧之间的未标记的帧。 Budvytis等人 （2010）通过提出在Badrinarayanan等人引入的生成繁殖的混合模型来扩展这种方法。 （2010）以及解决闭塞和闭塞的歧视性分类阶段，并允许在更大的时间范围内传播。 为了纠正错误的标签传播，Badrinarayanan等 （2014）提出了一种用于时间相关的基于超像素的树混合模型。 Vijayanarasimhan＆Grauman（2012）解决了
选择用于手动标签的最有希望的关键帧的问题，使得期望的传播误差最小化。

- While the aforementioned methods transfer annotations in 2D, Chen et al. (2014); Xie et al. (2016) propose to annotate directly in 3D and then transfer these annotations into the image domain. Given a source of 3D information (e.g., stereo, laser), these approaches are able to produce improved semantic accuracy and time coherent labels while limiting annotation costs. Towards this goal, Chen et al. (2014) use annotations from KITTI (Geiger et al. (2013)) and leverage 3D car CAD models to infer separate figure-ground segmentations for all cars in the image. In contrast, Xie et al. (2016) reason jointly about all objects in the scene and also handle categories for which CAD models or 3D point measurements are unavailable. To this end, they propose a non-local CRF model which reasons jointly about semantic and instance labels of all 3D points and pixels in the image.
- 虽然上述方法在2D中传输注释，但Chen等（2014）; 谢等人 （2016）建议直接在3D中注释，然后将这些注释传输到图像域中。 给定3D信息的来源（例如，立体声，激光），这些方法能够产生改进的语义准确度和时间相干标签，同时限制注释成本。 为了实现这一目标，Chen et al。 （2014）使用KITTI（Geiger等人（2013））的注释，并利用3D汽车CAD模型推测图像中所有汽车的独立图形分割。 相比之下，谢等人 （2016）共同理解场景中的所有对象，并处理CAD模型或3D点测量不可用的类别。 为此，他们提出了一种非本地CRF模型，它们共同对图像中所有3D点和像素的语义和实例标签进行了理解。

- 6.3. Semantic Segmentation with Multiple Frames 多帧语义分割
- Semantic segmentation from movable platforms such as autonomous vehicles has become an active area of research due to the need of autonomous systems for recognizing their surrounding environment. As such systems are typically equipped with video cameras, temporal correlation between adjacent frames can be exploited to improve segmentation accuracy, efficiency and robustness.
- Towards this goal, Floros & Leibe (2012) propose graphical models operating on video sequences in order to enforce temporal consistency between frames. Specifically, they have proposed a CRF where temporal consistency between consecutive video frames is ensured by linking corresponding image pixels to the inferred 3D scene points obtained by Structure from Motion (SfM). Compared to an image-only baseline they achieve an improved segmentation performance and observe a good generalization to varying image conditions.
- 自动车辆等移动平台的语义分割已经成为一个活跃的研究领域，由于需要自主系统来识别周围的环境。 由于这样的系统通常配备有摄像机，因此可以利用相邻帧之间的时间相关性来提高分割精度，效率和鲁棒性。
- 为了实现这一目标，Floros＆Leibe（2012）提出了对视频序列进行操作的图形模型，以便强化帧之间的时间一致性。 具体来说，他们提出了一种CRF，其中通过将对应的图像像素与通过运动结构（SfM）获得的推断的3D场景点相关联来确保连续视频帧之间的时间一致性。 与仅基于图像的基线相比，它们实现了改进的分割性能，并观察到不同图像条件的良好泛化。

- 3D reconstruction works relatively well for static scenes but is still an open problem in dynamic scenes. Feature-sensitive CRF models have been very successful in semantic image segmentation but the considered distance measure does not appropriately model spatiotemporal correspondences. The presence of both scene and camera motion makes temporal association in videos a challenging task. Because of the possibility of significant optical flow due to such motions, Euclidean distance in the space-time volume is not a good surrogate for correspondence. To tackle this problem, Kundu et al. (2016) propose a method for optimizing the feature space of a dense CRF for spatiotemporal regularization. Specifically, the feature space is optimized such that distances between features associated with corresponding points are minimized using correspondences from optical flow. The resulting mapping is exploited by the CRF to achieve long-range regularization over the entire video volume.
- 3D重建对于静态场景效果较好，但在动态场景中仍然是一个开放的问题。 功能敏感的CRF模型在语义图像分割中取得了非常成功，但考虑的距离度量并不能适当地模拟时空对应关系。 场景和相机运动的存在使视频中的时间关联成为一项具有挑战性的任务。 由于这种运动的可能性很大，所以在时空体积中的欧几里德距离不是很好的对应关系。 为了解决这个问题，Kundu et al。 （2016）提出了一种用于优化密集CRF的时空正则化特征空间的方法。 具体地，特征空间被优化，使得使用来自光流的对应来最小化与对应点相关联的特征之间的距离。 所得到的映射由CRF利用，以在整个视频卷上实现远程正则化。

- 6.4. Semantic Segmentation of 3D Data 3D数据的语义分割
- Autonomous systems need to recognize their surroundings to identify and interact with objects of interest. While the problem of semantic object labeling has been studied extensively, most of these algorithms work in the 2D image domain where each pixel in the image is labeled with a semantic category such as car, road or pavement. However, 2D images lack important information such as the 3D shape and scale of objects which are strong cues for object class segmentation and facilitate the detection and separation of individual object instances.
- Sengupta et al. (2012) present an approach to generate a semantic overhead map of an urban scene from street level images. They formulate the problem using two CRFs. The first is used for semantic image segmentation of the street view images treating each image independently. Each street view image is then related by a geometrical function that back projects a region from the image into the overhead map. The outputs of this phase are then aggregated over many images to form the input for a second CRF producing a labeling of the ground plane. However, their method does not go beyond the flat world assumption to deliver dense semantic reconstruction using multiple street view images.
- 自治系统需要识别他们的周围环境，以识别和与感兴趣的对象进行交互。 虽然已经广泛研究了语义对象标注的问题，但是大多数这些算法在2D图像域中工作，其中图像中的每个像素被标记有诸如汽车，道路或路面的语义类别。 然而，2D图像缺少诸如对象类别分割的强线索的对象的3D形状和尺度等重要信息，并且便于各个对象实例的检测和分离。
- Sengupta（2012）提出了一种从街道图像生成城市场景的语义开销图的方法。 他们使用两个CRF制定问题。 第一个用于独立处理每个图像的街景图像的语义图像分割。 然后，每个街景图像通过几何函数相关联，后者将区域从图像投影到架空地图中。 然后将该相的输出聚集在许多图像上以形成用于产生接地平面的标记的第二CRF的输入。 然而，他们的方法不超越平面世界的假设，使用多个街景图像提供密集的语义重建。

- Towards this goal, Sengupta et al. (2013) propose an approach illustrated in Figure 15 where a dense semantic 3D reconstruction is generated using multiple street view images. They use visual odometry for ego-motion estimation according to which depth-maps generated from input stereo image pairs are fused. This allows them to generate a volumetric 3D representation of the scene. In parallel, input images are semantically classified using a CRF model. The results of segmentation are then aggregated across the sequence to generate the final 3D semantic model. However, the object labeling is performed in the image domain and then projected onto the model. As a result, these methods fail to fully exploit all structural constraints present in road scenes.
- Valentin et al. (2013) tackle the problem of semantic scene reconstruction in 3D space by combining both structural and appearance cues. They use input depth estimates to generate a triangulated mesh representation of the scene and apply a cascaded classifier to learn geometric cues from the mesh and appearance cues from images. Subsequently, they solve for the labeling in 3D by defining a CRF over the scene mesh. However, they approach requires inference on the whole mesh an does not allow for incrementally adding information in an online setting as common in the autonomous driving context.
- Hackel et al. (2016) propose a fast semantic segmentation approach for 3D point clouds with strongly varying densities. They construct approximate multi-scale neighborhoods by downsampling the entire point cloud, to generate a multi-scale pyramid with decreasing density, and searching for the nearest neighbors per scale. This scheme allows to extract rich feature representation, that captures the geometry in a point’s local neighborhood such as roughness, surface orientation, height over ground and others, in very little time. A random forest classifier finally predicts the class-conditional probabilities. The proposed method can process point clouds with many million of points in a matter of minutes.
- 为了实现这一目标，Sengupta等 （2013）提出了图15所示的方法，其中使用多个街景图像生成密集的语义3D重建。 根据从输入立体图像对生成的深度图被融合，他们使用视觉测距法进行自我运动估计。 这允许他们生成场景的体积3D表示。 并行地，输入图像使用CRF模型进行语义分类。 然后，分割结果跨序列进行聚合，以生成最终的3D语义模型。 然而，对象标注在图像域中执行，然后投影到模型上。 因此，这些方法无法充分利用道路场景中存在的所有结构性限制。
- 瓦伦丁等人 （2013）通过结合结构和外观线索来解决3D空间中语义场景重构的问题。 他们使用输入深度估计来生成场景的三角网格表示，并应用级联分类器从网格和图像中的外观线索学习几何提示。 随后，他们通过在场景网格上定义CRF来解决3D中的标签问题。 然而，他们的方法需要对整个网格进行推理，不允许在自主驾驶环境中常见的在线设置中逐渐添加信息。
- Hackel等人 （2016）提出了一种具有强烈变化密度的3D点云的快速语义分割方法。 它们通过对整个点云进行下采样来构造近似的多尺度邻域，以生成具有减小密度的多尺度金字塔，并且每个尺度搜索最近的邻居。 该方案允许提取丰富的特征表示，其在非常少的时间内捕获点的本地邻域中的几何，例如粗糙度，表面取向，地面高度等。 随机森林分类器最终预测了类条件概率。 所提出的方法可以在几分钟内处理具有数百万点的点云。

- **Online Methods**: Vineet et al. (2015) propose an end-to-end system which processes data incrementally and performs realtime dense stereo reconstruction and semantic segmentation of outdoor environments. They achieve this using voxel hashing (Nießner et al. (2013)), a hash-table-driven 3D volumetric representation that ignores unoccupied space in the target environment. Furthermore, they employ an online volumetric mean-field inference technique that incrementally refines the voxel labeling. They are able to achieve semantic reconstruction at real-time rates by harnessing the processing power of modern GPUs.
- McCormac et al. (2016) propose a pipeline for dense 3D semantic mapping designed to work online by fusing semantic predictions of a CNN with the geometric information from a SLAM system (ElasticFusion by Whelan et al. (2015)). Specifically, ElasticFusion provides correspondences between 2D frames and a globally consistent map of surfels. Furthermore, they use a Bayesian update scheme which computes the class probabilities for each surfel based on the CNN’s predictions. The advantage of using surfel-based surface representations is their ability to fuse long-range information, for instance after a loop closure has been detected and the poses have been corrected accordingly.
- 在线方法：Vineet et al。 （2015）提出了一种端到端系统，可以逐步处理数据，并进行户外环境的实时密集立体重构和语义分割。 他们使用体素散列（Nießneret al。（2013））实现了这一点，这是一种散列表驱动的3D体积表示，忽略了目标环境中未占用的空间。 此外，他们采用在线体积平均场推理技术，逐步优化体素标签。 通过利用现代GPU的处理能力，他们能够以实时速率实现语义重建。
- McCormac等人 （2016）提出了一种用于密集3D语义映射的流水线，旨在通过将CNN的语义预测与SLAM系统的几何信息（Whelan等人（2015）的ElasticFusion）融合在线工作）。 具体来说，ElasticFusion可以提供2D帧与全局一致的冲浪图之间的对应关系。 此外，他们使用贝叶斯更新方案，其基于CNN的预测计算每个冲浪的类概率。 使用基于浮标的表面表示的优点是它们能够融合长距离信息，例如在检测到闭环并且相应地纠正姿态之后。

- **3D CNN**: While convolutional networks have proven very successful segmenting 2D images semantically, there exists relatively little work on labeling 3D data using convolutional networks. Huang & You (2016) propose a framework for labeling 3D point cloud data using a 3D Convolutional Neural Network (3D-CNN). Specifically, they compute 3D occupancy grids of size 203 centered at a set of randomly generated key points. The occupancy and the labels form the input to a 3D CNN, which is composed of convolutional layers, max-pooling layers, a fully connected layer and a logistic regression layer. Due to the dense voxel representation, 3D CNNs are only able to process voxel grids of very coarse resolution considering the memory limitations of modern GPUs.
- To alleviate this problem, Riegler et al. (2017) propose Oct-Nets, a 3D convolutional network, that allows for training deep architectures at significantly higher resolutions. They build on the observation that 3D data (e.g., point clouds, meshes) is often sparse in nature. The proposed OctNet exploits this sparsity property by hierarchically partitioning the 3D space into a set of octrees and applying pooling in a data-adaptive fashion. This leads to a reduction in computational and memory requirements as the convolutional network operations are defined on the structure of these trees and thus can dynamically allocate resources depending on the structure of the input.
- 3D CNN：虽然卷积网络已经证明非常成功地在语义上分割2D图像，但是使用卷积网络标记3D数据的工作相对较少。 Huang＆You（2016）提出了一个使用3D卷积神经网络（3D-CNN）标记3D点云数据的框架。 具体地说，它们以一组随机产生的关键点为中心计算大小为203的3D占用网格。 占有率和标签形成3D CNN的输入，该三维CNN由卷积层，最大池层，完全连接层和逻辑回归层组成。 考虑到现代GPU的内存限制，由于密集的体素表示，3D CNN只能处理非常粗略的分辨率的体素网格。
- 为了减轻这个问题，Riegler等 （2017）提出了一个3D卷积网络Oct-Nets，它允许以更高的分辨率训练深层架构。 它们建立在3D数据（例如，点云，网格）本质上经常稀疏的观察的基础上。 提出的OctNet通过将3D空间分层划分成一组八叉树并以数据自适应方式应用池来利用此稀疏属性。 这导致计算和存储器需求的减少，因为卷积网络操作在这些树的结构上被定义，并且因此可以根据输入的结构而动态地分配资源。

- 6.5. Semantic Segmentation of Street Side Views 街景视图的语义分割
- One important application of semantic segmentation for autonomous vehicles is to segment street-side images (i.e., building facades) into its components (wall, door, window, vegetation, balcony, store, mailbox etc.). Such semantic segmentations are useful for accurate 3D reconstruction, memory-efficient 3D mapping, robust localization as well as path planning.
- Xiao & Quan (2009) propose a multi-view semantic segmentation framework for images captured by a camera mounted on a car driving along the street. Specifically, they define a pairwise MRF across superpixels in multiple views, where the unary terms are based on 2D and 3D features. Furthermore, they minimize color differences for spatial smoothness and use dense correspondences to enforce smoothness across different views. Existing approaches for multi-view semantic segmentation typically require labeling all pixels in all images used for the 3D model which, depending on the semantic segmentation algorithm, can be prohibitively slow. To increase efficiency, Riemenschneider et al. (2014) exploit the inherent redundancy in the labeling of all overlapping images used for the 3D model. They propose an approach that exploits the geometry of a 3D mesh model obtained from multi-view reconstruction to predict the best view for each face of the mesh before performing the actual semantic image labeling. This allows them to accelerate the pipeline by two orders of magnitude.
- 用于自主车辆的语义分割的一个重要应用是将街道侧图像（即，建筑物立面）分割成其部件（墙壁，门，窗，植被，阳台，商店，邮箱等）。 这样的语义分割对于精确的3D重建，高效的内存记录，三维映射，鲁棒的本地化以及路径规划都是有用的。
- Xiao＆Quan（2009）提出了一种用于安装在沿着街道行驶的汽车上拍摄的照相机拍摄的图像的多视图语义分割框架。具体来说，它们在多个视图中定义跨越多个像素的成对MRF，其中一元项基于2D和3D特征。此外，它们使颜色差异最小化，使空间平滑度和密集的对应关系在不同视图之间实现平滑度。用于多视图语义分割的现有方法通常需要标注用于3D模型的所有图像中的所有像素，其取决于语义分割算法可能会非常缓慢。为了提高效率，Riemenschneider等（2014）利用3D模型中所有重叠图像的标签固有冗余。他们提出了一种方法，利用从多视图重建获得的3D网格模型的几何，以便在执行实际的语义图像标记之前预测网格的每个面的最佳视图。这允许他们加速管道两个数量级。

- Gadde et al. (2016b) describe a system for segmentation of 2D images and 3D point clouds of building facades that is fast at inference time and is easily adaptable to new datasets. In contrast to existing methods which exploit the structure of facade images by imposing strong priors, they implement a sequence of boosted decision tree classifiers, that are stacked using auto-context features and learn all correlations from data.
- Xiao et al. (2009) propose another method to generate streetside 3D photo-realistic models from images captured at ground level. In particular, they segment each image into semantically meaningful areas, such as building, sky, ground, vegetation or car. Then, they partition buildings into independent blocks and employ a regularization term by exploiting architectural priors in the orthographic view for inference. This allows them to cope with noisy and missing reconstructed 3D data and produces visually compelling results.
- Gadde等 （2016b）描述了一种在推理时间快的建筑立面的2D图像和3D点云的分割系统，并且易于适应新的数据集。 与通过强加优先权利用立面图像结构的现有方法相比，它们实现了一系列增强的决策树分类器，它们使用自动上下文特征进行堆叠，并从数据中学习所有相关性。
- Xiao等 （2009）提出了另一种方法，从地面捕获的图像生成街头3D逼真模型。 特别是，它们将每个图像分割成语义有意义的领域，例如建筑，天空，地面，植被或汽车。 然后，他们将建筑分成独立的块，并采用正则化术语，通过在正交视图中利用建筑先验来推断。 这使得它们能够应对嘈杂和缺失的重建3D数据，并产生视觉上令人信服的结果。

- Mathias et al. (2016) propose a flexible 3-layered method for segmentation of building facades which avoids the need for explicitly specifying a grammar. First, the facade is segmented into semantic classes which are combined with the output of detectors for architectural elements such as windows and door. Finally, weak architectural priors such as alignment, symmetry, co-occurrence are proposed which encourage the reconstruction to be architecturally consistent. The complete pipeline is illustrated in Figure 16. In contrast to the majority of semantic facade modeling approaches that treat facades as planar surfaces, Martinovi´c et al. (2015) propose an approach for facade modeling which operates directly in 3D. As their approach avoids time-consuming conversions between 2D and 3D representations, they obtain substantially shorter runtime. Specifically, they reconstruct a semi-dense 3D point cloud using SfM and classify each point using a Random Forest classifier trained on 3D features. Afterwards, they separate individual facades based on their semantic structure and impose weak architectural priors.
- Mathias等人（2016）提出了一种灵活的3层分层建筑立面分割方法，避免了明确指定语法的需要。首先，门面被分割成语义类，它们与建筑元素如窗户和门的检测器的输出相结合。最后，提出了弱化的建筑先验，如对齐，对称，同现，鼓励重建在架构上保持一致。完整的流水线如图16所示。与将正面视为平面曲面的大多数语义外观建模方法相反，Martinovi'c et al。 （2015）提出了一种立体建模方法，可直接在3D中进行操作。由于他们的方法避免了2D和3D表示之间耗时的转换，所以它们获得了更短的运行时间。具体来说，他们使用SfM重建半密度3D点云，并使用经过3D特征训练的随机森林分类器对每个点进行分类。之后，他们根据自己的语义结构分开了各个立面，强化了体系结构先验。

- 6.6. Semantic Segmentation of Aerial Images 空中图像的语义分割
- The aim of aerial image parsing is the automated extraction of urban objects from data acquired by airborne sensors. The need for accurate and detailed information for urban objects such as roads is rapidly increasing because of its applications in navigation of autonomous driving systems. For example, aerial image parses can be used to automatically build road maps (even in remote areas) and keep them up-to-date. Furthermore, information from aerial images can be used for localization. However, the problem is challenging because of the heterogeneous appearance of objects like buildings, streets, trees and cars which results in high intra-class variance but low inter-class variance. Furthermore, the complex structure of the prior complicates inference. For instance, roads must form a connected network of thin segments with slowly changing curvatures which meet at junctions. This type of prior knowledge is more challenging to formalize and integrate into a structured prediction formulation than standard smoothness assumptions.
- 空中图像解析的目的是通过机载传感器获取的数据自动提取城市对象。由于其在自主驾驶系统的导航中的应用，对诸如道路等城市对象的准确详细信息的需求正在迅速增长。例如，航空图像解析可以用于自动构建路线图（甚至在偏远地区），并保持最新。此外，来自航空图像的信息可以用于定位。然而，这个问题是具有挑战性的，因为像建筑物，街道，树木和汽车这样的物体的外观异乎寻常，导致班内差异很大，班级间差异较小。此外，复杂的结构先前复杂化推理。例如，道路必须形成具有缓慢变化的曲率的薄段的连接网络，其在交叉点处相遇。这种类型的先验知识比标准平滑度假设更具挑战性，将其形式化并结合到结构化预测公式中。

- Wegner et al. (2013) propose a CRF formulation for road labeling in which the prior is represented by cliques that connect sets of superpixels along straight line segments. Specifically, they formulate the constraints as high-order cliques with asymmetric $P^N$-potentials which express a preference to assign all rather than just some of their constituent superpixels to the road class. This allows the road likelihood to be amplified for thin chains while still being amenable to efficient inference using graph cuts. Wegner et al. (2015) also model the road network using a CRF with long-range, higher-order cliques. However, unlike Wegner et al. (2013), they allow for arbitrarily shaped segments which adapt to more complex road shapes by searching for putative roads with minimum cost paths based on local features. Montoya et al. (2015) extend this formulation to multi-label classification of aerial images with class-specific priors for buildings and roads. In addition to the road network prior of Wegner et al. (2015), they introduce a second higher order potential for cliques specific to buildings.
- Wegner et al。 （2013）提出了一种用于道路标记的CRF公式，其中先前由通过沿直线段连接超像素组的分支来表示。具体来说，他们将约束作为具有不对称的PN-totentials的高阶组合，它们表示偏好将所有而不仅仅是他们的组成超像素的一些分配给道路类。这允许对于细链可以扩大道路的可能性，同时仍然可以使用图形切割进行有效的推断。 Wegner et al。 （2015年）还使用具有远程，高阶组合的CRF对道路网进行建模。然而，与Wegner等人不同（2013），它们允许通过基于局部特征搜索具有最小成本路径的推定道路来适应更复杂的道路形状的任意形状的段。 Montoya等人（2015年）将此方案扩展到具有类别特色的建筑物和道路先进的航空图像多标签分类。除了Wegner等人之前的道路网络之外（2015年），它们为特定建筑物的集团引入了第二高的潜力。

- In contrast to other methods, Verdie & Lafarge (2014) propose the application of Markov point processes for recovering specific structures from images, including road networks. Markov point processes are a generalization of traditional MRFs which can address object recognition problems by directly manipulating parametric entities such as line segments, whereas MRFs are restricted to labeling problems. Importantly, they implicitly solve the model-selection problem, i.e., they allow for an arbitrary number of variables in the MRF which can be associated with the parameters of the objects of interest. Specifically for road segmentation, the parametric representation of road segments is chosen as a point at the center of mass of the segment and two additional parameters modeling the length and orientation of the road segment.
- 与其他方法相反，Verdie＆Lafarge（2014）提出了马尔科夫点处理从图像恢复特定结构的应用，包括道路网络。 马可夫点过程是传统MRF的概括，可以通过直接操纵诸如线段的参数实体来解决对象识别问题，而MRF仅限于标签问题。 重要的是，它们隐含地解决了模型选择问题，即它们允许可以与感兴趣对象的参数相关联的MRF中的任意数量的变量。 特别针对道路分割，道路段的参数化表示被选择为段的质心点，以及两个额外的参数来建模道路段的长度和方位。

- **Aerial Image Parsing using Maps**: Instead of framing the problem of detecting topologically correct road network as a semantic segmentation problem, Mattyus et al. (2015) exploit map information from OpenStreetMap (OSM)27. OSM is a collection of roads, trails, caf´es, railway stations and much more all over the world contributed and maintained by a community of mappers. It provides freely available maps of the road topology in the form of piece-wise linear road segments. Given a road map from OSM, Mattyus et al. (2015) propose an MRF which reasons about the location of the road centerline and its width for each road segment in OSM. In addition, they incorporate smoothness between consecutive line segments by encouraging their widths to be similar. This formulation has the advantage that it enables efficient inference while restricting the road topology to the OSM map.
- 使用地图的空中图像分析：Mattyus等人，不是将拓扑正确的道路网络检测为语义分割问题的问题。 （2015）利用OpenStreetMap（OSM）27的地图信息。 OSM是一个道路，小径，咖啡馆，火车站的集合，还有世界各地由映射者社区贡献和维护的。 它以分段线性路段的形式提供道路拓扑的免费地图。 给出了OSM的路线图，Mattyus等人 （2015）提出一个MRF，说明道路中心线的位置及其在OSM中每个路段的宽度的原因。 此外，它们通过鼓励它们的宽度相似而在连续线段之间融合平滑度。 该公式的优点是能够有效地推理，同时将道路拓扑限制到OSM地图。

- **Fine-grained Image Parsing with Aerial-to-ground Reasoning**: While aerial images provide full coverage of a significant portion of the world, they are of much lower resolution than ground images. In aerial imagery the resolution relates to the ground area covered by one pixel. Whereas 1 meter resolution is already a high resolution for satellite imagery, the standard resolution for most image databases (e.g. Google Earth) is 12 inch. Resolutions of 6 to 1 inch are considered high resolutions for aerial imagery and are usually not publicly available. This makes fine grained segmentation from aerial images a challenging problem. On the other hand, ground images provide additional information which enables fine-grained semantic segmentation. Motivated by the complementary nature of these cues, several methods for fine grained segmentation have been recently proposed which jointly reason about co-located aerial and ground image pairs.
- 具有空中对地推理的细粒度图像解析：虽然空中图像提供了全世界相当大部分的全面覆盖，但它们的分辨率远低于地面图像。 在空中影像中，分辨率与一个像素覆盖的地面相关。 虽然1米分辨率已经是卫星图像的高分辨率，但大多数图像数据库（例如Google Earth）的标准分辨率为12英寸。 6至1英寸的分辨率被认为是高分辨率的航空影像，通常不是公开的。 这使得空中图像的细粒度分割成为一个具有挑战性的问题。 另一方面，地面图像提供了能够进行细粒度语义分割的附加信息。 由于这些线索的互补性质，最近提出了几种细粒度分割方法，这些方法共同地说明了共同定位的天线和地面图像对。

- Mattyus et al. (2016) extend the approach of Mattyus et al. (2015) by introducing a formulation that reasons about fine-grained road semantics such as lanes and sidewalks. To infer this information, they jointly consider monocular aerial images and high-resolution stereo images captured from ground vehicles. Specifically, they formulate the problem as energy minimization in an MRF, inferring the number and location of the lanes for each road segment, all parking spots and sidewalks along with the alignment between the ground and aerial images. Towards this goal, they exploit deep learning to estimate semantics from aerial and ground images and define potentials exploiting both cues. In addition, they define potentials which model road constraints like relationships between parallel roads and the smoothness along roads.
- In a related work, Wegner et al. (2016) build a map of trees for urban planning applications from aerial images, street view images and semantic map data. They train CNN based object detection algorithms on human-annotated data. Furthermore, they combine the CNN predictions from multiple street view images and aerial images with map data in a CRF formulation to achieve a geolocated fine-grained catalog.
- Mattyus等人 （2016）扩展了Mattyus等人的方法。 （2015）通过介绍道路和人行道等细粒度道路语义的原因。 为了推断这些信息，他们共同考虑从地面车辆捕获的单目空间图像和高分辨率立体图像。 具体来说，他们将MRF中的能量最小化问题制定出来，推断每个路段的车道数量和位置，所有停车点和人行道以及地面和航空图像之间的对齐。 为实现这一目标，他们利用深度学习来估计空中和地面图像的语义，并定义利用两种线索的潜力。 此外，他们界定了模拟道路约束的潜力，如平行道路之间的关系以及道路的平滑度。
- 在相关的工作中，Wegner et al。 （2016）从航空图像，街景图像和语义地图数据构建城市规划应用的树木地图。 他们在人工数据上训练基于CNN的对象检测算法。 此外，它们将来自多个街景图像和航空图像的CNN预测与CRF公式中的地图数据相结合，以实现地理位置的细粒度目录。

- 6.6.1. ISPRS Segmentation Challenge ISPRS分段挑战
- The focus of the ISPRS segmentation challenge (Rottensteiner et al. (2013, 2014)) is detailed 2D semantic segmentation of data acquired by airborne sensors as shown in Figure17. More specifically, the task is to assign labels to multiple urban object categories. The challenge comprises two airborne image datasets, Vaihingen and Potsdam, which have been manually annotated by the six most common land cover classes, namely impervious surfaces, building, vegetation, tree, car, clutter/background. Both areas cover urban scenes. The leaderboards of the datasets Potsdam and Vaihingen are provided in the Table 5. The performance of the approaches is assessed with the F1 scores for the six classes and overall
- ISPRS分段挑战的重点（Rottensteiner等（2013，2014））详细描述了机载传感器获取的数据的2D语义分割，如图17所示。 更具体地说，任务是将标签分配给多个城市对象类别。 挑战包括两个机载图像数据集，Vaihingen和波茨坦，这些数据已经被六个最常见的土地覆盖类别手工注释，即不透水表面，建筑物，植被，树木，汽车，杂波/背景。 这两个区域都是城市场景。 数据集Potsdam和Vaihingen的排行榜在表5中提供。该方法的表现用六个等级和总体的F1分数进行评估。

- Paisitkriangkrai et al. (2015) is one of the best-performing methods in the ISPRS segmentation challenge. They propose a semantic pixel labeling method which combines CNN features with hand-crafted features in a pixel-wise CRF formulation to infer a globally consistent labeling that is locally smooth except at edges. Sherrah (2016) propose to use fully-convolutional networks without any downsampling layers to preserve the resolution of the output. In order to make use of elevation data, they propose a hybrid network that combines the pre-trained image features with features based on available digital surface models (DSM) which capture the Earth’s surface. Sherrah (2016) achieve the best performance on the ISPRS Potsdam (Table 5a) and competitive results on Vaihingen in Table 5b.
- Paisitkriangkrai等 （2015）是ISPRS分段挑战中最好的方法之一。 他们提出了一种语义像素标记方法，其将CNN特征与以像素为单位的CRF公式中的手工特征相结合，以推断除了边缘之外局部平滑的全局一致的标记。 Sherrah（2016）建议使用完全卷积网络，而不需要任何下采样层来保持输出的分辨率。 为了利用高程数据，他们提出了一种混合网络，其将预先训练的图像特征与基于捕获地球表面的可用数字表面模型（DSM）的特征相结合。 Sherrah（2016）在表5b中的“Vaihingen”上获得了最佳表现（表5a）和竞争结果。

- Maggiori et al. (2016) introduce a model which extracts spatial features at multiple resolutions and learns how to combine them in order to integrate local and global information. Audebert et al. (2016) further improved the state-of-the-art for dense scene labeling of aerial images by exploiting the encoder-decoder architecture of SegNet (Badrinarayanan et al. (2015)). In addition, they introduce a multi-kernel convolutional layer for fast aggregation of predictions at multiple scales and perform data fusion from heterogeneous sensors using a residual correction network. Marmanis et al. (2016a) demonstrate the best performance on the ISPRS Vaihingen challenge in Table 5b. They use their previous work Marmanis et al. (2016b) which uses an ensemble of fully convolutional networks to obtain pixel-wise classification at full resolution of aerial images. Marmanis et al. (2016a) propose to compensate the loss of spatial resolution due to the pooling layers by combining semantic segmentation with edge detection.
- Maggiori等人（2016）介绍了一种以多种分辨率提取空间特征的模型，并学习如何组合它们，以便整合本地和全球信息。 Audebert等（2016年）通过利用SegNet编码器 - 解码器架构（Badrinarayanan等（2015））进一步改进了航空图像密集场景标记的最新技术。此外，它们引入了一个多内核卷积层，用于在多个尺度上快速聚合预测，并使用残差校正网络执行异构传感器的数据融合。 Marmanis等人（2016a）在表5b中证明了ISPRS Vaihingen挑战的最佳性能。他们使用他们以前的工作Marmanis et al。 （2016b），其使用完整卷积网络的集合来获得全分辨率的空间图像的像素分类。 Marmanis等人（2016a）提出通过将语义分割与边缘检测相结合来补偿由于汇集层造成的空间分辨率的损失。

- 6.7. Road Segmentation 道路分割
- Segmentation of road scenes is a crucial problem in computer vision for applications such as autonomous driving and pedestrian detection. For instance, in order to navigate, an autonomous vehicle needs to determine the drivable free space ahead and determine its own position on the road with respect to the lane markings. However, the problem is challenging due to the presence of a variety of differently shaped objects such as cars and people, different road types and varying illumination and weather conditions.
- Munoz et al. (2010) propose an alternative to standard inference in graphical models for semantic labeling of scenes. In particular, they train a sequence of inference models in a hierarchical procedure that captures the context over large regions. This allows them to bypass the difficulties of training structured prediction models when exact inference is intractable and leads to a very efficient and accurate scene labeling algorithm.
- Kuehnl et al. (2012) propose a method that aims to improve appearance-based classification by incorporating the spatial layout of the scene. Specifically, they propose a two-stage approach for road segmentation. First, they represent the road surface and delimiting elements such as curbstones and lane-markings using confidence maps based on local visual features. From these confidence maps, they extract SPatial RAY (SPRAY) features that incorporate global properties of the scene and train a classifier on those features. Their evaluation shows that spatial layout helps especially for the cases where there is a clear structural correspondence between properties at different spatial locations.
- 道路场景的分割是自动驾驶和行人检测等应用的计算机视觉中的关键问题。 例如，为了导航，自主车辆需要确定前方的可驾驶自由空间，并且相对于车道标记确定其在道路上的位置。 然而，由于存在各种不同形状的物体，例如汽车和人，不同的道路类型和不同的照明和天气条件，问题是具有挑战性的。
- Munoz等人 （2010）提出了场景语义标注图形模型中标准推理的替代方法。 特别地，他们在分层程序中训练一系列推理模型，以捕获大区域上下文。 这样就可以避免训练结构化预测模型的困难，当精确推理是棘手的，并导致非常有效和准确的场景标记算法
- Kuehnl et al。 （2012）提出了一种旨在通过结合场景的空间布局来改进基于外观的分类的方法。 具体来说，他们提出了一个两阶段的道路分割方法。 首先，它们使用基于局部视觉特征的置信图来代表路面和划线元素，例如路缘石和车道标记。 从这些置信图中，他们提取了包含场景全局属性的空间RAY（SPRAY）功能，并对这些特征进行了分类。 他们的评估表明，空间布局特别适用于在不同空间位置的属性之间存在明确的结构对应关系的情况

- Alvarez et al. (2010) propose a Bayesian framework to classify road sequences by combining low-level appearance cues with contextual 3D road cues such as horizon lines, vanishing points, 3D scene layout and 3D road stages. In addition, they extract temporal cues for temporal smoothing of the results. In a follow-up work, A´ lvarez & Lo´pez (2011) convert the image into an illuminant invariant feature space to make their method robust to shadows and then apply a classifier to assign a semantic label to each pixel. Mansinghka et al. (2013) propose an inverse-graphics inspired method employing generative probabilistic graphics programs (GPGP) to infer roads in images taken from vehicle-mounted cameras. GPGPs consist of a stochastic scene generator for generating random samples from a road scene prior, a graphics renderer for rendering the image segmentation for each sample and a stochastic likelihood model linking the renderer’s output and the data.
- CNN-based Methods: Almost all existing algorithms for labeling road scenes are based on machine learning where the parameters of the model are estimated from large annotated datasets. To alleviate the burden of annotating large datasets manually, A´ lvarez et al. (2012) propose a method for road segmentation where noisy training labels for road images are generated using a convolutional neural network trained on a general image database. They further propose a texture descriptor which is based on learning a linear combination of color planes to reduce variability in road texture.
- Alvarez et al（2010）提出了一个贝叶斯框架，通过结合低级别的外观线索与上下文3D路线线索（如地平线，消失点，3D场景布局和3D路段）来分类道路序列。 此外，它们提取时间线索以便对结果进行时间平滑。 在后续工作中，A'lvarez＆Lo'pez（2011）将图像转换为光源不变特征空间，使其方法对阴影有效，然后应用分类器为每个像素分配语义标签。 曼辛哈卡等人 （2013）提出了一种利用生成概率图形程序（GPGP）来推导从车载摄像机拍摄的图像中的道路的逆图形启发方法。 GPGP由随机场景发生器组成，用于从道路场景生成随机样本，用于渲染每个样本的图像分割的图形渲染器以及链接渲染器的输出和数据的随机似然模型。
- 基于CNN的方法：几乎所有现有的用于标记道路场景的算法都是基于机器学习，其中模型的参数是从大的注释数据集估计的。 为了减轻手动注释大数据集的负担，A'lvarez et al。 （2012）提出了一种用于道路分割的方法，其中使用在一般图像数据库上训练的卷积神经网络来生成道路图像的噪声训练标签。 他们进一步提出了一种纹理描述符，其基于学习颜色的线性组合以减少道路纹理的变异性。

- Mohan (2014) propose a scene parsing system using deconvolutional layers in combination with traditional CNNs. Deconvolutional layers learn features that capture mid-level cues such as edge intersections, parallelism and symmetry in image data and thus obtain a more robust representation than regular CNNs. Oliveira et al. (2016) investigate the trade-off between segmentation quality and runtime using U-Nets by Ronneberger et al. (2015). Specifically, they introduce a new mapping between classes and filters at the up-convolutional part of the network to reduce the runtime. They further segment the whole image with a single forward pass, which makes the approach more efficient than patch-based approaches.
- To mitigate the difficulties in acquiring human annotations, Laddha et al. (2016) propose a map-supervised deep learning pipeline which does not require human annotations for training a road segmentation algorithm. Instead, they obtain ground truth labels based on OpenStreetMap information projected into the image domain using the vehicle pose given by the GPS sensor.
- Mohan（2014）提出了一种使用去卷积层与传统CNN相结合的场景解析系统。 解卷积层学习捕获中级线索的特征，例如图像数据中的边缘交点，并行度和对称性，从而获得比常规CNN更强的表示。 Oliveira等人 （2016）研究了Ronneberger等人使用U-Nets进行分割质量和运行时间之间的权衡。（2015年）。 具体来说，它们在网络的上卷积部分引入类和过滤器之间的新映射，以减少运行时间。 他们进一步将整个图像分割成一个单一的向前传递，这使得该方法比基于补丁的方法更有效率。
- 为了缓解人类注解的缺陷，Laddha等 （2016）提出了一种地图监督的深层学习管道，不需要人为注释来训练道路分割算法。 相反，他们使用GPS传感器给出的车辆姿态，基于投影到图像域中的OpenStreetMap信息获得地面真实标签。

- 6.7.1. Free Space Estimation 自由空间估计
- Accurate and reliable estimation of free space and detection of obstacles are core problems that need to be solved to enable autonomous driving. Free space is defined by the available space on the ground surface where navigation of vehicle is guaranteed without collision. Obstacles refer to structures that block the path of the vehicle by sticking out of the ground surface. In contrast to road segmentation approaches, methods for estimating the free-space in front of a vehicle often rely on geometric features as derived from a depth map computed from stereo sensors. However, both approaches can be advantageously combined.
- Badino et al. (2007) propose a method for free space estimation by computing stochastic occupancy grids based on stereo information, where cells in a stochastic occupancy grid carry information about the likelihood of occupancy. Stereo information is integrated over time in order to reduce depth uncertainty. The boundary between free space and occupied space is robustly obtained using dynamic programming on the occupancy grid. This work laid the foundations for the Stixel representation, see Section 4 for an in-depth discussion. While the original method of Badino et al. (2007) makes the assumption of a planar road surface, this assumption is often violated in practice. To tackle more complicated road surfaces, Wedel et al. (2009) propose an algorithm which models non-planar road surfaces using B-splines. The surface parameters are estimated from stereo measurements and tracked over time using a Kalman filter.
- 准确可靠的自由空间估计和障碍物的检测是需要解决的核心问题，以实现自主驾驶。 自由空间由地面上的可用空间定义，车辆的导航保证没有碰撞。 障碍是指通过从地面伸出而阻挡车辆路径的结构。 与道路分割方法相反，用于估计车辆前方的自由空间的方法通常依赖于从立体声传感器计算的深度图导出的几何特征。 然而，可以有利地组合这两种方法。
- Badino等人 （2007）提出了一种基于立体声信息计算随机占用网格的自由空间估计方法，其中随机占用网格中的单元携带有关占用可能性的信息。 随着时间的推移，立体声信息被整合，以减少深度不确定性。 使用占用网格上的动态规划可以获得自由空间和占用空间之间的边界。 这项工作为Stixel代表奠定了基础，参见第4节进行了深入的讨论。 虽然Badino等人的原始方法 （2007）假设一个平面的路面，这个假设在实践中经常被违反。 为了解决更复杂的路面，Wedel等 （2009）提出了一种使用B样条模拟非平面路面的算法。 表面参数从立体测量估计，并使用卡尔曼滤波器随时间跟踪。

- Suleymanov et al. (2016) propose an online system to detect and drive on collision-free traversable paths, based on stereo estimation using a variational approach. In addition to free space detection, their approach also establishes a semantic segmentation of the scene, where labels include ground, sky, obstacles and vegetation. Fisheye cameras provide a wider field of view compared to regular cameras and allow for detection of obstacles closer to the car. H¨ane et al. (2015) propose a method for obstacle detection using monocular fisheye cameras. In order to reduce runtime, they avoid using visual odometry systems to provide accurate vehicle poses and instead rely on less accurate pose estimates from the wheel odometry.
- Long Range Obstacle Detection: The accuracy of obstacle detection methods at long range is a crucial factor for timely obstacle localization when the observer (i.e., the ego-vehicle) moves at high speed. Unfortunately, the error of stereo vision system increases quadratically with depth in contrast to laser range sensors or radar which do not suffer from this problem. To tackle this problem, Pinggera et al. (2015, 2016) propose long-range obstacle detection algorithms using stereo vision by exploiting geometric constraints on camera motion and planarity to formulate obstacle detection as a statistical hypothesis testing problem. Specifically, independent hypothesis tests are performed on small local patches distributed across the input images where free-space and obstacles are represented by the null and alternative hypothesis respectively. The detection results for an exemplary scene from their novel dataset is illustrated in Figure 18.
- Suleymanov等人 （2016）提出了一种基于使用变分方法的立体声估计的在无系统的无碰撞路径上进行检测和驱动的在线系统。 除了自由空间检测，他们的方法还建立了场景的语义分割，其中标签包括地面，天空，障碍物和植被。 与普通相机相比，鱼眼相机提供了更广阔的视野，并且能够检测靠近汽车的障碍物。 H¨ane等 （2015）提出了一种使用单眼鱼眼相机进行障碍物检测的方法。 为了减少运行时间，他们避免使用视觉测距系统来提供精确的车辆姿势，而是依靠轮距离测量的精确姿态估计
- 长距障碍检测：当观察者（即，自我 - 车辆）高速移动时，长距离障碍物检测方法的准确性是及时障碍物定位的关键因素。 不幸的是，立体视觉系统的误差随着深度的增加而增加，与激光距离传感器或雷达不同，该雷达不会受到此问题的影响。 为了解决这个问题，Pinggera等 （2015年，2016年）提出了使用立体视觉的远程障碍物检测算法，通过利用相机运动和平面度的几何约束来制定障碍物检测作为统计假设检验问题。 具体来说，对分布在输入图像上的小局部补丁执行独立假设检验，其中空间和障碍分别由空和替代假设表示。 图18中示出了来自其新颖数据集的示例场景的检测结果。
