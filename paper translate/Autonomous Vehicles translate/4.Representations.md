## Computer Vision for Autonomous Vehicles:Problems, Datasets and State-of-the-Art
自动驾驶技术的计算机视觉：问题，数据和前沿技术

### 4. Representations 表现
- A wide variety of representations at different levels of granularity is used in the computer vision literature. Variables or parameters can be associated directly with 2D pixels in an image or describe high-level primitives in 3D space. In pixel-based representation each pixel is a separate entity, for example a random variable in a graphical model. Pixels are amongst the most fine-grained representations, but are harder to relate to physical properties of our 3D world. Furthermore, pixel-based representations increase complexity of inference algorithms due to the large number of variables in high resolution images. As a consequence, many approaches model only local interactions between pixels which do not capture the structure of our world sufficiently well to overcome all ambiguities in the ill-posed inverse
problems computer vision is trying to solve.
- 在计算机视觉文献中使用了不同粒度级别的各种表示。 变量或参数可以直接与图像中的2D像素相关联，或者描述3D空间中的高级原语。 在基于像素的表示中，每个像素是一个单独的实体，例如图形模型中的随机变量。 像素是最细粒度的表示，但更难与3D世界的物理属性相关。 此外，由于高分辨率图像中的大量变量，基于像素的表示增加了推理算法的复杂性。 因此，许多方法仅模拟像素之间的局部相互作用，这些相互作用不能很好地捕获我们世界的结构，以克服不正确的逆向中的所有模棱两可
计算机视觉问题正在试图解决。

- **Superpixels**: Consequently, compact representations based on grouping of pixels, i.e. superpixels, have gained popularity. Superpixel-based representations are obtained by a segmentation of the image into atomic regions which are ideally similar in color and texture, and respect image boundaries (Ren & Malik (2003); Achanta et al. (2012); Li & Chen (2015)). The implicit assumption each superpixel-based method makes is that certain properties of interest remain constant within a superpixel, e.g., the semantic class label or the slant of a surface. However, boundary adherence with respect to these properties is easily violated, especially for cluttered images when relying on standard segmentation algorithms which leverage color or intensity cues.
- If available, depth information can be leveraged as valuable feature for accurate superpixel extraction (Badino et al.(2009); Yamaguchi et al. (2014)). Superpixels are used as building blocks for various tasks such as stereo and flow estimation (Yamaguchi et al. (2012, 2013, 2014); G¨uney & Geiger (2015); Bai et al. (2016)), scene flow (Menze & Geiger (2015); Menze et al. (2015b); Lv et al. (2016)), semantic segmentation (Xiao & Quan (2009); Wegner et al. (2013)), scene understanding (Ess et al. (2009b); Liu et al. (2014)) and 3D reconstruction (Sch¨onbein et al. (2014)). In cases that include geometric reasoning
such as stereo estimation, superpixels often represent 3D planar segments. When the goal is to represent real-world scenes with independent object motion as in scene flow or optical flow, superpixels can be generalized to rigidly moving segments (Vogel et al. (2015); Menze & Geiger (2015)), or semantic segments (Bai et al. (2016); Sevilla-Lara et al. (2016)).
- 超像素：因此，基于像素分组（即，超像素）的紧凑表示已经受欢迎。基于超像素的表示是通过将图像分割成在颜色和纹理理想上相似的原子区域和尊重图像边界来获得的（Ren＆Malik（2003）; Achanta等人（2012）; Li＆Chen（2015） ）。每个基于超像素的方法所产生的隐含假设是在某个超像素（例如，语义类标签或表面的倾斜）中保持一定的感兴趣的特性。然而，相对于这些属性的边界附着容易受到侵害，特别是对依赖于利用颜色或强度提示的标准分割算法的混乱图像。
- 如果可用，深度信息可以用作准确的超像素提取的有价值的特征（Badino等（2009）; Yamaguchi等（2014））。超像素被用作立体声和流量估计等各种任务的构建块（Yamaguchi et al。（2012，2013，2014）;G¨uney＆Geiger（2015）; Bai et al。（2016）），场景流（Menze ＆Geiger（2015）; Menze等（2015b）; Lv et al。（2016）），语义分割（Xiao＆Quan（2009）; Wegner等（2013）），场景理解（Ess et al。 2009b）; Liu et al。（2014））和3D重建（Sch¨onbein等（2014））。在包括几何推理的情况下
例如立体声估计，超像素通常表示3D平面片段。当目标是在场景流或光流中表现具有独立物体运动的现实世界场景时，可以将超像素推广到刚性移动段（Vogel等人（2015）; Menze＆Geiger（2015））或语义段（Bai et al。（2016）; Sevilla-Lara et al。（2016））。

- **Stixels**: Stixels are presented as a medium level representation of 3D traffic scenes with the goal to bridge the gap between pixels and objects (Badino et al. (2009)). The so-called “Stixel World” representation originates from the observation that free space in front of the vehicle is mostly limited by vertical surfaces. Stixels are represented by a set of rectangular sticks standing vertically on the ground to approximate these surfaces. Assuming a constant width, each stixel is defined by its 3D position relative to the camera and its height. The main goal is to gain eciency through a compact, complete, stable, and robust representation. In addition, Stixel representations provide an encoding of the free space and the obstacles in the scene.
- Using depth maps from SGM Hirschm¨uller (2008) as input, Badino et al. (2009) use dynamic programming based on occupancy grids to compute free space (determining the Stixels’ lower positions) and foreground/background segmentation on the disparity map (to compute the Stixels’ height). Pfeiffer & Franke (2011) extend Badino et al. (2009) to a unified probabilistic scheme. They lift the constraint of Stixels to touch the ground and allow multiple stixels along an image column. This way objects can be located at multiple depths in a single image column (Figure 5).
- Stixels：Stixels被呈现为3D流量场景的中等级别表示，目的是弥补像素和对象之间的差距（Badino等人（2009））。所谓的“Stixel World”表现起源于观察车前面的自由空间主要受垂直面的限制。柱状物由垂直放置在地面上的一组矩形棒表示以近似这些表面。假设一个恒定的宽度，每个Stixel是通过它相对于相机的3D位置及其高度来定义的。主要目标是通过紧凑，完整，稳定和强大的表现来提高效率。此外，Stixel表示提供了现场的自由空间和障碍物的编码。
- 使用SGMHirschm¨uller（2008）的深度图作为输入，Badino et al。 （2009）使用基于占用网格的动态规划来计算自由空间（确定Stixels的较低位置）和视差图上的前景/背景分割（以计算Stixels的高度）。 Pfeiffer＆Franke（2011）扩展了Badino等人（2009）统一概率方案。它们提升Stixels的约束以触摸地面，并允许沿着图像列的多个Stixels。这样，对象可以位于单个图像列中的多个深度（图5）。

- Pfeiffer & Franke (2010) extend the Stixel world representation to dynamic scenes by tracking stixels using a 6D Kalman filter framework and optical flow as input. Erbs et al. (2012, 2013) propose a CRF framework for segmenting a traffic scene based on the Dynamic StixelWorld representation. G¨unyel et al. (2012) show that motion estimation for stixels can be reduced to a 1D problem and can be solved eciently via 2D dynamic programming by avoiding costly dense optical flow computation.
- Levi et al. (2015) propose to use a CNN called StixelNet for learning to extract the foot point of each Stixel from the image. Cordts et al. (2014) propose to incorporate top-down objectlevel cues into bottom-up Stixel representation in a probabilistic approach. In order to achieve that, they leverage probability images derived from the output of three different object detectors, namely pedestrian, vehicle, and guard rail. Schneider et al.(2016) propose a semantic Stixel representation to jointly infer semantic and geometric layout of the scene from a dense disparity map and a pixel-level semantic scene labeling.
- Pfeiffer＆Franke（2010）通过使用6D卡尔曼滤波器框架和光流作为输入，通过跟踪Stixels将Stixel世界表示扩展到动态场景。 Erbs等人（2012年，2013年）提出了一个基于Dynamic StixelWorld表示来分割交通场景的CRF框架。 G¨unel等人（2012）显示，Stixels的运动估计可以减少到1D问题，可以通过2D动态编程有效地解决，避免了昂贵的密集光流计算。
- Levi et al。 （2015）建议使用名为StixelNet的CNN学习从图像中提取每个Stixel的脚点。 Cordts et al。 （2014）提出将自顶向下的物体等级线索纳入自下而上的Stixel表示法中，以概率方法。为了实现这一点，它们利用从三个不同物体检测器（即行人，车辆和护栏）的输出得到的概率图像。 Schneider等人（2016）提出了一种语义Stixel表示，从密集视差图和像素级语义场景标记共同推断场景的语义和几何布局。

- **3D Primitives**: The use of 3D geometric primitives is very common in 3D reconstruction, particularly when reconstructing urban areas. Atomic regions which are geometrically meaningful allow the shape of urban objects to be better preserved. In addition, simplified geometric assumptions can provide significant speedups as well as a compact model. In Cornelis et al.(2008), 3D city models are composed of ruled surfaces for both the facades and the roads. Duan & Lafarge (2016) use polygons with elevation estimate for 3D city modeling from pairs of satellite images. de Oliveira et al. (2016) update a list of large-scale polygons over time for an incremental scene representation from 3D range measurements. Lafarge et al. (2010) use a library of 3D blocks for reconstructing buildings with different roof forms. Lafarge & Mallet (2012); Lafarge et al. (2013) use 3D-primitives such as planes, cylinders, spheres or cones for describing regular structures of the scene. Dub´e et al. (2016) segments point clouds into distinct elements for a loop-closure detection algorithm based on the matching of 3D segments.
- 3D原语：在3D重建中使用3D几何图元非常常见，特别是在重建城市地区时。几何有意义的原子区域可以更好地保存城市物体的形状。此外，简化的几何假设可以提供显着的加速以及紧凑的模型。在Cornelis等人（2008）中，3D城市模型由外墙和道路的统治曲面组成。 Duan＆Lafarge（2016）使用多边形，对卫星图像进行三维城市建模的高程估计。 de Oliveira et al。 （2016）根据3D范围测量更新一个随时间推移的大尺寸多边形的增量场景表示。拉法基等人（2010）使用3D块库来重建具有不同屋顶形式的建筑物。拉法基与马勒（2012）;拉法基等人（2013）使用3D原始图像，例如平面，圆柱体，球体或锥体来描述场景的常规结构。 Dub'e等人（2016）将云划分成基于3D段匹配的闭环检测算法的不同元素。
