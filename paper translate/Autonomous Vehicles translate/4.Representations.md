## Computer Vision for Autonomous Vehicles:Problems, Datasets and State-of-the-Art
è‡ªåŠ¨é©¾é©¶æŠ€æœ¯çš„è®¡ç®—æœºè§†è§‰ï¼šé—®é¢˜ï¼Œæ•°æ®å’Œå‰æ²¿æŠ€æœ¯

### 4. Representations è¡¨ç°
- A wide variety of representations at different levels of granularity is used in the computer vision literature. Variables or parameters can be associated directly with 2D pixels in an image or describe high-level primitives in 3D space. In pixel-based representation each pixel is a separate entity, for example a random variable in a graphical model. Pixels are amongst the most fine-grained representations, but are harder to relate to physical properties of our 3D world. Furthermore, pixel-based representations increase complexity of inference algorithms due to the large number of variables in high resolution images. As a consequence, many approaches model only local interactions between pixels which do not capture the structure of our world sufficiently well to overcome all ambiguities in the ill-posed inverse
problems computer vision is trying to solve.
- åœ¨è®¡ç®—æœºè§†è§‰æ–‡çŒ®ä¸­ä½¿ç”¨äº†ä¸åŒç²’åº¦çº§åˆ«çš„å„ç§è¡¨ç¤ºã€‚ å˜é‡æˆ–å‚æ•°å¯ä»¥ç›´æ¥ä¸å›¾åƒä¸­çš„2Dåƒç´ ç›¸å…³è”ï¼Œæˆ–è€…æè¿°3Dç©ºé—´ä¸­çš„é«˜çº§åŸè¯­ã€‚ åœ¨åŸºäºåƒç´ çš„è¡¨ç¤ºä¸­ï¼Œæ¯ä¸ªåƒç´ æ˜¯ä¸€ä¸ªå•ç‹¬çš„å®ä½“ï¼Œä¾‹å¦‚å›¾å½¢æ¨¡å‹ä¸­çš„éšæœºå˜é‡ã€‚ åƒç´ æ˜¯æœ€ç»†ç²’åº¦çš„è¡¨ç¤ºï¼Œä½†æ›´éš¾ä¸3Dä¸–ç•Œçš„ç‰©ç†å±æ€§ç›¸å…³ã€‚ æ­¤å¤–ï¼Œç”±äºé«˜åˆ†è¾¨ç‡å›¾åƒä¸­çš„å¤§é‡å˜é‡ï¼ŒåŸºäºåƒç´ çš„è¡¨ç¤ºå¢åŠ äº†æ¨ç†ç®—æ³•çš„å¤æ‚æ€§ã€‚ å› æ­¤ï¼Œè®¸å¤šæ–¹æ³•ä»…æ¨¡æ‹Ÿåƒç´ ä¹‹é—´çš„å±€éƒ¨ç›¸äº’ä½œç”¨ï¼Œè¿™äº›ç›¸äº’ä½œç”¨ä¸èƒ½å¾ˆå¥½åœ°æ•è·æˆ‘ä»¬ä¸–ç•Œçš„ç»“æ„ï¼Œä»¥å…‹æœä¸æ­£ç¡®çš„é€†å‘ä¸­çš„æ‰€æœ‰æ¨¡æ£±ä¸¤å¯
è®¡ç®—æœºè§†è§‰é—®é¢˜æ­£åœ¨è¯•å›¾è§£å†³ã€‚

- **Superpixels**: Consequently, compact representations based on grouping of pixels, i.e. superpixels, have gained popularity. Superpixel-based representations are obtained by a segmentation of the image into atomic regions which are ideally similar in color and texture, and respect image boundaries (Ren & Malik (2003); Achanta et al. (2012); Li & Chen (2015)). The implicit assumption each superpixel-based method makes is that certain properties of interest remain constant within a superpixel, e.g., the semantic class label or the slant of a surface. However, boundary adherence with respect to these properties is easily violated, especially for cluttered images when relying on standard segmentation algorithms which leverage color or intensity cues.
- If available, depth information can be leveraged as valuable feature for accurate superpixel extraction (Badino et al.(2009); Yamaguchi et al. (2014)). Superpixels are used as building blocks for various tasks such as stereo and flow estimation (Yamaguchi et al. (2012, 2013, 2014); GÂ¨uney & Geiger (2015); Bai et al. (2016)), scene flow (Menze & Geiger (2015); Menze et al. (2015b); Lv et al. (2016)), semantic segmentation (Xiao & Quan (2009); Wegner et al. (2013)), scene understanding (Ess et al. (2009b); Liu et al. (2014)) and 3D reconstruction (SchÂ¨onbein et al. (2014)). In cases that include geometric reasoning
such as stereo estimation, superpixels often represent 3D planar segments. When the goal is to represent real-world scenes with independent object motion as in scene flow or optical flow, superpixels can be generalized to rigidly moving segments (Vogel et al. (2015); Menze & Geiger (2015)), or semantic segments (Bai et al. (2016); Sevilla-Lara et al. (2016)).
- è¶…åƒç´ ï¼šå› æ­¤ï¼ŒåŸºäºåƒç´ åˆ†ç»„ï¼ˆå³ï¼Œè¶…åƒç´ ï¼‰çš„ç´§å‡‘è¡¨ç¤ºå·²ç»å—æ¬¢è¿ã€‚åŸºäºè¶…åƒç´ çš„è¡¨ç¤ºæ˜¯é€šè¿‡å°†å›¾åƒåˆ†å‰²æˆåœ¨é¢œè‰²å’Œçº¹ç†ç†æƒ³ä¸Šç›¸ä¼¼çš„åŸå­åŒºåŸŸå’Œå°Šé‡å›¾åƒè¾¹ç•Œæ¥è·å¾—çš„ï¼ˆRenï¼†Malikï¼ˆ2003ï¼‰; Achantaç­‰äººï¼ˆ2012ï¼‰; Liï¼†Chenï¼ˆ2015ï¼‰ ï¼‰ã€‚æ¯ä¸ªåŸºäºè¶…åƒç´ çš„æ–¹æ³•æ‰€äº§ç”Ÿçš„éšå«å‡è®¾æ˜¯åœ¨æŸä¸ªè¶…åƒç´ ï¼ˆä¾‹å¦‚ï¼Œè¯­ä¹‰ç±»æ ‡ç­¾æˆ–è¡¨é¢çš„å€¾æ–œï¼‰ä¸­ä¿æŒä¸€å®šçš„æ„Ÿå…´è¶£çš„ç‰¹æ€§ã€‚ç„¶è€Œï¼Œç›¸å¯¹äºè¿™äº›å±æ€§çš„è¾¹ç•Œé™„ç€å®¹æ˜“å—åˆ°ä¾µå®³ï¼Œç‰¹åˆ«æ˜¯å¯¹ä¾èµ–äºåˆ©ç”¨é¢œè‰²æˆ–å¼ºåº¦æç¤ºçš„æ ‡å‡†åˆ†å‰²ç®—æ³•çš„æ··ä¹±å›¾åƒã€‚
- å¦‚æœå¯ç”¨ï¼Œæ·±åº¦ä¿¡æ¯å¯ä»¥ç”¨ä½œå‡†ç¡®çš„è¶…åƒç´ æå–çš„æœ‰ä»·å€¼çš„ç‰¹å¾ï¼ˆBadinoç­‰ï¼ˆ2009ï¼‰; Yamaguchiç­‰ï¼ˆ2014ï¼‰ï¼‰ã€‚è¶…åƒç´ è¢«ç”¨ä½œç«‹ä½“å£°å’Œæµé‡ä¼°è®¡ç­‰å„ç§ä»»åŠ¡çš„æ„å»ºå—ï¼ˆYamaguchi et alã€‚ï¼ˆ2012ï¼Œ2013ï¼Œ2014ï¼‰;GÂ¨uneyï¼†Geigerï¼ˆ2015ï¼‰; Bai et alã€‚ï¼ˆ2016ï¼‰ï¼‰ï¼Œåœºæ™¯æµï¼ˆMenze ï¼†Geigerï¼ˆ2015ï¼‰; Menzeç­‰ï¼ˆ2015bï¼‰; Lv et alã€‚ï¼ˆ2016ï¼‰ï¼‰ï¼Œè¯­ä¹‰åˆ†å‰²ï¼ˆXiaoï¼†Quanï¼ˆ2009ï¼‰; Wegnerç­‰ï¼ˆ2013ï¼‰ï¼‰ï¼Œåœºæ™¯ç†è§£ï¼ˆEss et alã€‚ 2009bï¼‰; Liu et alã€‚ï¼ˆ2014ï¼‰ï¼‰å’Œ3Dé‡å»ºï¼ˆSchÂ¨onbeinç­‰ï¼ˆ2014ï¼‰ï¼‰ã€‚åœ¨åŒ…æ‹¬å‡ ä½•æ¨ç†çš„æƒ…å†µä¸‹
ä¾‹å¦‚ç«‹ä½“å£°ä¼°è®¡ï¼Œè¶…åƒç´ é€šå¸¸è¡¨ç¤º3Då¹³é¢ç‰‡æ®µã€‚å½“ç›®æ ‡æ˜¯åœ¨åœºæ™¯æµæˆ–å…‰æµä¸­è¡¨ç°å…·æœ‰ç‹¬ç«‹ç‰©ä½“è¿åŠ¨çš„ç°å®ä¸–ç•Œåœºæ™¯æ—¶ï¼Œå¯ä»¥å°†è¶…åƒç´ æ¨å¹¿åˆ°åˆšæ€§ç§»åŠ¨æ®µï¼ˆVogelç­‰äººï¼ˆ2015ï¼‰; Menzeï¼†Geigerï¼ˆ2015ï¼‰ï¼‰æˆ–è¯­ä¹‰æ®µï¼ˆBai et alã€‚ï¼ˆ2016ï¼‰; Sevilla-Lara et alã€‚ï¼ˆ2016ï¼‰ï¼‰ã€‚

- **Stixels**: Stixels are presented as a medium level representation of 3D traffic scenes with the goal to bridge the gap between pixels and objects (Badino et al. (2009)). The so-called â€œStixel Worldâ€ representation originates from the observation that free space in front of the vehicle is mostly limited by vertical surfaces. Stixels are represented by a set of rectangular sticks standing vertically on the ground to approximate these surfaces. Assuming a constant width, each stixel is defined by its 3D position relative to the camera and its height. The main goal is to gain eciency through a compact, complete, stable, and robust representation. In addition, Stixel representations provide an encoding of the free space and the obstacles in the scene.
- Using depth maps from SGM HirschmÂ¨uller (2008) as input, Badino et al. (2009) use dynamic programming based on occupancy grids to compute free space (determining the Stixelsâ€™ lower positions) and foreground/background segmentation on the disparity map (to compute the Stixelsâ€™ height). Pfeiffer & Franke (2011) extend Badino et al. (2009) to a unified probabilistic scheme. They lift the constraint of Stixels to touch the ground and allow multiple stixels along an image column. This way objects can be located at multiple depths in a single image column (Figure 5).
- Stixelsï¼šStixelsè¢«å‘ˆç°ä¸º3Dæµé‡åœºæ™¯çš„ä¸­ç­‰çº§åˆ«è¡¨ç¤ºï¼Œç›®çš„æ˜¯å¼¥è¡¥åƒç´ å’Œå¯¹è±¡ä¹‹é—´çš„å·®è·ï¼ˆBadinoç­‰äººï¼ˆ2009ï¼‰ï¼‰ã€‚æ‰€è°“çš„â€œStixel Worldâ€è¡¨ç°èµ·æºäºè§‚å¯Ÿè½¦å‰é¢çš„è‡ªç”±ç©ºé—´ä¸»è¦å—å‚ç›´é¢çš„é™åˆ¶ã€‚æŸ±çŠ¶ç‰©ç”±å‚ç›´æ”¾ç½®åœ¨åœ°é¢ä¸Šçš„ä¸€ç»„çŸ©å½¢æ£’è¡¨ç¤ºä»¥è¿‘ä¼¼è¿™äº›è¡¨é¢ã€‚å‡è®¾ä¸€ä¸ªæ’å®šçš„å®½åº¦ï¼Œæ¯ä¸ªStixelæ˜¯é€šè¿‡å®ƒç›¸å¯¹äºç›¸æœºçš„3Dä½ç½®åŠå…¶é«˜åº¦æ¥å®šä¹‰çš„ã€‚ä¸»è¦ç›®æ ‡æ˜¯é€šè¿‡ç´§å‡‘ï¼Œå®Œæ•´ï¼Œç¨³å®šå’Œå¼ºå¤§çš„è¡¨ç°æ¥æé«˜æ•ˆç‡ã€‚æ­¤å¤–ï¼ŒStixelè¡¨ç¤ºæä¾›äº†ç°åœºçš„è‡ªç”±ç©ºé—´å’Œéšœç¢ç‰©çš„ç¼–ç ã€‚
- ä½¿ç”¨SGMHirschmÂ¨ullerï¼ˆ2008ï¼‰çš„æ·±åº¦å›¾ä½œä¸ºè¾“å…¥ï¼ŒBadino et alã€‚ ï¼ˆ2009ï¼‰ä½¿ç”¨åŸºäºå ç”¨ç½‘æ ¼çš„åŠ¨æ€è§„åˆ’æ¥è®¡ç®—è‡ªç”±ç©ºé—´ï¼ˆç¡®å®šStixelsçš„è¾ƒä½ä½ç½®ï¼‰å’Œè§†å·®å›¾ä¸Šçš„å‰æ™¯/èƒŒæ™¯åˆ†å‰²ï¼ˆä»¥è®¡ç®—Stixelsçš„é«˜åº¦ï¼‰ã€‚ Pfeifferï¼†Frankeï¼ˆ2011ï¼‰æ‰©å±•äº†Badinoç­‰äººï¼ˆ2009ï¼‰ç»Ÿä¸€æ¦‚ç‡æ–¹æ¡ˆã€‚å®ƒä»¬æå‡Stixelsçš„çº¦æŸä»¥è§¦æ‘¸åœ°é¢ï¼Œå¹¶å…è®¸æ²¿ç€å›¾åƒåˆ—çš„å¤šä¸ªStixelsã€‚è¿™æ ·ï¼Œå¯¹è±¡å¯ä»¥ä½äºå•ä¸ªå›¾åƒåˆ—ä¸­çš„å¤šä¸ªæ·±åº¦ï¼ˆå›¾5ï¼‰ã€‚

- Pfeiffer & Franke (2010) extend the Stixel world representation to dynamic scenes by tracking stixels using a 6D Kalman filter framework and optical flow as input. Erbs et al. (2012, 2013) propose a CRF framework for segmenting a traffic scene based on the Dynamic StixelWorld representation. GÂ¨unyel et al. (2012) show that motion estimation for stixels can be reduced to a 1D problem and can be solved eciently via 2D dynamic programming by avoiding costly dense optical flow computation.
- Levi et al. (2015) propose to use a CNN called StixelNet for learning to extract the foot point of each Stixel from the image. Cordts et al. (2014) propose to incorporate top-down objectlevel cues into bottom-up Stixel representation in a probabilistic approach. In order to achieve that, they leverage probability images derived from the output of three different object detectors, namely pedestrian, vehicle, and guard rail. Schneider et al.(2016) propose a semantic Stixel representation to jointly infer semantic and geometric layout of the scene from a dense disparity map and a pixel-level semantic scene labeling.
- Pfeifferï¼†Frankeï¼ˆ2010ï¼‰é€šè¿‡ä½¿ç”¨6Då¡å°”æ›¼æ»¤æ³¢å™¨æ¡†æ¶å’Œå…‰æµä½œä¸ºè¾“å…¥ï¼Œé€šè¿‡è·Ÿè¸ªStixelså°†Stixelä¸–ç•Œè¡¨ç¤ºæ‰©å±•åˆ°åŠ¨æ€åœºæ™¯ã€‚ Erbsç­‰äººï¼ˆ2012å¹´ï¼Œ2013å¹´ï¼‰æå‡ºäº†ä¸€ä¸ªåŸºäºDynamic StixelWorldè¡¨ç¤ºæ¥åˆ†å‰²äº¤é€šåœºæ™¯çš„CRFæ¡†æ¶ã€‚ GÂ¨unelç­‰äººï¼ˆ2012ï¼‰æ˜¾ç¤ºï¼ŒStixelsçš„è¿åŠ¨ä¼°è®¡å¯ä»¥å‡å°‘åˆ°1Dé—®é¢˜ï¼Œå¯ä»¥é€šè¿‡2DåŠ¨æ€ç¼–ç¨‹æœ‰æ•ˆåœ°è§£å†³ï¼Œé¿å…äº†æ˜‚è´µçš„å¯†é›†å…‰æµè®¡ç®—ã€‚
- Levi et alã€‚ ï¼ˆ2015ï¼‰å»ºè®®ä½¿ç”¨åä¸ºStixelNetçš„CNNå­¦ä¹ ä»å›¾åƒä¸­æå–æ¯ä¸ªStixelçš„è„šç‚¹ã€‚ Cordts et alã€‚ ï¼ˆ2014ï¼‰æå‡ºå°†è‡ªé¡¶å‘ä¸‹çš„ç‰©ä½“ç­‰çº§çº¿ç´¢çº³å…¥è‡ªä¸‹è€Œä¸Šçš„Stixelè¡¨ç¤ºæ³•ä¸­ï¼Œä»¥æ¦‚ç‡æ–¹æ³•ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œå®ƒä»¬åˆ©ç”¨ä»ä¸‰ä¸ªä¸åŒç‰©ä½“æ£€æµ‹å™¨ï¼ˆå³è¡Œäººï¼Œè½¦è¾†å’ŒæŠ¤æ ï¼‰çš„è¾“å‡ºå¾—åˆ°çš„æ¦‚ç‡å›¾åƒã€‚ Schneiderç­‰äººï¼ˆ2016ï¼‰æå‡ºäº†ä¸€ç§è¯­ä¹‰Stixelè¡¨ç¤ºï¼Œä»å¯†é›†è§†å·®å›¾å’Œåƒç´ çº§è¯­ä¹‰åœºæ™¯æ ‡è®°å…±åŒæ¨æ–­åœºæ™¯çš„è¯­ä¹‰å’Œå‡ ä½•å¸ƒå±€ã€‚

- **3D Primitives**: The use of 3D geometric primitives is very common in 3D reconstruction, particularly when reconstructing urban areas. Atomic regions which are geometrically meaningful allow the shape of urban objects to be better preserved. In addition, simplified geometric assumptions can provide significant speedups as well as a compact model. In Cornelis et al.(2008), 3D city models are composed of ruled surfaces for both the facades and the roads. Duan & Lafarge (2016) use polygons with elevation estimate for 3D city modeling from pairs of satellite images. de Oliveira et al. (2016) update a list of large-scale polygons over time for an incremental scene representation from 3D range measurements. Lafarge et al. (2010) use a library of 3D blocks for reconstructing buildings with different roof forms. Lafarge & Mallet (2012); Lafarge et al. (2013) use 3D-primitives such as planes, cylinders, spheres or cones for describing regular structures of the scene. DubÂ´e et al. (2016) segments point clouds into distinct elements for a loop-closure detection algorithm based on the matching of 3D segments.
- 3DåŸè¯­ï¼šåœ¨3Dé‡å»ºä¸­ä½¿ç”¨3Då‡ ä½•å›¾å…ƒéå¸¸å¸¸è§ï¼Œç‰¹åˆ«æ˜¯åœ¨é‡å»ºåŸå¸‚åœ°åŒºæ—¶ã€‚å‡ ä½•æœ‰æ„ä¹‰çš„åŸå­åŒºåŸŸå¯ä»¥æ›´å¥½åœ°ä¿å­˜åŸå¸‚ç‰©ä½“çš„å½¢çŠ¶ã€‚æ­¤å¤–ï¼Œç®€åŒ–çš„å‡ ä½•å‡è®¾å¯ä»¥æä¾›æ˜¾ç€çš„åŠ é€Ÿä»¥åŠç´§å‡‘çš„æ¨¡å‹ã€‚åœ¨Cornelisç­‰äººï¼ˆ2008ï¼‰ä¸­ï¼Œ3DåŸå¸‚æ¨¡å‹ç”±å¤–å¢™å’Œé“è·¯çš„ç»Ÿæ²»æ›²é¢ç»„æˆã€‚ Duanï¼†Lafargeï¼ˆ2016ï¼‰ä½¿ç”¨å¤šè¾¹å½¢ï¼Œå¯¹å«æ˜Ÿå›¾åƒè¿›è¡Œä¸‰ç»´åŸå¸‚å»ºæ¨¡çš„é«˜ç¨‹ä¼°è®¡ã€‚ de Oliveira et alã€‚ ï¼ˆ2016ï¼‰æ ¹æ®3DèŒƒå›´æµ‹é‡æ›´æ–°ä¸€ä¸ªéšæ—¶é—´æ¨ç§»çš„å¤§å°ºå¯¸å¤šè¾¹å½¢çš„å¢é‡åœºæ™¯è¡¨ç¤ºã€‚æ‹‰æ³•åŸºç­‰äººï¼ˆ2010ï¼‰ä½¿ç”¨3Då—åº“æ¥é‡å»ºå…·æœ‰ä¸åŒå±‹é¡¶å½¢å¼çš„å»ºç­‘ç‰©ã€‚æ‹‰æ³•åŸºä¸é©¬å‹’ï¼ˆ2012ï¼‰;æ‹‰æ³•åŸºç­‰äººï¼ˆ2013ï¼‰ä½¿ç”¨3DåŸå§‹å›¾åƒï¼Œä¾‹å¦‚å¹³é¢ï¼Œåœ†æŸ±ä½“ï¼Œçƒä½“æˆ–é”¥ä½“æ¥æè¿°åœºæ™¯çš„å¸¸è§„ç»“æ„ã€‚ Dub'eç­‰äººï¼ˆ2016ï¼‰å°†äº‘åˆ’åˆ†æˆåŸºäº3Dæ®µåŒ¹é…çš„é—­ç¯æ£€æµ‹ç®—æ³•çš„ä¸åŒå…ƒç´ ã€‚
